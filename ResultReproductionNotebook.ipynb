{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This file serves as an interactive and easy to use notebook for reproducing a majority of the results from our groups project for the CSE 481 Neural Engineering Capstone. Our project aimed to process raw single-channeled EEG data from numerous sleep study participants and develop/train various models to determine what methods are most effective at classifying these signals into their correct sleep stages. Our project aimed to develop classifiers that could be used to assist other researchers in the field as the first step in most sleep-study experiments relies on an expert spending multiple hours hand labeling the EEG signals themselves."
      ],
      "metadata": {
        "id": "Q_n6c4PNmC22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8KhqlvijfFj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Please uncomment this cell if you are running the notebook on google colab and wish to import data through your personal drive."
      ],
      "metadata": {
        "id": "TQKFjNMhnb9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM3vC9mhj_X9",
        "outputId": "f7406da2-bc50-4965-ead5-ce240be90281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "Our data is organized into various .npz files each of which correspond to the data from a single participant in the sleep study we utilized. The singal is processed using a sampling rate of 100 Hz and then divided into separate 30 second epochs. We extract a test set that is equivalent to ~10% of the total data and reserve the rest for training our models. We process each file according to whichever set it belongs, vectorize the data, and one-hot-encode the labels into a format that is understandable to our models.\n",
        "\n",
        "As a result our input data is a collection of 3000x1 vectors corresponding to a sampled epoch and our labels are a collection of 5x1 vectors corresponding to which label below (using labels_dict) the input matches to. "
      ],
      "metadata": {
        "id": "Hd_NV-p4nmWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byq1pNaAjfFk"
      },
      "outputs": [],
      "source": [
        "labels_dict = {\n",
        "    0: \"W\",\n",
        "    1: \"N1\",\n",
        "    2: \"N2\",\n",
        "    3: \"N3\",\n",
        "    4: \"REM\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRR5tKS2jfFk",
        "outputId": "93cb1a25-bde1-452e-8003-6711f0a1fe58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SC4001E0.npz', 'SC4002E0.npz', 'SC4011E0.npz', 'SC4012E0.npz', 'SC4021E0.npz', 'SC4022E0.npz', 'SC4031E0.npz', 'SC4032E0.npz', 'SC4041E0.npz', 'SC4042E0.npz', 'SC4051E0.npz', 'SC4052E0.npz', 'SC4061E0.npz', 'SC4062E0.npz', 'SC4071E0.npz', 'SC4072E0.npz', 'SC4081E0.npz', 'SC4082E0.npz', 'SC4091E0.npz', 'SC4092E0.npz', 'SC4101E0.npz', 'SC4102E0.npz', 'SC4111E0.npz', 'SC4112E0.npz', 'SC4121E0.npz', 'SC4122E0.npz', 'SC4131E0.npz', 'SC4141E0.npz', 'SC4142E0.npz', 'SC4151E0.npz', 'SC4152E0.npz', 'SC4161E0.npz', 'SC4162E0.npz', 'SC4171E0.npz', 'SC4172E0.npz', 'SC4181E0.npz', 'SC4182E0.npz', 'SC4191E0.npz', 'SC4192E0.npz']\n"
          ]
        }
      ],
      "source": [
        "# Read in all files from directory\n",
        "data_dir = \"drive/MyDrive/data/eeg_fpz_cz\"\n",
        "allfiles = os.listdir(data_dir)\n",
        "print(allfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9GQPTDgjfFl",
        "outputId": "073c8f4c-9b05-4589-dfc1-71e54e89dbdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['drive/MyDrive/data/eeg_fpz_cz/SC4001E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4002E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4011E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4012E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4021E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4022E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4031E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4032E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4041E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4042E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4051E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4052E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4061E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4062E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4071E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4072E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4081E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4082E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4091E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4092E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4101E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4102E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4111E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4112E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4121E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4122E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4131E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4141E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4142E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4151E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4152E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4161E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4162E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4171E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4172E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4181E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4182E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4191E0.npz', 'drive/MyDrive/data/eeg_fpz_cz/SC4192E0.npz']\n"
          ]
        }
      ],
      "source": [
        "# Process only .npz files\n",
        "npzfiles = []\n",
        "for idx, f in enumerate(allfiles):\n",
        "    if \".npz\" in f:\n",
        "        npzfiles.append(os.path.join(data_dir, f))\n",
        "npzfiles.sort()\n",
        "print(npzfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ6PwJ4rjfFm"
      },
      "outputs": [],
      "source": [
        "# Randomly split in 90% train, 10% test\n",
        "idx = np.random.permutation(len(npzfiles))\n",
        "train_idx = idx[: 9*len(npzfiles) // 10]\n",
        "test_idx = idx[9*len(npzfiles) // 10 :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20MyoCgcjfFn"
      },
      "outputs": [],
      "source": [
        "# Extract train and test files\n",
        "train_files = [npzfiles[i] for i in train_idx]\n",
        "test_files = [npzfiles[i] for i in test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b84SW30FjfFn"
      },
      "outputs": [],
      "source": [
        "# Function used to read a collection of .npz files and return processed data and labels\n",
        "def extract_files(files):\n",
        "    data = []\n",
        "    labels = []\n",
        "    fs = None\n",
        "    for file in files:\n",
        "        print(\"Loading {} ...\".format(file))\n",
        "        with np.load(file) as f:\n",
        "            d = f['x']\n",
        "            l = f['y']\n",
        "            sr = f['fs']\n",
        "        fs = sr\n",
        "        data.append(d)\n",
        "        labels.append(l)\n",
        "    data = np.vstack(data)\n",
        "    labels = np.hstack(labels)\n",
        "    labels = tf.one_hot(labels, 5)\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUYcAwEqjfFo",
        "outputId": "085e7e2c-ccbf-4e93-fca5-81dc016417c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4011E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4041E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4192E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4151E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4081E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4091E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4062E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4121E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4021E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4032E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4131E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4181E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4182E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4172E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4082E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4161E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4122E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4111E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4102E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4162E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4071E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4191E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4022E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4142E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4152E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4051E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4012E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4061E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4001E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4141E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4042E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4171E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4072E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4031E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4112E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4002E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4092E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4052E0.npz ...\n",
            "Loading drive/MyDrive/data/eeg_fpz_cz/SC4101E0.npz ...\n"
          ]
        }
      ],
      "source": [
        "# Final train and test sets\n",
        "train_X, train_y = extract_files(train_files)\n",
        "test_X, test_y = extract_files(test_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Parameter Tuning and Model Architecture\n",
        "We created and trained three separate models with different architectures to try and uncover which would be most effective for the task at hand. The three models are as follows:\n",
        "\n",
        "\n",
        "1.   Basic CNN\n",
        "\n",
        "> From our initial research, we uncovered that the most widely used networks for working with time series data and specifically EEG signals relies on a convolutional neural net as the backbone for feature extraction. As a result, our group decided it was a natural first step to try and develop and train a CNN of our own to see how effective this type of model would be at extracting features and making classifications.\n",
        "\n",
        "\n",
        "2.   CNN-LSTM\n",
        "\n",
        "> To expand upon the CNN architecture from (1) many other researchers have suggested feeding the features extracted from a CNN into a recurrent neural net in hopes of being able to better learn transition rules between the various stages. As a result, the second implementation that we tested was a model which fed the results from our CNN into some long short-term memory (LSTM) cells.\n",
        "\n",
        "3.   CNN-Transformer\n",
        "\n",
        "> As an attempt to expand upon current literature and contribute our own findings to the space our group decided to test a third architecture. We were inspired by the recent results coming from related ML fields such as NLP where attention based models have begun to outperform RNN based models including LSTM layers. As a result, our group wanted to investigate the results of replacing the LSTM layers in (2) with a transformer based layer to see if this new model could better learn the transition rules.\n",
        "\n",
        "We begun by defining the general architecture for each model and then performing a randomized cross validation hyperparameter grid search over a subset of hyperparameters we decided were most critical to the model. \n",
        "\n",
        "Note: Unfortunately even with access to a GPU the training time for model (3) proved to be prohibitively long for great hyper parameter tuning. The model trained for several hours with each subset and as a result allowed us only to manually check a few configurations by hand. \n",
        "\n"
      ],
      "metadata": {
        "id": "gD7HSuORpRFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-AGJANALjfFo"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first run hyperparameter tuning for our basic CNN Model (1):"
      ],
      "metadata": {
        "id": "mBdcilbAtMj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build function for our basic CNN model (1)\n",
        "def get_CNN_model(k1_size=50, pool1_size=8, conv_size=8, learnRate=0.01):\n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=k1_size, strides=k1_size//8, activation='relu', padding='same', input_shape=(3000,1)))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(pool_size=pool1_size, strides =pool1_size, padding=\"same\"))\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(pool_size=pool1_size//2, strides=pool1_size//2, padding=\"same\"))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "  model.add(tf.keras.layers.Dense(700))\n",
        "  model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "  sgd=keras.optimizers.SGD(learning_rate=learnRate)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "F4AKWy3ODGrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier and hyper parameter grid\n",
        "model = KerasClassifier(build_fn=get_CNN_model, verbose=2)\n",
        "\n",
        "k1_size = [25, 50, 75]\n",
        "pool1_size = [4, 8, 16]\n",
        "conv_size = [4, 8, 16]\n",
        "learnRate = [1e-2, 1e-3, 1e-4]\n",
        "batchSize=[64]\n",
        "epochs=[20]\n",
        "\n",
        "grid = {\n",
        "    \"k1_size\": k1_size,\n",
        "    \"pool1_size\": pool1_size,\n",
        "    \"conv_size\": conv_size,\n",
        "    \"learnRate\": learnRate,\n",
        "    \"batch_size\": batchSize,\n",
        "    \"epochs\": epochs\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTs4kpa1E_5w",
        "outputId": "b9832f6e-de83-4cae-ed04-89a6866a7bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run randomized CV search\n",
        "searcher = RandomizedSearchCV(estimator=model, cv=5, param_distributions=grid, scoring='accuracy')\n",
        "searchResults = searcher.fit(train_X, np.argmax(train_y.numpy(), axis=1))\n",
        "\n",
        "bestScore = searchResults.best_score_\n",
        "bestParams = searchResults.best_params_\n",
        "print(\"Best score is {:.2f} using {}\".format(bestScore,\tbestParams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCkA1kJIHVvV",
        "outputId": "6213b043-b1ba-44fa-cdae-3975208a156f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 2.8670 - accuracy: 0.2846 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.7936 - accuracy: 0.3276 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 1.5395 - accuracy: 0.3829 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.3822 - accuracy: 0.4505 - 5s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2548 - accuracy: 0.5117 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1608 - accuracy: 0.5577 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.0910 - accuracy: 0.5838 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0369 - accuracy: 0.6061 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9952 - accuracy: 0.6147 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9569 - accuracy: 0.6284 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.9211 - accuracy: 0.6435 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8961 - accuracy: 0.6479 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8736 - accuracy: 0.6581 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.8550 - accuracy: 0.6633 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.8394 - accuracy: 0.6720 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.8295 - accuracy: 0.6774 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.8115 - accuracy: 0.6849 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7995 - accuracy: 0.6900 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7887 - accuracy: 0.6961 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7826 - accuracy: 0.7001 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 7s - loss: 2.7202 - accuracy: 0.2916 - 7s/epoch - 15ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.7780 - accuracy: 0.3468 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.5040 - accuracy: 0.4109 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.3414 - accuracy: 0.4776 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2267 - accuracy: 0.5295 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1331 - accuracy: 0.5706 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.0679 - accuracy: 0.5908 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0060 - accuracy: 0.6142 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9681 - accuracy: 0.6264 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9282 - accuracy: 0.6419 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.8949 - accuracy: 0.6527 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8675 - accuracy: 0.6616 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8428 - accuracy: 0.6759 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.8217 - accuracy: 0.6843 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.8057 - accuracy: 0.6923 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7928 - accuracy: 0.7003 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7700 - accuracy: 0.7118 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7662 - accuracy: 0.7142 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7500 - accuracy: 0.7210 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7429 - accuracy: 0.7251 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 2.6396 - accuracy: 0.2900 - 6s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.7447 - accuracy: 0.3499 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.4519 - accuracy: 0.4317 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.2882 - accuracy: 0.5033 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.1692 - accuracy: 0.5506 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 1.0942 - accuracy: 0.5828 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.0265 - accuracy: 0.6052 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.9735 - accuracy: 0.6274 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9290 - accuracy: 0.6414 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9042 - accuracy: 0.6491 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.8751 - accuracy: 0.6606 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8549 - accuracy: 0.6683 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8332 - accuracy: 0.6751 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.8163 - accuracy: 0.6846 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.8012 - accuracy: 0.6931 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7814 - accuracy: 0.6976 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7730 - accuracy: 0.7022 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7627 - accuracy: 0.7085 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7511 - accuracy: 0.7155 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7434 - accuracy: 0.7178 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 2.6867 - accuracy: 0.2797 - 6s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.7992 - accuracy: 0.3274 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.5643 - accuracy: 0.3756 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.4091 - accuracy: 0.4392 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2821 - accuracy: 0.4988 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1745 - accuracy: 0.5487 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.0952 - accuracy: 0.5845 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0354 - accuracy: 0.6041 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9840 - accuracy: 0.6260 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9430 - accuracy: 0.6354 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.9088 - accuracy: 0.6469 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8904 - accuracy: 0.6547 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8704 - accuracy: 0.6591 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.8536 - accuracy: 0.6676 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.8428 - accuracy: 0.6748 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.8242 - accuracy: 0.6806 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.8161 - accuracy: 0.6879 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.8055 - accuracy: 0.6890 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7964 - accuracy: 0.6947 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7845 - accuracy: 0.7020 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 2.7148 - accuracy: 0.2836 - 6s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.8239 - accuracy: 0.3196 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.6175 - accuracy: 0.3538 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.4681 - accuracy: 0.4017 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.3666 - accuracy: 0.4580 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.2711 - accuracy: 0.5055 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.1824 - accuracy: 0.5553 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.1076 - accuracy: 0.5840 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 1.0504 - accuracy: 0.6060 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 1.0050 - accuracy: 0.6213 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.9625 - accuracy: 0.6329 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.9313 - accuracy: 0.6423 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.9015 - accuracy: 0.6527 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.8777 - accuracy: 0.6589 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.8552 - accuracy: 0.6670 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.8390 - accuracy: 0.6738 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.8188 - accuracy: 0.6786 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.8052 - accuracy: 0.6835 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7908 - accuracy: 0.6876 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7824 - accuracy: 0.6946 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.4059 - accuracy: 0.5289 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 4s - loss: 0.7477 - accuracy: 0.7191 - 4s/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 4s - loss: 0.6556 - accuracy: 0.7579 - 4s/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 4s - loss: 0.6061 - accuracy: 0.7751 - 4s/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 4s - loss: 0.5797 - accuracy: 0.7857 - 4s/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 4s - loss: 0.5572 - accuracy: 0.7944 - 4s/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 4s - loss: 0.5423 - accuracy: 0.8011 - 4s/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 4s - loss: 0.5220 - accuracy: 0.8067 - 4s/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 4s - loss: 0.5224 - accuracy: 0.8062 - 4s/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 4s - loss: 0.5087 - accuracy: 0.8122 - 4s/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 4s - loss: 0.5060 - accuracy: 0.8123 - 4s/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 4s - loss: 0.4981 - accuracy: 0.8118 - 4s/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 4s - loss: 0.4899 - accuracy: 0.8163 - 4s/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 4s - loss: 0.4880 - accuracy: 0.8186 - 4s/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 4s - loss: 0.4796 - accuracy: 0.8206 - 4s/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 4s - loss: 0.4771 - accuracy: 0.8235 - 4s/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 4s - loss: 0.4739 - accuracy: 0.8223 - 4s/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 4s - loss: 0.4669 - accuracy: 0.8252 - 4s/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 4s - loss: 0.4645 - accuracy: 0.8275 - 4s/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 4s - loss: 0.4595 - accuracy: 0.8290 - 4s/epoch - 9ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.2280 - accuracy: 0.5537 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 4s - loss: 0.7286 - accuracy: 0.7348 - 4s/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 4s - loss: 0.6508 - accuracy: 0.7625 - 4s/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 4s - loss: 0.6237 - accuracy: 0.7698 - 4s/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 4s - loss: 0.5751 - accuracy: 0.7901 - 4s/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 4s - loss: 0.5611 - accuracy: 0.7933 - 4s/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 4s - loss: 0.5485 - accuracy: 0.7999 - 4s/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 4s - loss: 0.5307 - accuracy: 0.8047 - 4s/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 4s - loss: 0.5229 - accuracy: 0.8072 - 4s/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 4s - loss: 0.5120 - accuracy: 0.8112 - 4s/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 4s - loss: 0.5052 - accuracy: 0.8137 - 4s/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 4s - loss: 0.5021 - accuracy: 0.8153 - 4s/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 4s - loss: 0.4960 - accuracy: 0.8162 - 4s/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 4s - loss: 0.4946 - accuracy: 0.8166 - 4s/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 4s - loss: 0.4852 - accuracy: 0.8224 - 4s/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 4s - loss: 0.4874 - accuracy: 0.8208 - 4s/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 4s - loss: 0.4789 - accuracy: 0.8239 - 4s/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 4s - loss: 0.4770 - accuracy: 0.8231 - 4s/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 4s - loss: 0.4685 - accuracy: 0.8257 - 4s/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 4s - loss: 0.4656 - accuracy: 0.8277 - 4s/epoch - 9ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.1380 - accuracy: 0.5896 - 5s/epoch - 10ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 4s - loss: 0.6878 - accuracy: 0.7485 - 4s/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 4s - loss: 0.5989 - accuracy: 0.7811 - 4s/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 4s - loss: 0.5603 - accuracy: 0.7935 - 4s/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 4s - loss: 0.5441 - accuracy: 0.7996 - 4s/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 4s - loss: 0.5240 - accuracy: 0.8064 - 4s/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 4s - loss: 0.5105 - accuracy: 0.8091 - 4s/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 4s - loss: 0.5025 - accuracy: 0.8155 - 4s/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 4s - loss: 0.4932 - accuracy: 0.8171 - 4s/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.4841 - accuracy: 0.8207 - 5s/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 4s - loss: 0.4811 - accuracy: 0.8228 - 4s/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 4s - loss: 0.4743 - accuracy: 0.8259 - 4s/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 4s - loss: 0.4674 - accuracy: 0.8288 - 4s/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 4s - loss: 0.4605 - accuracy: 0.8289 - 4s/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 4s - loss: 0.4735 - accuracy: 0.8249 - 4s/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 4s - loss: 0.4588 - accuracy: 0.8314 - 4s/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 4s - loss: 0.4525 - accuracy: 0.8321 - 4s/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 4s - loss: 0.4499 - accuracy: 0.8324 - 4s/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 4s - loss: 0.4480 - accuracy: 0.8343 - 4s/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 4s - loss: 0.4461 - accuracy: 0.8336 - 4s/epoch - 9ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.1968 - accuracy: 0.5543 - 5s/epoch - 10ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 4s - loss: 0.7551 - accuracy: 0.7197 - 4s/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 4s - loss: 0.6650 - accuracy: 0.7516 - 4s/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 4s - loss: 0.6220 - accuracy: 0.7676 - 4s/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 4s - loss: 0.5887 - accuracy: 0.7784 - 4s/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 4s - loss: 0.5678 - accuracy: 0.7851 - 4s/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 4s - loss: 0.5571 - accuracy: 0.7918 - 4s/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 4s - loss: 0.5460 - accuracy: 0.7985 - 4s/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 4s - loss: 0.5353 - accuracy: 0.8000 - 4s/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 4s - loss: 0.5277 - accuracy: 0.8039 - 4s/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 4s - loss: 0.5213 - accuracy: 0.8062 - 4s/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 4s - loss: 0.5092 - accuracy: 0.8116 - 4s/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 4s - loss: 0.5082 - accuracy: 0.8123 - 4s/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 4s - loss: 0.5045 - accuracy: 0.8121 - 4s/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 4s - loss: 0.5018 - accuracy: 0.8139 - 4s/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 4s - loss: 0.4974 - accuracy: 0.8135 - 4s/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 4s - loss: 0.4893 - accuracy: 0.8159 - 4s/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 4s - loss: 0.4851 - accuracy: 0.8177 - 4s/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 4s - loss: 0.4820 - accuracy: 0.8197 - 4s/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 4s - loss: 0.4783 - accuracy: 0.8222 - 4s/epoch - 9ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.2056 - accuracy: 0.5583 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 4s - loss: 0.7374 - accuracy: 0.7279 - 4s/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 4s - loss: 0.6394 - accuracy: 0.7620 - 4s/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 4s - loss: 0.6034 - accuracy: 0.7750 - 4s/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 4s - loss: 0.5758 - accuracy: 0.7837 - 4s/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 4s - loss: 0.5577 - accuracy: 0.7907 - 4s/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 4s - loss: 0.5455 - accuracy: 0.7983 - 4s/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 4s - loss: 0.5240 - accuracy: 0.8029 - 4s/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 4s - loss: 0.5175 - accuracy: 0.8067 - 4s/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 4s - loss: 0.5096 - accuracy: 0.8080 - 4s/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 4s - loss: 0.5042 - accuracy: 0.8108 - 4s/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 4s - loss: 0.4938 - accuracy: 0.8156 - 4s/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 4s - loss: 0.4860 - accuracy: 0.8158 - 4s/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 4s - loss: 0.4842 - accuracy: 0.8194 - 4s/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 4s - loss: 0.4831 - accuracy: 0.8202 - 4s/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 4s - loss: 0.4787 - accuracy: 0.8216 - 4s/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 4s - loss: 0.4699 - accuracy: 0.8261 - 4s/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 4s - loss: 0.4681 - accuracy: 0.8225 - 4s/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 4s - loss: 0.4655 - accuracy: 0.8252 - 4s/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 4s - loss: 0.4603 - accuracy: 0.8270 - 4s/epoch - 9ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 8s - loss: 2.3657 - accuracy: 0.2920 - 8s/epoch - 16ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.6348 - accuracy: 0.3421 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.4613 - accuracy: 0.3947 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.3560 - accuracy: 0.4366 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2631 - accuracy: 0.4856 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1795 - accuracy: 0.5291 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.0935 - accuracy: 0.5738 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0269 - accuracy: 0.6000 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9611 - accuracy: 0.6277 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9106 - accuracy: 0.6437 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.8724 - accuracy: 0.6575 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8334 - accuracy: 0.6752 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8061 - accuracy: 0.6878 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.7817 - accuracy: 0.6977 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.7651 - accuracy: 0.7066 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7512 - accuracy: 0.7156 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7321 - accuracy: 0.7237 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7297 - accuracy: 0.7273 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7147 - accuracy: 0.7358 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7107 - accuracy: 0.7391 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 7s - loss: 2.1711 - accuracy: 0.2836 - 7s/epoch - 15ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.6384 - accuracy: 0.3377 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.4771 - accuracy: 0.3886 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.3769 - accuracy: 0.4306 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2857 - accuracy: 0.4772 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1903 - accuracy: 0.5271 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.1073 - accuracy: 0.5720 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0323 - accuracy: 0.6024 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9692 - accuracy: 0.6264 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9135 - accuracy: 0.6467 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.8699 - accuracy: 0.6596 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8310 - accuracy: 0.6742 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.7979 - accuracy: 0.6895 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.7719 - accuracy: 0.7044 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.7509 - accuracy: 0.7171 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7305 - accuracy: 0.7256 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7174 - accuracy: 0.7319 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7047 - accuracy: 0.7383 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.6969 - accuracy: 0.7439 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.6873 - accuracy: 0.7467 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 2.2184 - accuracy: 0.2870 - 6s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.6542 - accuracy: 0.3227 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.4993 - accuracy: 0.3651 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.4047 - accuracy: 0.4118 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.3097 - accuracy: 0.4592 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.2188 - accuracy: 0.5060 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.1403 - accuracy: 0.5512 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0521 - accuracy: 0.5928 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9882 - accuracy: 0.6216 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9358 - accuracy: 0.6411 - 5s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.8925 - accuracy: 0.6551 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8532 - accuracy: 0.6685 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8146 - accuracy: 0.6800 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.7872 - accuracy: 0.6929 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.7616 - accuracy: 0.7038 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7367 - accuracy: 0.7192 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7252 - accuracy: 0.7245 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7077 - accuracy: 0.7356 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.6951 - accuracy: 0.7394 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.6840 - accuracy: 0.7466 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 2.2093 - accuracy: 0.2926 - 6s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.5510 - accuracy: 0.3635 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.3959 - accuracy: 0.4130 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.3139 - accuracy: 0.4543 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2359 - accuracy: 0.4925 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1682 - accuracy: 0.5264 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.1051 - accuracy: 0.5585 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 1.0483 - accuracy: 0.5856 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9990 - accuracy: 0.6076 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.9530 - accuracy: 0.6258 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.9165 - accuracy: 0.6355 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8857 - accuracy: 0.6502 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.8569 - accuracy: 0.6601 - 5s/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.8268 - accuracy: 0.6761 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.7999 - accuracy: 0.6879 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7822 - accuracy: 0.6942 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7672 - accuracy: 0.6999 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7518 - accuracy: 0.7106 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7361 - accuracy: 0.7195 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.7261 - accuracy: 0.7270 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 2.3112 - accuracy: 0.2917 - 6s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 1.6475 - accuracy: 0.3373 - 5s/epoch - 11ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 1.4689 - accuracy: 0.3872 - 5s/epoch - 11ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 1.3544 - accuracy: 0.4412 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 1.2479 - accuracy: 0.4938 - 5s/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 1.1501 - accuracy: 0.5471 - 5s/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 1.0581 - accuracy: 0.5924 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.9876 - accuracy: 0.6218 - 5s/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.9352 - accuracy: 0.6428 - 5s/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.8920 - accuracy: 0.6564 - 5s/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.8546 - accuracy: 0.6683 - 5s/epoch - 11ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.8147 - accuracy: 0.6823 - 5s/epoch - 11ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.7901 - accuracy: 0.6950 - 5s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.7760 - accuracy: 0.7010 - 5s/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.7547 - accuracy: 0.7082 - 5s/epoch - 11ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.7391 - accuracy: 0.7164 - 5s/epoch - 11ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.7236 - accuracy: 0.7258 - 5s/epoch - 11ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.7127 - accuracy: 0.7308 - 5s/epoch - 11ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.7043 - accuracy: 0.7385 - 5s/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.6959 - accuracy: 0.7405 - 5s/epoch - 11ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 7s - loss: 1.2166 - accuracy: 0.5364 - 7s/epoch - 15ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.7966 - accuracy: 0.7047 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.6948 - accuracy: 0.7435 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6527 - accuracy: 0.7617 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6235 - accuracy: 0.7720 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.5966 - accuracy: 0.7823 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.5719 - accuracy: 0.7915 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.5640 - accuracy: 0.7931 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5430 - accuracy: 0.8029 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5310 - accuracy: 0.8038 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5287 - accuracy: 0.8035 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5250 - accuracy: 0.8049 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5115 - accuracy: 0.8113 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5201 - accuracy: 0.8076 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5050 - accuracy: 0.8117 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5026 - accuracy: 0.8135 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.4892 - accuracy: 0.8175 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.4871 - accuracy: 0.8187 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.4815 - accuracy: 0.8214 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.4814 - accuracy: 0.8210 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 7s - loss: 1.4509 - accuracy: 0.4802 - 7s/epoch - 14ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8706 - accuracy: 0.6680 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7193 - accuracy: 0.7416 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6535 - accuracy: 0.7592 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6211 - accuracy: 0.7740 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.5910 - accuracy: 0.7845 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.5806 - accuracy: 0.7869 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.5559 - accuracy: 0.7957 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5471 - accuracy: 0.8006 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5363 - accuracy: 0.8030 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5283 - accuracy: 0.8078 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5161 - accuracy: 0.8094 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5122 - accuracy: 0.8121 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.4979 - accuracy: 0.8165 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5007 - accuracy: 0.8163 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.4913 - accuracy: 0.8194 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.4923 - accuracy: 0.8182 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.4849 - accuracy: 0.8222 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.4832 - accuracy: 0.8220 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.4731 - accuracy: 0.8258 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.0885 - accuracy: 0.5894 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.7793 - accuracy: 0.7203 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.6677 - accuracy: 0.7590 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6172 - accuracy: 0.7768 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.5805 - accuracy: 0.7878 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.5677 - accuracy: 0.7925 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.5474 - accuracy: 0.8015 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.5290 - accuracy: 0.8063 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5181 - accuracy: 0.8103 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5104 - accuracy: 0.8119 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5005 - accuracy: 0.8162 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.4927 - accuracy: 0.8192 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.4878 - accuracy: 0.8208 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.4809 - accuracy: 0.8218 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.4700 - accuracy: 0.8250 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.4709 - accuracy: 0.8256 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.4678 - accuracy: 0.8286 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.4553 - accuracy: 0.8282 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.4562 - accuracy: 0.8297 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.4520 - accuracy: 0.8319 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 7s - loss: 1.2033 - accuracy: 0.5208 - 7s/epoch - 14ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8522 - accuracy: 0.6801 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7293 - accuracy: 0.7339 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6712 - accuracy: 0.7501 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6282 - accuracy: 0.7675 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.6094 - accuracy: 0.7772 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.5934 - accuracy: 0.7808 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.5709 - accuracy: 0.7891 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5583 - accuracy: 0.7931 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5529 - accuracy: 0.7954 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5373 - accuracy: 0.8001 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5375 - accuracy: 0.8023 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5287 - accuracy: 0.8059 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5262 - accuracy: 0.8032 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5132 - accuracy: 0.8088 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5051 - accuracy: 0.8119 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.5033 - accuracy: 0.8122 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.4960 - accuracy: 0.8151 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.4881 - accuracy: 0.8188 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.4881 - accuracy: 0.8195 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.2405 - accuracy: 0.5254 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8290 - accuracy: 0.6858 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7216 - accuracy: 0.7327 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6624 - accuracy: 0.7552 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6201 - accuracy: 0.7702 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.5935 - accuracy: 0.7781 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.5911 - accuracy: 0.7808 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.5598 - accuracy: 0.7906 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5465 - accuracy: 0.7967 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5336 - accuracy: 0.8013 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5230 - accuracy: 0.8071 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5175 - accuracy: 0.8068 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5061 - accuracy: 0.8102 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5025 - accuracy: 0.8127 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.4924 - accuracy: 0.8168 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.4899 - accuracy: 0.8162 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.4833 - accuracy: 0.8190 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.4851 - accuracy: 0.8187 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.4739 - accuracy: 0.8231 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.4662 - accuracy: 0.8268 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.3731 - accuracy: 0.5088 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 0.7396 - accuracy: 0.7262 - 5s/epoch - 10ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 0.5999 - accuracy: 0.7808 - 5s/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 0.5592 - accuracy: 0.7923 - 5s/epoch - 10ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 0.5285 - accuracy: 0.8036 - 5s/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 0.5092 - accuracy: 0.8114 - 5s/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 0.4950 - accuracy: 0.8137 - 5s/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.4869 - accuracy: 0.8206 - 5s/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.4763 - accuracy: 0.8220 - 5s/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.4693 - accuracy: 0.8247 - 5s/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.4590 - accuracy: 0.8275 - 5s/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.4540 - accuracy: 0.8299 - 5s/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.4476 - accuracy: 0.8333 - 5s/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.4452 - accuracy: 0.8327 - 5s/epoch - 10ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.4411 - accuracy: 0.8337 - 5s/epoch - 10ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.4370 - accuracy: 0.8385 - 5s/epoch - 10ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.4351 - accuracy: 0.8378 - 5s/epoch - 10ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.4312 - accuracy: 0.8389 - 5s/epoch - 10ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.4264 - accuracy: 0.8393 - 5s/epoch - 10ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.4244 - accuracy: 0.8414 - 5s/epoch - 10ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.2789 - accuracy: 0.5335 - 5s/epoch - 12ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 0.7062 - accuracy: 0.7451 - 5s/epoch - 10ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 0.6205 - accuracy: 0.7778 - 5s/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 0.5769 - accuracy: 0.7903 - 5s/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 0.5285 - accuracy: 0.8080 - 5s/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 0.5109 - accuracy: 0.8139 - 5s/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 0.5001 - accuracy: 0.8163 - 5s/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.4900 - accuracy: 0.8191 - 5s/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.4765 - accuracy: 0.8230 - 5s/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.4680 - accuracy: 0.8259 - 5s/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.4636 - accuracy: 0.8265 - 5s/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.4644 - accuracy: 0.8285 - 5s/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.4514 - accuracy: 0.8299 - 5s/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.4482 - accuracy: 0.8327 - 5s/epoch - 10ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.4462 - accuracy: 0.8336 - 5s/epoch - 10ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.4380 - accuracy: 0.8356 - 5s/epoch - 10ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.4370 - accuracy: 0.8347 - 5s/epoch - 10ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.4364 - accuracy: 0.8366 - 5s/epoch - 10ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.4291 - accuracy: 0.8397 - 5s/epoch - 10ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.4277 - accuracy: 0.8398 - 5s/epoch - 10ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.3063 - accuracy: 0.5447 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 0.6558 - accuracy: 0.7530 - 5s/epoch - 10ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 0.5550 - accuracy: 0.7925 - 5s/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 0.5227 - accuracy: 0.8053 - 5s/epoch - 10ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 0.4976 - accuracy: 0.8170 - 5s/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 0.4782 - accuracy: 0.8204 - 5s/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 0.4692 - accuracy: 0.8260 - 5s/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.4580 - accuracy: 0.8292 - 5s/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.4494 - accuracy: 0.8316 - 5s/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.4442 - accuracy: 0.8354 - 5s/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.4406 - accuracy: 0.8368 - 5s/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.4311 - accuracy: 0.8399 - 5s/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.4275 - accuracy: 0.8397 - 5s/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.4254 - accuracy: 0.8422 - 5s/epoch - 10ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.4198 - accuracy: 0.8425 - 5s/epoch - 10ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.4167 - accuracy: 0.8454 - 5s/epoch - 10ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.4164 - accuracy: 0.8456 - 5s/epoch - 10ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.4110 - accuracy: 0.8495 - 5s/epoch - 10ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.4097 - accuracy: 0.8481 - 5s/epoch - 10ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.4047 - accuracy: 0.8483 - 5s/epoch - 10ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.2727 - accuracy: 0.5335 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 0.7066 - accuracy: 0.7378 - 5s/epoch - 10ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 0.6220 - accuracy: 0.7702 - 5s/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 0.5768 - accuracy: 0.7839 - 5s/epoch - 10ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 0.5460 - accuracy: 0.7961 - 5s/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 0.5275 - accuracy: 0.8002 - 5s/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 0.5199 - accuracy: 0.8056 - 5s/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.5035 - accuracy: 0.8113 - 5s/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.4955 - accuracy: 0.8166 - 5s/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.4901 - accuracy: 0.8173 - 5s/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.4824 - accuracy: 0.8199 - 5s/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.4708 - accuracy: 0.8249 - 5s/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.4700 - accuracy: 0.8240 - 5s/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.4620 - accuracy: 0.8259 - 5s/epoch - 10ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.4591 - accuracy: 0.8276 - 5s/epoch - 10ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.4544 - accuracy: 0.8306 - 5s/epoch - 10ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.4527 - accuracy: 0.8295 - 5s/epoch - 10ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.4464 - accuracy: 0.8344 - 5s/epoch - 10ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.4435 - accuracy: 0.8365 - 5s/epoch - 10ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.4445 - accuracy: 0.8329 - 5s/epoch - 10ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 5s - loss: 1.2448 - accuracy: 0.5391 - 5s/epoch - 11ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 5s - loss: 0.6791 - accuracy: 0.7458 - 5s/epoch - 10ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 5s - loss: 0.6024 - accuracy: 0.7749 - 5s/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 5s - loss: 0.5497 - accuracy: 0.7936 - 5s/epoch - 10ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 5s - loss: 0.5240 - accuracy: 0.8022 - 5s/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 5s - loss: 0.5123 - accuracy: 0.8092 - 5s/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 5s - loss: 0.4926 - accuracy: 0.8154 - 5s/epoch - 11ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 5s - loss: 0.4831 - accuracy: 0.8179 - 5s/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 5s - loss: 0.4735 - accuracy: 0.8219 - 5s/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 5s - loss: 0.4682 - accuracy: 0.8240 - 5s/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 5s - loss: 0.4587 - accuracy: 0.8291 - 5s/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 5s - loss: 0.4687 - accuracy: 0.8249 - 5s/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 5s - loss: 0.4480 - accuracy: 0.8314 - 5s/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 5s - loss: 0.4452 - accuracy: 0.8339 - 5s/epoch - 10ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 5s - loss: 0.4371 - accuracy: 0.8347 - 5s/epoch - 10ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 5s - loss: 0.4364 - accuracy: 0.8365 - 5s/epoch - 10ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 5s - loss: 0.4354 - accuracy: 0.8349 - 5s/epoch - 10ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 5s - loss: 0.4290 - accuracy: 0.8371 - 5s/epoch - 10ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 5s - loss: 0.4280 - accuracy: 0.8382 - 5s/epoch - 10ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 5s - loss: 0.4207 - accuracy: 0.8428 - 5s/epoch - 10ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4474 - accuracy: 0.4709 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 0.8497 - accuracy: 0.6723 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 0.7427 - accuracy: 0.7206 - 8s/epoch - 17ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 8s - loss: 0.6838 - accuracy: 0.7520 - 8s/epoch - 17ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 8s - loss: 0.6491 - accuracy: 0.7665 - 8s/epoch - 17ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 8s - loss: 0.6170 - accuracy: 0.7778 - 8s/epoch - 17ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 8s - loss: 0.5954 - accuracy: 0.7848 - 8s/epoch - 17ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 8s - loss: 0.5848 - accuracy: 0.7899 - 8s/epoch - 17ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 8s - loss: 0.5639 - accuracy: 0.7960 - 8s/epoch - 17ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 8s - loss: 0.5539 - accuracy: 0.7979 - 8s/epoch - 17ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 8s - loss: 0.5449 - accuracy: 0.8017 - 8s/epoch - 17ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 8s - loss: 0.5349 - accuracy: 0.8039 - 8s/epoch - 17ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 8s - loss: 0.5270 - accuracy: 0.8066 - 8s/epoch - 17ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 0.5196 - accuracy: 0.8089 - 8s/epoch - 17ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 8s - loss: 0.5141 - accuracy: 0.8123 - 8s/epoch - 17ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 8s - loss: 0.5082 - accuracy: 0.8145 - 8s/epoch - 17ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 8s - loss: 0.5020 - accuracy: 0.8169 - 8s/epoch - 17ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 0.5007 - accuracy: 0.8161 - 8s/epoch - 17ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 8s - loss: 0.4914 - accuracy: 0.8210 - 8s/epoch - 17ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 8s - loss: 0.4865 - accuracy: 0.8192 - 8s/epoch - 17ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3954 - accuracy: 0.4781 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 0.8240 - accuracy: 0.6843 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 0.7122 - accuracy: 0.7389 - 8s/epoch - 17ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 8s - loss: 0.6606 - accuracy: 0.7663 - 8s/epoch - 17ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 8s - loss: 0.6349 - accuracy: 0.7762 - 8s/epoch - 17ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 8s - loss: 0.6077 - accuracy: 0.7859 - 8s/epoch - 17ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 8s - loss: 0.5942 - accuracy: 0.7895 - 8s/epoch - 17ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 8s - loss: 0.5742 - accuracy: 0.7955 - 8s/epoch - 17ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 8s - loss: 0.5646 - accuracy: 0.7978 - 8s/epoch - 17ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 8s - loss: 0.5557 - accuracy: 0.8017 - 8s/epoch - 17ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 8s - loss: 0.5460 - accuracy: 0.8043 - 8s/epoch - 17ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 8s - loss: 0.5345 - accuracy: 0.8077 - 8s/epoch - 17ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 8s - loss: 0.5258 - accuracy: 0.8092 - 8s/epoch - 17ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 0.5187 - accuracy: 0.8114 - 8s/epoch - 17ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 8s - loss: 0.5111 - accuracy: 0.8143 - 8s/epoch - 17ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 8s - loss: 0.5100 - accuracy: 0.8133 - 8s/epoch - 17ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 8s - loss: 0.5047 - accuracy: 0.8166 - 8s/epoch - 17ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 0.5017 - accuracy: 0.8157 - 8s/epoch - 17ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 8s - loss: 0.4941 - accuracy: 0.8181 - 8s/epoch - 17ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 8s - loss: 0.4922 - accuracy: 0.8201 - 8s/epoch - 17ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3994 - accuracy: 0.4903 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 0.7861 - accuracy: 0.6939 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 0.6763 - accuracy: 0.7481 - 8s/epoch - 17ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 8s - loss: 0.6342 - accuracy: 0.7685 - 8s/epoch - 17ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 8s - loss: 0.6019 - accuracy: 0.7821 - 8s/epoch - 17ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 8s - loss: 0.5849 - accuracy: 0.7919 - 8s/epoch - 17ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 8s - loss: 0.5648 - accuracy: 0.7991 - 8s/epoch - 17ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 8s - loss: 0.5530 - accuracy: 0.7985 - 8s/epoch - 17ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 8s - loss: 0.5389 - accuracy: 0.8080 - 8s/epoch - 17ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 8s - loss: 0.5320 - accuracy: 0.8083 - 8s/epoch - 17ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 8s - loss: 0.5185 - accuracy: 0.8107 - 8s/epoch - 17ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 8s - loss: 0.5122 - accuracy: 0.8151 - 8s/epoch - 17ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 8s - loss: 0.5049 - accuracy: 0.8142 - 8s/epoch - 17ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 0.5007 - accuracy: 0.8175 - 8s/epoch - 17ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 8s - loss: 0.4886 - accuracy: 0.8203 - 8s/epoch - 17ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 8s - loss: 0.4860 - accuracy: 0.8226 - 8s/epoch - 17ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 8s - loss: 0.4820 - accuracy: 0.8240 - 8s/epoch - 17ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 0.4740 - accuracy: 0.8271 - 8s/epoch - 17ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 8s - loss: 0.4716 - accuracy: 0.8243 - 8s/epoch - 17ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 8s - loss: 0.4678 - accuracy: 0.8280 - 8s/epoch - 17ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 8s - loss: 1.4143 - accuracy: 0.4711 - 8s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 0.8519 - accuracy: 0.6680 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 0.7571 - accuracy: 0.7141 - 8s/epoch - 17ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 8s - loss: 0.7002 - accuracy: 0.7419 - 8s/epoch - 17ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 8s - loss: 0.6647 - accuracy: 0.7582 - 8s/epoch - 17ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 8s - loss: 0.6311 - accuracy: 0.7713 - 8s/epoch - 17ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 8s - loss: 0.6108 - accuracy: 0.7773 - 8s/epoch - 17ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 8s - loss: 0.5964 - accuracy: 0.7855 - 8s/epoch - 17ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 8s - loss: 0.5848 - accuracy: 0.7874 - 8s/epoch - 17ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 8s - loss: 0.5767 - accuracy: 0.7881 - 8s/epoch - 17ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 8s - loss: 0.5628 - accuracy: 0.7947 - 8s/epoch - 17ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 8s - loss: 0.5541 - accuracy: 0.7967 - 8s/epoch - 17ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 8s - loss: 0.5479 - accuracy: 0.8003 - 8s/epoch - 17ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 0.5432 - accuracy: 0.7997 - 8s/epoch - 17ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 8s - loss: 0.5344 - accuracy: 0.8050 - 8s/epoch - 17ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 8s - loss: 0.5294 - accuracy: 0.8055 - 8s/epoch - 17ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 8s - loss: 0.5247 - accuracy: 0.8082 - 8s/epoch - 17ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 0.5186 - accuracy: 0.8095 - 8s/epoch - 17ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 8s - loss: 0.5161 - accuracy: 0.8116 - 8s/epoch - 17ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 8s - loss: 0.5139 - accuracy: 0.8136 - 8s/epoch - 17ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 8s - loss: 1.4454 - accuracy: 0.4638 - 8s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 0.8524 - accuracy: 0.6690 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 0.7432 - accuracy: 0.7132 - 8s/epoch - 17ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 8s - loss: 0.6794 - accuracy: 0.7472 - 8s/epoch - 17ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 8s - loss: 0.6483 - accuracy: 0.7610 - 8s/epoch - 17ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 8s - loss: 0.6197 - accuracy: 0.7722 - 8s/epoch - 17ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 8s - loss: 0.5993 - accuracy: 0.7805 - 8s/epoch - 17ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 8s - loss: 0.5826 - accuracy: 0.7861 - 8s/epoch - 17ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 8s - loss: 0.5702 - accuracy: 0.7885 - 8s/epoch - 17ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 8s - loss: 0.5581 - accuracy: 0.7949 - 8s/epoch - 17ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 8s - loss: 0.5454 - accuracy: 0.8004 - 8s/epoch - 17ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 8s - loss: 0.5371 - accuracy: 0.7999 - 8s/epoch - 17ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 8s - loss: 0.5305 - accuracy: 0.8038 - 8s/epoch - 17ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 0.5228 - accuracy: 0.8061 - 8s/epoch - 17ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 8s - loss: 0.5166 - accuracy: 0.8070 - 8s/epoch - 17ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 8s - loss: 0.5095 - accuracy: 0.8109 - 8s/epoch - 17ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 8s - loss: 0.4989 - accuracy: 0.8145 - 8s/epoch - 17ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 0.4969 - accuracy: 0.8157 - 8s/epoch - 17ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 8s - loss: 0.4915 - accuracy: 0.8176 - 8s/epoch - 17ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 8s - loss: 0.4854 - accuracy: 0.8211 - 8s/epoch - 17ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 4s - loss: 2.6268 - accuracy: 0.2869 - 4s/epoch - 9ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 3s - loss: 1.7228 - accuracy: 0.3360 - 3s/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 3s - loss: 1.5027 - accuracy: 0.3821 - 3s/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 3s - loss: 1.4096 - accuracy: 0.4108 - 3s/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 3s - loss: 1.3242 - accuracy: 0.4475 - 3s/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 3s - loss: 1.2511 - accuracy: 0.4837 - 3s/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 3s - loss: 1.1830 - accuracy: 0.5190 - 3s/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 3s - loss: 1.1329 - accuracy: 0.5510 - 3s/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 3s - loss: 1.0676 - accuracy: 0.5817 - 3s/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 3s - loss: 1.0189 - accuracy: 0.6013 - 3s/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 3s - loss: 0.9696 - accuracy: 0.6220 - 3s/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 3s - loss: 0.9378 - accuracy: 0.6342 - 3s/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 3s - loss: 0.8998 - accuracy: 0.6503 - 3s/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 3s - loss: 0.8751 - accuracy: 0.6584 - 3s/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 3s - loss: 0.8541 - accuracy: 0.6631 - 3s/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 3s - loss: 0.8347 - accuracy: 0.6715 - 3s/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 3s - loss: 0.8185 - accuracy: 0.6802 - 3s/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 3s - loss: 0.8031 - accuracy: 0.6852 - 3s/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 3s - loss: 0.7878 - accuracy: 0.6903 - 3s/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 3s - loss: 0.7816 - accuracy: 0.6966 - 3s/epoch - 6ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 4s - loss: 2.5912 - accuracy: 0.2914 - 4s/epoch - 8ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 3s - loss: 1.6866 - accuracy: 0.3441 - 3s/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 3s - loss: 1.4729 - accuracy: 0.3950 - 3s/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 3s - loss: 1.3376 - accuracy: 0.4530 - 3s/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 3s - loss: 1.2378 - accuracy: 0.5025 - 3s/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 3s - loss: 1.1660 - accuracy: 0.5412 - 3s/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 3s - loss: 1.0862 - accuracy: 0.5761 - 3s/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 3s - loss: 1.0360 - accuracy: 0.5991 - 3s/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 3s - loss: 0.9920 - accuracy: 0.6133 - 3s/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 3s - loss: 0.9491 - accuracy: 0.6324 - 3s/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 3s - loss: 0.9213 - accuracy: 0.6379 - 3s/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 3s - loss: 0.8965 - accuracy: 0.6486 - 3s/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 3s - loss: 0.8691 - accuracy: 0.6594 - 3s/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 3s - loss: 0.8417 - accuracy: 0.6716 - 3s/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 3s - loss: 0.8255 - accuracy: 0.6784 - 3s/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 3s - loss: 0.8059 - accuracy: 0.6877 - 3s/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 3s - loss: 0.7881 - accuracy: 0.6958 - 3s/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 3s - loss: 0.7763 - accuracy: 0.7010 - 3s/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 3s - loss: 0.7634 - accuracy: 0.7093 - 3s/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 3s - loss: 0.7519 - accuracy: 0.7109 - 3s/epoch - 6ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 3s - loss: 2.6114 - accuracy: 0.2737 - 3s/epoch - 7ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 3s - loss: 1.7222 - accuracy: 0.3228 - 3s/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 3s - loss: 1.5388 - accuracy: 0.3654 - 3s/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 3s - loss: 1.4182 - accuracy: 0.4104 - 3s/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 3s - loss: 1.3186 - accuracy: 0.4636 - 3s/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 3s - loss: 1.2274 - accuracy: 0.5115 - 3s/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 3s - loss: 1.1464 - accuracy: 0.5526 - 3s/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 3s - loss: 1.0795 - accuracy: 0.5820 - 3s/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 3s - loss: 1.0243 - accuracy: 0.6068 - 3s/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 3s - loss: 0.9733 - accuracy: 0.6223 - 3s/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 3s - loss: 0.9342 - accuracy: 0.6398 - 3s/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 3s - loss: 0.8995 - accuracy: 0.6513 - 3s/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 3s - loss: 0.8653 - accuracy: 0.6612 - 3s/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 3s - loss: 0.8470 - accuracy: 0.6667 - 3s/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 3s - loss: 0.8267 - accuracy: 0.6754 - 3s/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 3s - loss: 0.8084 - accuracy: 0.6831 - 3s/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 3s - loss: 0.7889 - accuracy: 0.6891 - 3s/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 3s - loss: 0.7751 - accuracy: 0.6953 - 3s/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 3s - loss: 0.7608 - accuracy: 0.7020 - 3s/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 3s - loss: 0.7538 - accuracy: 0.7085 - 3s/epoch - 6ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 3s - loss: 2.5979 - accuracy: 0.2918 - 3s/epoch - 7ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 3s - loss: 1.6943 - accuracy: 0.3445 - 3s/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 3s - loss: 1.4977 - accuracy: 0.3879 - 3s/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 3s - loss: 1.3843 - accuracy: 0.4282 - 3s/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 3s - loss: 1.2887 - accuracy: 0.4712 - 3s/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 3s - loss: 1.2108 - accuracy: 0.5091 - 3s/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 3s - loss: 1.1338 - accuracy: 0.5466 - 3s/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 3s - loss: 1.0731 - accuracy: 0.5798 - 3s/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 3s - loss: 1.0212 - accuracy: 0.6003 - 3s/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 3s - loss: 0.9775 - accuracy: 0.6148 - 3s/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 3s - loss: 0.9432 - accuracy: 0.6273 - 3s/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 3s - loss: 0.9090 - accuracy: 0.6410 - 3s/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 3s - loss: 0.8822 - accuracy: 0.6510 - 3s/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 3s - loss: 0.8646 - accuracy: 0.6578 - 3s/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 3s - loss: 0.8442 - accuracy: 0.6663 - 3s/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 3s - loss: 0.8241 - accuracy: 0.6752 - 3s/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 3s - loss: 0.8092 - accuracy: 0.6855 - 3s/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 3s - loss: 0.7996 - accuracy: 0.6870 - 3s/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 3s - loss: 0.7890 - accuracy: 0.6935 - 3s/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 3s - loss: 0.7859 - accuracy: 0.6953 - 3s/epoch - 6ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 3s - loss: 2.4759 - accuracy: 0.2976 - 3s/epoch - 7ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 3s - loss: 1.6644 - accuracy: 0.3524 - 3s/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 3s - loss: 1.4774 - accuracy: 0.3994 - 3s/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 3s - loss: 1.3672 - accuracy: 0.4380 - 3s/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 3s - loss: 1.2952 - accuracy: 0.4794 - 3s/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 3s - loss: 1.2286 - accuracy: 0.5121 - 3s/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 3s - loss: 1.1730 - accuracy: 0.5398 - 3s/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 3s - loss: 1.1121 - accuracy: 0.5731 - 3s/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 3s - loss: 1.0573 - accuracy: 0.5945 - 3s/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 3s - loss: 1.0172 - accuracy: 0.6118 - 3s/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 3s - loss: 0.9756 - accuracy: 0.6278 - 3s/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 3s - loss: 0.9464 - accuracy: 0.6344 - 3s/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 3s - loss: 0.9163 - accuracy: 0.6438 - 3s/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 3s - loss: 0.8947 - accuracy: 0.6497 - 3s/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 3s - loss: 0.8743 - accuracy: 0.6579 - 3s/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 3s - loss: 0.8512 - accuracy: 0.6667 - 3s/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 3s - loss: 0.8351 - accuracy: 0.6711 - 3s/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 3s - loss: 0.8127 - accuracy: 0.6789 - 3s/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 3s - loss: 0.7995 - accuracy: 0.6834 - 3s/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 3s - loss: 0.7842 - accuracy: 0.6894 - 3s/epoch - 6ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.4081 - accuracy: 0.4765 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8643 - accuracy: 0.6645 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7603 - accuracy: 0.7114 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.7171 - accuracy: 0.7362 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6738 - accuracy: 0.7554 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.6503 - accuracy: 0.7649 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.6302 - accuracy: 0.7774 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.6133 - accuracy: 0.7801 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5985 - accuracy: 0.7849 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5835 - accuracy: 0.7908 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5740 - accuracy: 0.7930 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5618 - accuracy: 0.7951 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5538 - accuracy: 0.7985 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5448 - accuracy: 0.8005 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5345 - accuracy: 0.8034 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5288 - accuracy: 0.8056 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.5248 - accuracy: 0.8084 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.5206 - accuracy: 0.8104 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.5159 - accuracy: 0.8089 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.5117 - accuracy: 0.8132 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.4075 - accuracy: 0.4687 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8425 - accuracy: 0.6733 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7329 - accuracy: 0.7265 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6782 - accuracy: 0.7562 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6564 - accuracy: 0.7650 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.6289 - accuracy: 0.7754 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.6121 - accuracy: 0.7824 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.6011 - accuracy: 0.7845 - 6s/epoch - 13ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5786 - accuracy: 0.7926 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5746 - accuracy: 0.7952 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5590 - accuracy: 0.7988 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5542 - accuracy: 0.8017 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5473 - accuracy: 0.8017 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5370 - accuracy: 0.8060 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5349 - accuracy: 0.8050 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5270 - accuracy: 0.8078 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.5230 - accuracy: 0.8094 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.5172 - accuracy: 0.8107 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.5140 - accuracy: 0.8136 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.5081 - accuracy: 0.8161 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.3080 - accuracy: 0.5191 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8079 - accuracy: 0.6848 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7168 - accuracy: 0.7323 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6743 - accuracy: 0.7549 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6397 - accuracy: 0.7722 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.6184 - accuracy: 0.7792 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.5976 - accuracy: 0.7873 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.5821 - accuracy: 0.7919 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5712 - accuracy: 0.7963 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5559 - accuracy: 0.8019 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5480 - accuracy: 0.8029 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5378 - accuracy: 0.8073 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5297 - accuracy: 0.8105 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5264 - accuracy: 0.8097 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5175 - accuracy: 0.8127 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5109 - accuracy: 0.8137 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.5101 - accuracy: 0.8119 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.4994 - accuracy: 0.8207 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.5010 - accuracy: 0.8189 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.4942 - accuracy: 0.8202 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.4222 - accuracy: 0.4602 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8694 - accuracy: 0.6599 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7616 - accuracy: 0.7136 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.7136 - accuracy: 0.7346 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6797 - accuracy: 0.7534 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.6563 - accuracy: 0.7630 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.6370 - accuracy: 0.7692 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.6195 - accuracy: 0.7782 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.6071 - accuracy: 0.7788 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5920 - accuracy: 0.7840 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5815 - accuracy: 0.7900 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5732 - accuracy: 0.7920 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5673 - accuracy: 0.7896 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5601 - accuracy: 0.7951 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5552 - accuracy: 0.7989 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5480 - accuracy: 0.7985 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.5412 - accuracy: 0.8018 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.5359 - accuracy: 0.8026 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.5311 - accuracy: 0.8043 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.5266 - accuracy: 0.8057 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 6s - loss: 1.3566 - accuracy: 0.5052 - 6s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 6s - loss: 0.8222 - accuracy: 0.6816 - 6s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 6s - loss: 0.7383 - accuracy: 0.7185 - 6s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 6s - loss: 0.6933 - accuracy: 0.7409 - 6s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 6s - loss: 0.6642 - accuracy: 0.7547 - 6s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 6s - loss: 0.6424 - accuracy: 0.7662 - 6s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 6s - loss: 0.6160 - accuracy: 0.7758 - 6s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 6s - loss: 0.6018 - accuracy: 0.7807 - 6s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 6s - loss: 0.5852 - accuracy: 0.7854 - 6s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 6s - loss: 0.5747 - accuracy: 0.7906 - 6s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 6s - loss: 0.5649 - accuracy: 0.7918 - 6s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 6s - loss: 0.5529 - accuracy: 0.7953 - 6s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 6s - loss: 0.5447 - accuracy: 0.8009 - 6s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 6s - loss: 0.5365 - accuracy: 0.8004 - 6s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 6s - loss: 0.5316 - accuracy: 0.8049 - 6s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 6s - loss: 0.5198 - accuracy: 0.8083 - 6s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 6s - loss: 0.5163 - accuracy: 0.8076 - 6s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 6s - loss: 0.5161 - accuracy: 0.8078 - 6s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 6s - loss: 0.5108 - accuracy: 0.8098 - 6s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 6s - loss: 0.5041 - accuracy: 0.8134 - 6s/epoch - 12ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 10s - loss: 1.2229 - accuracy: 0.5622 - 10s/epoch - 21ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 9s - loss: 0.6211 - accuracy: 0.7754 - 9s/epoch - 19ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: 0.5463 - accuracy: 0.8012 - 9s/epoch - 19ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 9s - loss: 0.5101 - accuracy: 0.8116 - 9s/epoch - 19ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 9s - loss: 0.4907 - accuracy: 0.8192 - 9s/epoch - 19ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 9s - loss: 0.4763 - accuracy: 0.8224 - 9s/epoch - 19ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: 0.4655 - accuracy: 0.8260 - 9s/epoch - 19ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 9s - loss: 0.4559 - accuracy: 0.8299 - 9s/epoch - 19ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 9s - loss: 0.4490 - accuracy: 0.8308 - 9s/epoch - 19ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 9s - loss: 0.4387 - accuracy: 0.8356 - 9s/epoch - 19ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: 0.4349 - accuracy: 0.8372 - 9s/epoch - 19ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: 0.4284 - accuracy: 0.8420 - 9s/epoch - 19ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 9s - loss: 0.4212 - accuracy: 0.8429 - 9s/epoch - 19ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 9s - loss: 0.4124 - accuracy: 0.8456 - 9s/epoch - 19ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 9s - loss: 0.4096 - accuracy: 0.8484 - 9s/epoch - 19ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 9s - loss: 0.4046 - accuracy: 0.8502 - 9s/epoch - 19ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 9s - loss: 0.3982 - accuracy: 0.8522 - 9s/epoch - 19ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 9s - loss: 0.3949 - accuracy: 0.8531 - 9s/epoch - 19ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 9s - loss: 0.3862 - accuracy: 0.8553 - 9s/epoch - 19ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 9s - loss: 0.3840 - accuracy: 0.8558 - 9s/epoch - 19ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 10s - loss: 1.0730 - accuracy: 0.6061 - 10s/epoch - 21ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 9s - loss: 0.6254 - accuracy: 0.7731 - 9s/epoch - 19ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: 0.5418 - accuracy: 0.8006 - 9s/epoch - 19ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 9s - loss: 0.6506 - accuracy: 0.7573 - 9s/epoch - 19ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 9s - loss: 0.5014 - accuracy: 0.8126 - 9s/epoch - 19ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 9s - loss: 0.4806 - accuracy: 0.8205 - 9s/epoch - 19ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: 0.4665 - accuracy: 0.8258 - 9s/epoch - 19ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 9s - loss: 0.4577 - accuracy: 0.8307 - 9s/epoch - 19ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 9s - loss: 0.4462 - accuracy: 0.8358 - 9s/epoch - 19ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 9s - loss: 0.4414 - accuracy: 0.8350 - 9s/epoch - 19ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: 0.4313 - accuracy: 0.8369 - 9s/epoch - 19ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: 0.4274 - accuracy: 0.8407 - 9s/epoch - 19ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 9s - loss: 0.4218 - accuracy: 0.8424 - 9s/epoch - 19ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 9s - loss: 0.4149 - accuracy: 0.8455 - 9s/epoch - 19ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 9s - loss: 0.4117 - accuracy: 0.8459 - 9s/epoch - 19ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 9s - loss: 0.4017 - accuracy: 0.8504 - 9s/epoch - 19ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 9s - loss: 0.4036 - accuracy: 0.8494 - 9s/epoch - 19ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 9s - loss: 0.3939 - accuracy: 0.8512 - 9s/epoch - 19ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 9s - loss: 0.3911 - accuracy: 0.8517 - 9s/epoch - 19ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 9s - loss: 0.3853 - accuracy: 0.8543 - 9s/epoch - 19ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 10s - loss: 1.1636 - accuracy: 0.5923 - 10s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 9s - loss: 0.6806 - accuracy: 0.7514 - 9s/epoch - 19ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: 0.5313 - accuracy: 0.8054 - 9s/epoch - 20ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 9s - loss: 0.4998 - accuracy: 0.8162 - 9s/epoch - 20ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 9s - loss: 0.4813 - accuracy: 0.8233 - 9s/epoch - 19ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 9s - loss: 0.4650 - accuracy: 0.8275 - 9s/epoch - 19ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: 0.4554 - accuracy: 0.8321 - 9s/epoch - 19ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 9s - loss: 0.4450 - accuracy: 0.8349 - 9s/epoch - 19ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 9s - loss: 0.4360 - accuracy: 0.8371 - 9s/epoch - 19ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 9s - loss: 0.4325 - accuracy: 0.8397 - 9s/epoch - 19ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: 0.4201 - accuracy: 0.8446 - 9s/epoch - 19ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: 0.4190 - accuracy: 0.8453 - 9s/epoch - 19ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 9s - loss: 0.4125 - accuracy: 0.8455 - 9s/epoch - 19ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 9s - loss: 0.4063 - accuracy: 0.8476 - 9s/epoch - 20ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 9s - loss: 0.4040 - accuracy: 0.8487 - 9s/epoch - 19ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 9s - loss: 0.3979 - accuracy: 0.8513 - 9s/epoch - 19ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 9s - loss: 0.3914 - accuracy: 0.8543 - 9s/epoch - 19ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 9s - loss: 0.3878 - accuracy: 0.8526 - 9s/epoch - 19ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 9s - loss: 0.3833 - accuracy: 0.8571 - 9s/epoch - 19ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 9s - loss: 0.3833 - accuracy: 0.8556 - 9s/epoch - 19ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1937 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 19ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.1919 - 9s/epoch - 18ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2034 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 9s - loss: nan - accuracy: 0.2021 - 9s/epoch - 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "5 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 236, in fit\n",
            "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
            "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
            "  File \"<ipython-input-28-815b79be4d16>\", line 7, in get_CNN_model\n",
            "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 629, in _method_wrapper\n",
            "    result = method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 305, in compute_output_shape\n",
            "    f'One of the dimensions in the output is <= 0 '\n",
            "ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_770. Consider increasing the input size. Received input shape [None, 6, 128] which would produce output shape with a zero or negative value in a dimension.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 236, in fit\n",
            "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
            "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
            "  File \"<ipython-input-28-815b79be4d16>\", line 7, in get_CNN_model\n",
            "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 629, in _method_wrapper\n",
            "    result = method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 305, in compute_output_shape\n",
            "    f'One of the dimensions in the output is <= 0 '\n",
            "ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_773. Consider increasing the input size. Received input shape [None, 6, 128] which would produce output shape with a zero or negative value in a dimension.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 236, in fit\n",
            "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
            "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
            "  File \"<ipython-input-28-815b79be4d16>\", line 7, in get_CNN_model\n",
            "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 629, in _method_wrapper\n",
            "    result = method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 305, in compute_output_shape\n",
            "    f'One of the dimensions in the output is <= 0 '\n",
            "ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_776. Consider increasing the input size. Received input shape [None, 6, 128] which would produce output shape with a zero or negative value in a dimension.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 236, in fit\n",
            "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
            "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
            "  File \"<ipython-input-28-815b79be4d16>\", line 7, in get_CNN_model\n",
            "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 629, in _method_wrapper\n",
            "    result = method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 305, in compute_output_shape\n",
            "    f'One of the dimensions in the output is <= 0 '\n",
            "ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_779. Consider increasing the input size. Received input shape [None, 6, 128] which would produce output shape with a zero or negative value in a dimension.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 236, in fit\n",
            "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
            "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
            "  File \"<ipython-input-28-815b79be4d16>\", line 7, in get_CNN_model\n",
            "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=conv_size, strides=1, activation='relu'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 629, in _method_wrapper\n",
            "    result = method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 305, in compute_output_shape\n",
            "    f'One of the dimensions in the output is <= 0 '\n",
            "ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_782. Consider increasing the input size. Received input shape [None, 6, 128] which would produce output shape with a zero or negative value in a dimension.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.63807429 0.78470977 0.72756022 0.79040916 0.77201477 0.76650177\n",
            " 0.70664631 0.73604503 0.5597393         nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "590/590 - 8s - loss: 1.1236 - accuracy: 0.5718 - 8s/epoch - 13ms/step\n",
            "Epoch 2/20\n",
            "590/590 - 7s - loss: 0.7592 - accuracy: 0.7183 - 7s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "590/590 - 7s - loss: 0.6619 - accuracy: 0.7577 - 7s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "590/590 - 7s - loss: 0.6105 - accuracy: 0.7740 - 7s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "590/590 - 7s - loss: 0.5834 - accuracy: 0.7856 - 7s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "590/590 - 7s - loss: 0.5613 - accuracy: 0.7912 - 7s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "590/590 - 7s - loss: 0.5482 - accuracy: 0.7977 - 7s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "590/590 - 7s - loss: 0.5345 - accuracy: 0.8026 - 7s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "590/590 - 7s - loss: 0.5319 - accuracy: 0.8012 - 7s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "590/590 - 7s - loss: 0.5178 - accuracy: 0.8091 - 7s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "590/590 - 7s - loss: 0.5082 - accuracy: 0.8119 - 7s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "590/590 - 7s - loss: 0.5005 - accuracy: 0.8154 - 7s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "590/590 - 7s - loss: 0.4960 - accuracy: 0.8159 - 7s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "590/590 - 7s - loss: 0.4857 - accuracy: 0.8178 - 7s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "590/590 - 7s - loss: 0.4787 - accuracy: 0.8210 - 7s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "590/590 - 7s - loss: 0.4739 - accuracy: 0.8219 - 7s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "590/590 - 7s - loss: 0.4756 - accuracy: 0.8213 - 7s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "590/590 - 7s - loss: 0.4654 - accuracy: 0.8229 - 7s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "590/590 - 7s - loss: 0.4634 - accuracy: 0.8268 - 7s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "590/590 - 7s - loss: 0.4582 - accuracy: 0.8283 - 7s/epoch - 12ms/step\n",
            "Best score is 0.79 using {'pool1_size': 16, 'learnRate': 0.01, 'k1_size': 25, 'epochs': 20, 'conv_size': 16, 'batch_size': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEST CNN MODEL BASED ON HYPERPARAMETER TUNING\n",
        "best_CNN = keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=25, strides=3, activation='relu', padding='same', input_shape=(3000,1)),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=16, strides =16, padding=\"same\"),\n",
        "        tf.keras.layers.Dropout(rate=0.5),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=8, strides=8, padding=\"same\"),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(rate=0.5),\n",
        "        tf.keras.layers.Dense(700),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "best_CNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OfrMq3LtXX3",
        "outputId": "7efe4226-4ec4-4bcf-d132-7bec2e905d4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 1000, 128)         3328      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 63, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 63, 128)           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 48, 128)           262272    \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 33, 128)           262272    \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 18, 128)           262272    \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 3, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 384)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 384)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 700)               269500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 3505      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,063,149\n",
            "Trainable params: 1,063,149\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best CNN\n",
        "sgd=keras.optimizers.SGD(learning_rate=0.01)\n",
        "best_CNN.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "best_CNN.fit(train_X, train_y, batch_size=64, epochs=20, verbose = 2)\n",
        "best_CNN.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WH9IG2EI0k9",
        "outputId": "cd4b4603-a587-4182-908f-f6ba617d5946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "590/590 - 8s - loss: 1.1505 - accuracy: 0.5624 - 8s/epoch - 14ms/step\n",
            "Epoch 2/20\n",
            "590/590 - 7s - loss: 0.7722 - accuracy: 0.7169 - 7s/epoch - 12ms/step\n",
            "Epoch 3/20\n",
            "590/590 - 7s - loss: 0.6710 - accuracy: 0.7536 - 7s/epoch - 12ms/step\n",
            "Epoch 4/20\n",
            "590/590 - 7s - loss: 0.6207 - accuracy: 0.7748 - 7s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "590/590 - 7s - loss: 0.5902 - accuracy: 0.7836 - 7s/epoch - 12ms/step\n",
            "Epoch 6/20\n",
            "590/590 - 7s - loss: 0.5678 - accuracy: 0.7926 - 7s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "590/590 - 7s - loss: 0.5511 - accuracy: 0.7962 - 7s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "590/590 - 7s - loss: 0.5330 - accuracy: 0.8041 - 7s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "590/590 - 7s - loss: 0.5235 - accuracy: 0.8062 - 7s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "590/590 - 7s - loss: 0.5185 - accuracy: 0.8065 - 7s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "590/590 - 7s - loss: 0.5063 - accuracy: 0.8112 - 7s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "590/590 - 7s - loss: 0.4990 - accuracy: 0.8151 - 7s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "590/590 - 7s - loss: 0.4934 - accuracy: 0.8165 - 7s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "590/590 - 7s - loss: 0.4919 - accuracy: 0.8200 - 7s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "590/590 - 7s - loss: 0.4843 - accuracy: 0.8210 - 7s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "590/590 - 7s - loss: 0.4769 - accuracy: 0.8242 - 7s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "590/590 - 7s - loss: 0.4733 - accuracy: 0.8238 - 7s/epoch - 12ms/step\n",
            "Epoch 18/20\n",
            "590/590 - 7s - loss: 0.4700 - accuracy: 0.8248 - 7s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "590/590 - 8s - loss: 0.4624 - accuracy: 0.8271 - 8s/epoch - 13ms/step\n",
            "Epoch 20/20\n",
            "590/590 - 7s - loss: 0.4601 - accuracy: 0.8264 - 7s/epoch - 12ms/step\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.8234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46764853596687317, 0.8234395384788513]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now run hyperparameter tuning for our CNN-LSTM model (2)"
      ],
      "metadata": {
        "id": "wvBdq2jdtepK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=50, strides=6, activation='relu', padding='same', input_shape=(3000,1)),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=8, strides =8, padding=\"same\"),\n",
        "        tf.keras.layers.Dropout(rate=0.5),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=8, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=8, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=8, strides=1, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=4, strides=4, padding=\"same\"),\n",
        "        tf.keras.layers.Dropout(rate=0.5),\n",
        "        tf.keras.layers.RNN(keras.layers.LSTMCell(128)),\n",
        "        tf.keras.layers.Dropout(rate=0.5),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "  ])"
      ],
      "metadata": {
        "id": "xQ8KIKZ6XZ5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build function for CNN-LSTM\n",
        "def build_CNN_LSTM(num_cells=128, dropout=0.5, learnRate=0.1):\n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=25, strides=3, activation='relu', padding='same', input_shape=(3000,1)))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(pool_size=16, strides =16, padding=\"same\"))\n",
        "  model.add(tf.keras.layers.Dropout(rate=dropout))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling1D(pool_size=8, strides=8, padding=\"same\"))\n",
        "  model.add(tf.keras.layers.Dropout(rate=dropout))\n",
        "  model.add(tf.keras.layers.RNN(keras.layers.LSTMCell(num_cells)))\n",
        "  model.add(tf.keras.layers.Dropout(rate=dropout))\n",
        "  model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "  sgd=keras.optimizers.SGD(learning_rate=learnRate)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "6cx8BEl87YtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier and grid to search over\n",
        "model = KerasClassifier(build_fn=build_CNN_LSTM, verbose=2)\n",
        "\n",
        "num_cells = [64, 128, 256]\n",
        "dropout = [0.3, 0.4, 0.5]\n",
        "learnRate = [1e-2, 1e-3, 1e-4]\n",
        "batchSize=[64]\n",
        "epochs=[20]\n",
        "\n",
        "grid = {\n",
        "    \"num_cells\": num_cells,\n",
        "    \"dropout\": dropout,\n",
        "    \"learnRate\": learnRate,\n",
        "    \"batch_size\": batchSize,\n",
        "    \"epochs\": epochs\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a14Gzckd8kyt",
        "outputId": "1b70f26a-43a2-434b-c91f-bf596c48e146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run randomized CV search\n",
        "searcher = RandomizedSearchCV(estimator=model, cv=5, param_distributions=grid, scoring='accuracy')\n",
        "searchResults = searcher.fit(train_X, np.argmax(train_y.numpy(), axis=1))\n",
        "\n",
        "bestScore = searchResults.best_score_\n",
        "bestParams = searchResults.best_params_\n",
        "print(\"Best score is {:.2f} using {}\".format(bestScore,\tbestParams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft9K--wf857P",
        "outputId": "a037afb9-d486-410f-a293-e015dfef7ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0516 - accuracy: 0.5909 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7388 - accuracy: 0.7289 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6611 - accuracy: 0.7588 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6113 - accuracy: 0.7765 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5767 - accuracy: 0.7872 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5594 - accuracy: 0.7944 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5362 - accuracy: 0.8026 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5247 - accuracy: 0.8052 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5115 - accuracy: 0.8100 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5015 - accuracy: 0.8130 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.4914 - accuracy: 0.8159 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4810 - accuracy: 0.8188 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4735 - accuracy: 0.8242 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 0.4640 - accuracy: 0.8269 - 8s/epoch - 17ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4577 - accuracy: 0.8290 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4515 - accuracy: 0.8314 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 9s - loss: 0.4456 - accuracy: 0.8353 - 9s/epoch - 19ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4386 - accuracy: 0.8365 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4330 - accuracy: 0.8385 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4284 - accuracy: 0.8403 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0917 - accuracy: 0.5705 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7481 - accuracy: 0.7241 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6481 - accuracy: 0.7621 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.5996 - accuracy: 0.7815 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 8s - loss: 0.5698 - accuracy: 0.7903 - 8s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5461 - accuracy: 0.7976 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5359 - accuracy: 0.8031 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5274 - accuracy: 0.8057 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5097 - accuracy: 0.8107 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.4996 - accuracy: 0.8154 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.4912 - accuracy: 0.8174 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4893 - accuracy: 0.8197 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4729 - accuracy: 0.8256 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4667 - accuracy: 0.8260 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4608 - accuracy: 0.8295 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4562 - accuracy: 0.8311 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4546 - accuracy: 0.8316 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4469 - accuracy: 0.8339 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4345 - accuracy: 0.8375 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4337 - accuracy: 0.8363 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0150 - accuracy: 0.6046 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.6906 - accuracy: 0.7487 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6160 - accuracy: 0.7755 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.5795 - accuracy: 0.7894 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5458 - accuracy: 0.8010 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5246 - accuracy: 0.8087 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5130 - accuracy: 0.8105 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.4942 - accuracy: 0.8177 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.4882 - accuracy: 0.8213 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.4780 - accuracy: 0.8234 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: 0.4693 - accuracy: 0.8269 - 9s/epoch - 18ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4620 - accuracy: 0.8296 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4521 - accuracy: 0.8337 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4485 - accuracy: 0.8331 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4445 - accuracy: 0.8342 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4376 - accuracy: 0.8377 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4275 - accuracy: 0.8427 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4277 - accuracy: 0.8409 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4251 - accuracy: 0.8421 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4157 - accuracy: 0.8458 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0699 - accuracy: 0.5734 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7605 - accuracy: 0.7153 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6724 - accuracy: 0.7500 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6221 - accuracy: 0.7711 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5887 - accuracy: 0.7808 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5665 - accuracy: 0.7889 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5537 - accuracy: 0.7934 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5340 - accuracy: 0.7997 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5183 - accuracy: 0.8038 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5098 - accuracy: 0.8118 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.5010 - accuracy: 0.8142 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4911 - accuracy: 0.8178 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4857 - accuracy: 0.8188 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4794 - accuracy: 0.8197 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4701 - accuracy: 0.8237 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4664 - accuracy: 0.8254 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4595 - accuracy: 0.8271 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 0.4514 - accuracy: 0.8311 - 8s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 8s - loss: 0.4497 - accuracy: 0.8320 - 8s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 8s - loss: 0.4462 - accuracy: 0.8322 - 8s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0814 - accuracy: 0.5717 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7788 - accuracy: 0.7084 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6633 - accuracy: 0.7531 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6145 - accuracy: 0.7745 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5881 - accuracy: 0.7816 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5585 - accuracy: 0.7925 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5453 - accuracy: 0.7970 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5218 - accuracy: 0.8062 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5114 - accuracy: 0.8078 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5009 - accuracy: 0.8122 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.4882 - accuracy: 0.8175 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: 0.4845 - accuracy: 0.8161 - 9s/epoch - 19ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4736 - accuracy: 0.8221 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4706 - accuracy: 0.8234 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4643 - accuracy: 0.8240 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4600 - accuracy: 0.8250 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4493 - accuracy: 0.8303 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4404 - accuracy: 0.8334 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4393 - accuracy: 0.8357 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4352 - accuracy: 0.8366 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4921 - accuracy: 0.4005 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4448 - accuracy: 0.4072 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 1.4245 - accuracy: 0.4137 - 8s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4111 - accuracy: 0.4159 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3960 - accuracy: 0.4171 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3849 - accuracy: 0.4247 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3713 - accuracy: 0.4284 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3611 - accuracy: 0.4306 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.3450 - accuracy: 0.4405 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.3302 - accuracy: 0.4460 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.3107 - accuracy: 0.4552 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2951 - accuracy: 0.4639 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 8s - loss: 1.2711 - accuracy: 0.4790 - 8s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.2418 - accuracy: 0.4941 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.2081 - accuracy: 0.5125 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1789 - accuracy: 0.5312 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.1415 - accuracy: 0.5542 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.1046 - accuracy: 0.5754 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0694 - accuracy: 0.5935 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0315 - accuracy: 0.6128 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5255 - accuracy: 0.3737 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4721 - accuracy: 0.4020 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4484 - accuracy: 0.4074 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4323 - accuracy: 0.4122 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4141 - accuracy: 0.4177 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3989 - accuracy: 0.4201 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3835 - accuracy: 0.4262 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3667 - accuracy: 0.4307 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.3450 - accuracy: 0.4420 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.3283 - accuracy: 0.4508 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.3041 - accuracy: 0.4625 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2814 - accuracy: 0.4747 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.2623 - accuracy: 0.4870 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 8s - loss: 1.2380 - accuracy: 0.5006 - 8s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.2151 - accuracy: 0.5120 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1895 - accuracy: 0.5272 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.1619 - accuracy: 0.5414 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.1340 - accuracy: 0.5575 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.1071 - accuracy: 0.5744 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0740 - accuracy: 0.5926 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5320 - accuracy: 0.3503 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 1.4628 - accuracy: 0.3975 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4400 - accuracy: 0.4065 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4145 - accuracy: 0.4159 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3920 - accuracy: 0.4269 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3671 - accuracy: 0.4382 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3313 - accuracy: 0.4570 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3004 - accuracy: 0.4735 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.2588 - accuracy: 0.4960 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2216 - accuracy: 0.5189 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.1851 - accuracy: 0.5332 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.1473 - accuracy: 0.5561 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.1065 - accuracy: 0.5786 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.0718 - accuracy: 0.5944 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.0354 - accuracy: 0.6136 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.9997 - accuracy: 0.6303 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.9718 - accuracy: 0.6368 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.9394 - accuracy: 0.6491 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.9134 - accuracy: 0.6605 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.8938 - accuracy: 0.6651 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5026 - accuracy: 0.3783 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4544 - accuracy: 0.4016 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4352 - accuracy: 0.4064 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4128 - accuracy: 0.4147 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3908 - accuracy: 0.4232 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3695 - accuracy: 0.4306 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3430 - accuracy: 0.4410 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3192 - accuracy: 0.4570 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.2961 - accuracy: 0.4677 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2700 - accuracy: 0.4783 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.2502 - accuracy: 0.4904 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2292 - accuracy: 0.4983 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.2095 - accuracy: 0.5060 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.1895 - accuracy: 0.5168 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.1705 - accuracy: 0.5248 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1495 - accuracy: 0.5328 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.1256 - accuracy: 0.5450 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.1056 - accuracy: 0.5588 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0800 - accuracy: 0.5702 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0557 - accuracy: 0.5831 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5104 - accuracy: 0.3642 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4473 - accuracy: 0.4080 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4276 - accuracy: 0.4164 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4114 - accuracy: 0.4175 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3955 - accuracy: 0.4257 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3793 - accuracy: 0.4325 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: 1.3612 - accuracy: 0.4381 - 9s/epoch - 19ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3392 - accuracy: 0.4499 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.3141 - accuracy: 0.4644 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2839 - accuracy: 0.4835 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.2524 - accuracy: 0.5024 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2200 - accuracy: 0.5212 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.1793 - accuracy: 0.5450 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.1480 - accuracy: 0.5626 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.1137 - accuracy: 0.5798 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.0869 - accuracy: 0.5936 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.0568 - accuracy: 0.6058 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.0305 - accuracy: 0.6158 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0072 - accuracy: 0.6246 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.9834 - accuracy: 0.6315 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4100 - accuracy: 0.4125 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.2123 - accuracy: 0.5178 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.9713 - accuracy: 0.6413 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8460 - accuracy: 0.6893 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7884 - accuracy: 0.7109 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7514 - accuracy: 0.7274 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7224 - accuracy: 0.7403 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7060 - accuracy: 0.7447 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6891 - accuracy: 0.7501 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6830 - accuracy: 0.7552 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6704 - accuracy: 0.7578 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6602 - accuracy: 0.7607 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6517 - accuracy: 0.7645 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6465 - accuracy: 0.7656 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6355 - accuracy: 0.7735 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6330 - accuracy: 0.7715 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6237 - accuracy: 0.7752 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6168 - accuracy: 0.7767 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6142 - accuracy: 0.7786 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6031 - accuracy: 0.7837 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4087 - accuracy: 0.4147 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 1.1490 - accuracy: 0.5481 - 8s/epoch - 17ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.9202 - accuracy: 0.6569 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8118 - accuracy: 0.7061 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7522 - accuracy: 0.7334 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7212 - accuracy: 0.7415 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.6919 - accuracy: 0.7557 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6817 - accuracy: 0.7570 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6599 - accuracy: 0.7639 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6521 - accuracy: 0.7700 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6378 - accuracy: 0.7725 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6300 - accuracy: 0.7751 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6230 - accuracy: 0.7773 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6120 - accuracy: 0.7808 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6065 - accuracy: 0.7831 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6022 - accuracy: 0.7858 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5954 - accuracy: 0.7873 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5881 - accuracy: 0.7901 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5842 - accuracy: 0.7911 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5756 - accuracy: 0.7934 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3696 - accuracy: 0.4346 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.0550 - accuracy: 0.6000 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.8554 - accuracy: 0.6902 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.7712 - accuracy: 0.7226 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7258 - accuracy: 0.7408 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.6917 - accuracy: 0.7539 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.6688 - accuracy: 0.7617 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6500 - accuracy: 0.7665 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6374 - accuracy: 0.7723 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6251 - accuracy: 0.7768 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6158 - accuracy: 0.7800 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6057 - accuracy: 0.7842 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.5969 - accuracy: 0.7857 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.5905 - accuracy: 0.7897 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.5823 - accuracy: 0.7896 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.5768 - accuracy: 0.7943 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5710 - accuracy: 0.7960 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5648 - accuracy: 0.7979 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5644 - accuracy: 0.7990 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5538 - accuracy: 0.8013 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 8s - loss: 1.4250 - accuracy: 0.4028 - 8s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.2506 - accuracy: 0.4833 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0130 - accuracy: 0.6223 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8591 - accuracy: 0.6891 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7879 - accuracy: 0.7156 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7467 - accuracy: 0.7327 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7227 - accuracy: 0.7408 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 9s - loss: 0.7068 - accuracy: 0.7472 - 9s/epoch - 18ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6909 - accuracy: 0.7517 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6762 - accuracy: 0.7585 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6646 - accuracy: 0.7623 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6555 - accuracy: 0.7658 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6514 - accuracy: 0.7670 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6407 - accuracy: 0.7696 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6278 - accuracy: 0.7762 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6250 - accuracy: 0.7765 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6180 - accuracy: 0.7805 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6100 - accuracy: 0.7828 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6148 - accuracy: 0.7820 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6066 - accuracy: 0.7833 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3908 - accuracy: 0.4289 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.1464 - accuracy: 0.5579 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.9396 - accuracy: 0.6549 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8303 - accuracy: 0.6904 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7658 - accuracy: 0.7164 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7314 - accuracy: 0.7321 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7076 - accuracy: 0.7415 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6904 - accuracy: 0.7496 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6752 - accuracy: 0.7530 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6633 - accuracy: 0.7597 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6507 - accuracy: 0.7639 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6405 - accuracy: 0.7681 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6325 - accuracy: 0.7725 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6227 - accuracy: 0.7755 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6158 - accuracy: 0.7766 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6125 - accuracy: 0.7793 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6016 - accuracy: 0.7815 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5940 - accuracy: 0.7870 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5931 - accuracy: 0.7842 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5836 - accuracy: 0.7877 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4730 - accuracy: 0.3859 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.2983 - accuracy: 0.4627 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0939 - accuracy: 0.5752 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9169 - accuracy: 0.6524 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8203 - accuracy: 0.6898 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7720 - accuracy: 0.7110 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7437 - accuracy: 0.7270 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7292 - accuracy: 0.7313 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7154 - accuracy: 0.7369 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6983 - accuracy: 0.7442 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6906 - accuracy: 0.7458 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 9s - loss: 0.6800 - accuracy: 0.7500 - 9s/epoch - 18ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6781 - accuracy: 0.7508 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6685 - accuracy: 0.7558 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6614 - accuracy: 0.7574 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6580 - accuracy: 0.7616 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6493 - accuracy: 0.7614 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6424 - accuracy: 0.7654 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6368 - accuracy: 0.7668 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6308 - accuracy: 0.7711 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4691 - accuracy: 0.3892 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.3488 - accuracy: 0.4434 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.2001 - accuracy: 0.5163 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.0069 - accuracy: 0.6153 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8637 - accuracy: 0.6732 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7867 - accuracy: 0.7067 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7501 - accuracy: 0.7248 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7269 - accuracy: 0.7372 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7114 - accuracy: 0.7402 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6934 - accuracy: 0.7482 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6799 - accuracy: 0.7554 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6730 - accuracy: 0.7578 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6606 - accuracy: 0.7607 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6542 - accuracy: 0.7648 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6421 - accuracy: 0.7680 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6343 - accuracy: 0.7735 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6335 - accuracy: 0.7716 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6255 - accuracy: 0.7747 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6238 - accuracy: 0.7738 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6129 - accuracy: 0.7791 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4689 - accuracy: 0.3889 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.2607 - accuracy: 0.5054 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0257 - accuracy: 0.6063 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8817 - accuracy: 0.6604 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7931 - accuracy: 0.6981 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7416 - accuracy: 0.7220 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7137 - accuracy: 0.7370 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6930 - accuracy: 0.7462 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6770 - accuracy: 0.7536 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6659 - accuracy: 0.7566 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6591 - accuracy: 0.7618 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6410 - accuracy: 0.7670 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6361 - accuracy: 0.7686 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6287 - accuracy: 0.7713 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6205 - accuracy: 0.7750 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6097 - accuracy: 0.7789 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6100 - accuracy: 0.7794 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6051 - accuracy: 0.7811 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5981 - accuracy: 0.7833 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5925 - accuracy: 0.7893 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4772 - accuracy: 0.3817 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.3397 - accuracy: 0.4402 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.1574 - accuracy: 0.5318 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9605 - accuracy: 0.6300 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8454 - accuracy: 0.6780 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7982 - accuracy: 0.6964 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7693 - accuracy: 0.7073 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7497 - accuracy: 0.7220 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7355 - accuracy: 0.7268 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.7184 - accuracy: 0.7345 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.7100 - accuracy: 0.7387 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6973 - accuracy: 0.7435 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6927 - accuracy: 0.7438 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6829 - accuracy: 0.7511 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6700 - accuracy: 0.7540 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6689 - accuracy: 0.7557 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6649 - accuracy: 0.7554 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6540 - accuracy: 0.7611 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6517 - accuracy: 0.7611 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6460 - accuracy: 0.7649 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4486 - accuracy: 0.4027 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.3211 - accuracy: 0.4634 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0881 - accuracy: 0.5878 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9068 - accuracy: 0.6526 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8201 - accuracy: 0.6832 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7740 - accuracy: 0.7044 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7480 - accuracy: 0.7191 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7216 - accuracy: 0.7290 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7124 - accuracy: 0.7321 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.7003 - accuracy: 0.7377 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6919 - accuracy: 0.7388 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6819 - accuracy: 0.7448 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6751 - accuracy: 0.7462 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6679 - accuracy: 0.7499 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6659 - accuracy: 0.7506 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6562 - accuracy: 0.7572 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6488 - accuracy: 0.7578 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6383 - accuracy: 0.7637 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6384 - accuracy: 0.7628 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6356 - accuracy: 0.7651 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5033 - accuracy: 0.3543 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4397 - accuracy: 0.4024 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4169 - accuracy: 0.4138 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.3987 - accuracy: 0.4187 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3786 - accuracy: 0.4242 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3642 - accuracy: 0.4293 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3458 - accuracy: 0.4352 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3337 - accuracy: 0.4418 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.3154 - accuracy: 0.4481 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2958 - accuracy: 0.4595 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.2769 - accuracy: 0.4676 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2525 - accuracy: 0.4834 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.2312 - accuracy: 0.4966 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.2040 - accuracy: 0.5175 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.1779 - accuracy: 0.5300 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1511 - accuracy: 0.5460 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.1243 - accuracy: 0.5633 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.0945 - accuracy: 0.5775 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0621 - accuracy: 0.5972 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0321 - accuracy: 0.6085 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4757 - accuracy: 0.3954 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4308 - accuracy: 0.4134 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4088 - accuracy: 0.4194 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.3805 - accuracy: 0.4313 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3608 - accuracy: 0.4357 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3363 - accuracy: 0.4445 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3085 - accuracy: 0.4571 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.2783 - accuracy: 0.4752 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.2494 - accuracy: 0.4925 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2180 - accuracy: 0.5056 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.1847 - accuracy: 0.5256 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.1485 - accuracy: 0.5474 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.1165 - accuracy: 0.5645 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.0790 - accuracy: 0.5872 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.0435 - accuracy: 0.6049 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.0121 - accuracy: 0.6161 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.9813 - accuracy: 0.6284 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.9529 - accuracy: 0.6384 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.9262 - accuracy: 0.6499 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.9013 - accuracy: 0.6569 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4922 - accuracy: 0.3793 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4376 - accuracy: 0.4059 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: 1.4108 - accuracy: 0.4161 - 9s/epoch - 18ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.3917 - accuracy: 0.4259 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3732 - accuracy: 0.4324 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3536 - accuracy: 0.4416 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3322 - accuracy: 0.4491 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.3114 - accuracy: 0.4613 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.2839 - accuracy: 0.4759 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2527 - accuracy: 0.4939 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.2204 - accuracy: 0.5101 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.1905 - accuracy: 0.5313 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.1510 - accuracy: 0.5550 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.1230 - accuracy: 0.5702 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.0896 - accuracy: 0.5842 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.0586 - accuracy: 0.6031 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.0321 - accuracy: 0.6116 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.0024 - accuracy: 0.6274 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.9740 - accuracy: 0.6382 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.9484 - accuracy: 0.6449 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4856 - accuracy: 0.3584 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 1.4259 - accuracy: 0.4100 - 8s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.3966 - accuracy: 0.4199 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.3696 - accuracy: 0.4317 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3504 - accuracy: 0.4394 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3302 - accuracy: 0.4470 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3045 - accuracy: 0.4608 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.2857 - accuracy: 0.4690 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.2637 - accuracy: 0.4777 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2469 - accuracy: 0.4853 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.2235 - accuracy: 0.4940 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2003 - accuracy: 0.5060 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.1843 - accuracy: 0.5092 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.1637 - accuracy: 0.5205 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.1456 - accuracy: 0.5297 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1218 - accuracy: 0.5443 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.0998 - accuracy: 0.5557 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.0773 - accuracy: 0.5676 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0518 - accuracy: 0.5859 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0250 - accuracy: 0.6003 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5090 - accuracy: 0.3801 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4416 - accuracy: 0.4134 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4142 - accuracy: 0.4220 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.3919 - accuracy: 0.4276 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.3727 - accuracy: 0.4364 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.3580 - accuracy: 0.4392 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.3305 - accuracy: 0.4497 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 8s - loss: 1.3098 - accuracy: 0.4604 - 8s/epoch - 18ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.2843 - accuracy: 0.4720 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.2600 - accuracy: 0.4844 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.2355 - accuracy: 0.4951 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.2146 - accuracy: 0.5013 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.1928 - accuracy: 0.5133 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.1694 - accuracy: 0.5219 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.1498 - accuracy: 0.5316 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1271 - accuracy: 0.5444 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.1058 - accuracy: 0.5595 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.0794 - accuracy: 0.5744 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0437 - accuracy: 0.5962 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0179 - accuracy: 0.6100 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3823 - accuracy: 0.4266 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.1874 - accuracy: 0.5161 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.9629 - accuracy: 0.6292 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8184 - accuracy: 0.6867 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7559 - accuracy: 0.7138 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7058 - accuracy: 0.7389 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.6839 - accuracy: 0.7472 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6609 - accuracy: 0.7583 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6480 - accuracy: 0.7638 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6348 - accuracy: 0.7669 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6235 - accuracy: 0.7711 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6155 - accuracy: 0.7753 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6077 - accuracy: 0.7776 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6003 - accuracy: 0.7809 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.5872 - accuracy: 0.7853 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.5816 - accuracy: 0.7876 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5812 - accuracy: 0.7885 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5697 - accuracy: 0.7933 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5629 - accuracy: 0.7935 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5589 - accuracy: 0.7956 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3720 - accuracy: 0.4339 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.1048 - accuracy: 0.5707 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.8548 - accuracy: 0.6735 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.7442 - accuracy: 0.7224 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.6932 - accuracy: 0.7464 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.6674 - accuracy: 0.7564 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 9s - loss: 0.6432 - accuracy: 0.7661 - 9s/epoch - 18ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6315 - accuracy: 0.7683 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6166 - accuracy: 0.7764 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6065 - accuracy: 0.7795 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.5941 - accuracy: 0.7829 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.5894 - accuracy: 0.7868 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.5852 - accuracy: 0.7862 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.5772 - accuracy: 0.7876 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.5724 - accuracy: 0.7916 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.5645 - accuracy: 0.7947 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5589 - accuracy: 0.7970 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5542 - accuracy: 0.7990 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5530 - accuracy: 0.7970 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5505 - accuracy: 0.7993 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3733 - accuracy: 0.4322 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.1181 - accuracy: 0.5661 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.8872 - accuracy: 0.6540 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.7677 - accuracy: 0.7070 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.6988 - accuracy: 0.7396 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.6572 - accuracy: 0.7591 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.6323 - accuracy: 0.7691 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6146 - accuracy: 0.7756 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6016 - accuracy: 0.7788 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5906 - accuracy: 0.7855 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.5805 - accuracy: 0.7871 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.5734 - accuracy: 0.7937 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.5663 - accuracy: 0.7942 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.5599 - accuracy: 0.7956 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.5529 - accuracy: 0.7993 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.5479 - accuracy: 0.7994 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5462 - accuracy: 0.8014 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5406 - accuracy: 0.8041 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5364 - accuracy: 0.8052 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5327 - accuracy: 0.8064 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3932 - accuracy: 0.4246 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.1868 - accuracy: 0.5143 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.9755 - accuracy: 0.6195 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.8188 - accuracy: 0.6870 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7503 - accuracy: 0.7164 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7083 - accuracy: 0.7356 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.6879 - accuracy: 0.7448 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6707 - accuracy: 0.7526 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6533 - accuracy: 0.7585 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6464 - accuracy: 0.7613 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6354 - accuracy: 0.7642 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6309 - accuracy: 0.7653 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6225 - accuracy: 0.7716 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 9s - loss: 0.6132 - accuracy: 0.7721 - 9s/epoch - 18ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6089 - accuracy: 0.7760 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6025 - accuracy: 0.7787 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5986 - accuracy: 0.7809 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5900 - accuracy: 0.7828 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5885 - accuracy: 0.7833 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5832 - accuracy: 0.7847 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.3713 - accuracy: 0.4335 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.1368 - accuracy: 0.5541 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.8948 - accuracy: 0.6615 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.7803 - accuracy: 0.7047 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.7204 - accuracy: 0.7277 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.6939 - accuracy: 0.7401 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.6678 - accuracy: 0.7507 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.6574 - accuracy: 0.7537 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.6446 - accuracy: 0.7587 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6332 - accuracy: 0.7633 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6226 - accuracy: 0.7677 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6160 - accuracy: 0.7733 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6089 - accuracy: 0.7727 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6010 - accuracy: 0.7773 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.5922 - accuracy: 0.7821 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.5879 - accuracy: 0.7836 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.5763 - accuracy: 0.7888 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.5724 - accuracy: 0.7878 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.5656 - accuracy: 0.7913 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.5585 - accuracy: 0.7932 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5231 - accuracy: 0.3696 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4886 - accuracy: 0.3945 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4726 - accuracy: 0.4016 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4680 - accuracy: 0.4012 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4538 - accuracy: 0.4044 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4418 - accuracy: 0.4102 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4376 - accuracy: 0.4080 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4290 - accuracy: 0.4122 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4198 - accuracy: 0.4159 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.4102 - accuracy: 0.4193 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.3947 - accuracy: 0.4236 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3794 - accuracy: 0.4316 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3618 - accuracy: 0.4386 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3395 - accuracy: 0.4511 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3137 - accuracy: 0.4667 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.2886 - accuracy: 0.4805 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.2526 - accuracy: 0.5047 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.2243 - accuracy: 0.5247 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.1886 - accuracy: 0.5476 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.1601 - accuracy: 0.5646 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5600 - accuracy: 0.3260 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5031 - accuracy: 0.3753 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4899 - accuracy: 0.3819 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4731 - accuracy: 0.3922 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4660 - accuracy: 0.3906 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4572 - accuracy: 0.3970 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4444 - accuracy: 0.4029 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4368 - accuracy: 0.4068 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4284 - accuracy: 0.4062 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.4228 - accuracy: 0.4114 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.4151 - accuracy: 0.4144 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.4085 - accuracy: 0.4136 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.4003 - accuracy: 0.4174 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3978 - accuracy: 0.4178 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3862 - accuracy: 0.4222 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.3794 - accuracy: 0.4248 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.3660 - accuracy: 0.4307 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.3582 - accuracy: 0.4290 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.3425 - accuracy: 0.4377 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.3230 - accuracy: 0.4510 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5535 - accuracy: 0.3339 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5078 - accuracy: 0.3729 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4920 - accuracy: 0.3817 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4725 - accuracy: 0.3884 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4603 - accuracy: 0.3974 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4490 - accuracy: 0.4002 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4357 - accuracy: 0.4088 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4161 - accuracy: 0.4163 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.3967 - accuracy: 0.4273 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.3760 - accuracy: 0.4335 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.3461 - accuracy: 0.4511 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3173 - accuracy: 0.4709 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.2840 - accuracy: 0.4914 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.2485 - accuracy: 0.5151 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.2180 - accuracy: 0.5351 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.1819 - accuracy: 0.5526 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.1565 - accuracy: 0.5694 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.1291 - accuracy: 0.5822 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.0994 - accuracy: 0.5923 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.0775 - accuracy: 0.5986 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.6004 - accuracy: 0.2867 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5271 - accuracy: 0.3664 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 9s - loss: 1.5030 - accuracy: 0.3784 - 9s/epoch - 18ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4808 - accuracy: 0.3878 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4650 - accuracy: 0.3964 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4493 - accuracy: 0.4018 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4327 - accuracy: 0.4063 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4164 - accuracy: 0.4134 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.3973 - accuracy: 0.4203 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.3769 - accuracy: 0.4329 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.3600 - accuracy: 0.4362 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3333 - accuracy: 0.4535 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3170 - accuracy: 0.4609 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3010 - accuracy: 0.4654 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.2866 - accuracy: 0.4728 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.2666 - accuracy: 0.4812 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.2503 - accuracy: 0.4893 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.2380 - accuracy: 0.4977 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.2223 - accuracy: 0.5058 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.2037 - accuracy: 0.5125 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5517 - accuracy: 0.3458 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.4980 - accuracy: 0.3944 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4835 - accuracy: 0.3973 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4706 - accuracy: 0.3981 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4583 - accuracy: 0.4048 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4449 - accuracy: 0.4079 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4315 - accuracy: 0.4098 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4203 - accuracy: 0.4126 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4100 - accuracy: 0.4151 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.3958 - accuracy: 0.4199 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.3796 - accuracy: 0.4281 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3617 - accuracy: 0.4330 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3454 - accuracy: 0.4395 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3297 - accuracy: 0.4469 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3089 - accuracy: 0.4572 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.2877 - accuracy: 0.4697 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.2727 - accuracy: 0.4774 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 8s - loss: 1.2555 - accuracy: 0.4842 - 8s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.2372 - accuracy: 0.4943 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.2167 - accuracy: 0.5084 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5539 - accuracy: 0.3466 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5180 - accuracy: 0.3738 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4912 - accuracy: 0.3820 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4835 - accuracy: 0.3853 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4753 - accuracy: 0.3884 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4620 - accuracy: 0.3944 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4545 - accuracy: 0.3966 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4428 - accuracy: 0.4014 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4331 - accuracy: 0.4047 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.4183 - accuracy: 0.4085 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: 1.4130 - accuracy: 0.4100 - 9s/epoch - 18ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3974 - accuracy: 0.4175 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3860 - accuracy: 0.4235 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3736 - accuracy: 0.4288 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3552 - accuracy: 0.4376 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.3367 - accuracy: 0.4403 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.3263 - accuracy: 0.4509 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.3062 - accuracy: 0.4620 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.2945 - accuracy: 0.4677 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.2768 - accuracy: 0.4776 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5756 - accuracy: 0.3207 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5177 - accuracy: 0.3648 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.5017 - accuracy: 0.3744 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4848 - accuracy: 0.3825 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4737 - accuracy: 0.3849 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4574 - accuracy: 0.3935 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4499 - accuracy: 0.3955 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4363 - accuracy: 0.4016 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4302 - accuracy: 0.4048 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.4144 - accuracy: 0.4117 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.4064 - accuracy: 0.4176 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3907 - accuracy: 0.4201 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3763 - accuracy: 0.4282 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3608 - accuracy: 0.4341 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3426 - accuracy: 0.4416 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.3266 - accuracy: 0.4497 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.3064 - accuracy: 0.4625 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.2863 - accuracy: 0.4714 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.2617 - accuracy: 0.4875 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.2361 - accuracy: 0.4985 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.6073 - accuracy: 0.3098 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 1.5394 - accuracy: 0.3693 - 8s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.5130 - accuracy: 0.3782 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4968 - accuracy: 0.3851 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4796 - accuracy: 0.3890 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4614 - accuracy: 0.4015 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4489 - accuracy: 0.4028 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4286 - accuracy: 0.4124 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4131 - accuracy: 0.4193 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.3941 - accuracy: 0.4263 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 9s - loss: 1.3724 - accuracy: 0.4344 - 9s/epoch - 19ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.3524 - accuracy: 0.4497 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3228 - accuracy: 0.4636 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.2959 - accuracy: 0.4805 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.2645 - accuracy: 0.5067 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.2307 - accuracy: 0.5240 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.2021 - accuracy: 0.5407 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.1689 - accuracy: 0.5552 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.1399 - accuracy: 0.5742 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.1130 - accuracy: 0.5882 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5894 - accuracy: 0.2997 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5285 - accuracy: 0.3599 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.5151 - accuracy: 0.3700 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.5034 - accuracy: 0.3747 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4875 - accuracy: 0.3802 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4823 - accuracy: 0.3824 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4729 - accuracy: 0.3896 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4589 - accuracy: 0.3908 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4534 - accuracy: 0.3900 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.4491 - accuracy: 0.3942 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.4389 - accuracy: 0.3951 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.4305 - accuracy: 0.4049 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.4230 - accuracy: 0.4049 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.4080 - accuracy: 0.4092 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3971 - accuracy: 0.4104 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.3860 - accuracy: 0.4157 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.3701 - accuracy: 0.4247 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 1.3589 - accuracy: 0.4269 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.3360 - accuracy: 0.4402 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.3199 - accuracy: 0.4477 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.5650 - accuracy: 0.3234 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.5129 - accuracy: 0.3695 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.4995 - accuracy: 0.3827 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 1.4870 - accuracy: 0.3880 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 1.4802 - accuracy: 0.3907 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 1.4678 - accuracy: 0.3987 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 1.4599 - accuracy: 0.4009 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 1.4443 - accuracy: 0.4025 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 1.4389 - accuracy: 0.4079 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 1.4287 - accuracy: 0.4126 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 1.4238 - accuracy: 0.4158 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 1.4072 - accuracy: 0.4220 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 1.3996 - accuracy: 0.4221 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 1.3853 - accuracy: 0.4307 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 1.3712 - accuracy: 0.4347 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 1.3561 - accuracy: 0.4423 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 1.3407 - accuracy: 0.4491 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 9s - loss: 1.3318 - accuracy: 0.4579 - 9s/epoch - 18ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 1.3166 - accuracy: 0.4631 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 1.3015 - accuracy: 0.4673 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0939 - accuracy: 0.5678 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7678 - accuracy: 0.7133 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6736 - accuracy: 0.7488 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6306 - accuracy: 0.7675 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5932 - accuracy: 0.7814 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5729 - accuracy: 0.7877 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5521 - accuracy: 0.7940 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5350 - accuracy: 0.8012 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5272 - accuracy: 0.8060 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5077 - accuracy: 0.8101 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.5049 - accuracy: 0.8107 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4928 - accuracy: 0.8157 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4822 - accuracy: 0.8200 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4711 - accuracy: 0.8235 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 8s - loss: 0.4724 - accuracy: 0.8238 - 8s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4619 - accuracy: 0.8270 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4575 - accuracy: 0.8274 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4529 - accuracy: 0.8293 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4470 - accuracy: 0.8307 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4459 - accuracy: 0.8308 - 7s/epoch - 16ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0936 - accuracy: 0.5678 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 8s - loss: 0.7465 - accuracy: 0.7224 - 8s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 8s - loss: 0.6575 - accuracy: 0.7602 - 8s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6202 - accuracy: 0.7724 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5910 - accuracy: 0.7823 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5607 - accuracy: 0.7922 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5449 - accuracy: 0.7997 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5306 - accuracy: 0.8037 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5213 - accuracy: 0.8072 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5124 - accuracy: 0.8108 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.5007 - accuracy: 0.8149 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4894 - accuracy: 0.8187 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4823 - accuracy: 0.8210 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4796 - accuracy: 0.8244 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4706 - accuracy: 0.8243 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4653 - accuracy: 0.8284 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4628 - accuracy: 0.8262 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4546 - accuracy: 0.8318 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4559 - accuracy: 0.8316 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4442 - accuracy: 0.8338 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.0589 - accuracy: 0.5814 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 9s - loss: 0.7203 - accuracy: 0.7355 - 9s/epoch - 18ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6321 - accuracy: 0.7668 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.5925 - accuracy: 0.7794 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.5614 - accuracy: 0.7940 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5507 - accuracy: 0.7950 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 8s - loss: 0.5234 - accuracy: 0.8055 - 8s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5121 - accuracy: 0.8126 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.4977 - accuracy: 0.8165 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.4939 - accuracy: 0.8166 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.4838 - accuracy: 0.8213 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4734 - accuracy: 0.8257 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4658 - accuracy: 0.8287 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4587 - accuracy: 0.8285 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4557 - accuracy: 0.8293 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4468 - accuracy: 0.8339 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4467 - accuracy: 0.8343 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4383 - accuracy: 0.8358 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4350 - accuracy: 0.8381 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4310 - accuracy: 0.8416 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.1085 - accuracy: 0.5591 - 9s/epoch - 19ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7897 - accuracy: 0.7051 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6947 - accuracy: 0.7404 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6464 - accuracy: 0.7584 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.6162 - accuracy: 0.7687 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5935 - accuracy: 0.7776 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5679 - accuracy: 0.7876 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5558 - accuracy: 0.7924 - 7s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5414 - accuracy: 0.7955 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5358 - accuracy: 0.8025 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.5250 - accuracy: 0.8043 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.5126 - accuracy: 0.8091 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.5070 - accuracy: 0.8110 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4986 - accuracy: 0.8147 - 7s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4949 - accuracy: 0.8152 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4889 - accuracy: 0.8183 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4810 - accuracy: 0.8206 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4741 - accuracy: 0.8212 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4735 - accuracy: 0.8241 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4698 - accuracy: 0.8228 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.1075 - accuracy: 0.5541 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 0.7807 - accuracy: 0.7052 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 0.6806 - accuracy: 0.7448 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.6305 - accuracy: 0.7636 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 9s - loss: 0.6016 - accuracy: 0.7730 - 9s/epoch - 18ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.5721 - accuracy: 0.7856 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.5528 - accuracy: 0.7933 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.5361 - accuracy: 0.7983 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.5224 - accuracy: 0.8045 - 7s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.5081 - accuracy: 0.8105 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.4979 - accuracy: 0.8138 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.4942 - accuracy: 0.8158 - 7s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.4808 - accuracy: 0.8204 - 7s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.4760 - accuracy: 0.8219 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.4738 - accuracy: 0.8221 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.4642 - accuracy: 0.8264 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.4614 - accuracy: 0.8282 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.4528 - accuracy: 0.8299 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.4484 - accuracy: 0.8324 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.4463 - accuracy: 0.8322 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4505 - accuracy: 0.4002 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.2811 - accuracy: 0.4866 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0781 - accuracy: 0.5999 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9271 - accuracy: 0.6563 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8353 - accuracy: 0.6922 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7879 - accuracy: 0.7147 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7632 - accuracy: 0.7253 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7409 - accuracy: 0.7329 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7222 - accuracy: 0.7389 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.7112 - accuracy: 0.7439 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.7015 - accuracy: 0.7476 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6889 - accuracy: 0.7524 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6817 - accuracy: 0.7587 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6694 - accuracy: 0.7611 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6610 - accuracy: 0.7648 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6504 - accuracy: 0.7666 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6463 - accuracy: 0.7680 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6346 - accuracy: 0.7742 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6279 - accuracy: 0.7764 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6200 - accuracy: 0.7794 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4578 - accuracy: 0.3958 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.3051 - accuracy: 0.4652 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.1123 - accuracy: 0.5748 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9454 - accuracy: 0.6522 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8432 - accuracy: 0.6962 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7837 - accuracy: 0.7232 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7501 - accuracy: 0.7366 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7264 - accuracy: 0.7437 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 9s - loss: 0.7088 - accuracy: 0.7514 - 9s/epoch - 18ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6885 - accuracy: 0.7597 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6751 - accuracy: 0.7608 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6626 - accuracy: 0.7668 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6597 - accuracy: 0.7697 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6495 - accuracy: 0.7703 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6426 - accuracy: 0.7749 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6355 - accuracy: 0.7754 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6258 - accuracy: 0.7813 - 7s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6219 - accuracy: 0.7822 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6189 - accuracy: 0.7819 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6128 - accuracy: 0.7842 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4939 - accuracy: 0.3758 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.3503 - accuracy: 0.4552 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0993 - accuracy: 0.5871 - 7s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9091 - accuracy: 0.6691 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8210 - accuracy: 0.7028 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7763 - accuracy: 0.7245 - 7s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7355 - accuracy: 0.7406 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7236 - accuracy: 0.7445 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7050 - accuracy: 0.7487 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.6866 - accuracy: 0.7591 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6768 - accuracy: 0.7630 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6667 - accuracy: 0.7658 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6524 - accuracy: 0.7703 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6471 - accuracy: 0.7723 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6420 - accuracy: 0.7751 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6291 - accuracy: 0.7784 - 7s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6240 - accuracy: 0.7820 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6175 - accuracy: 0.7818 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6091 - accuracy: 0.7874 - 7s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6094 - accuracy: 0.7859 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4599 - accuracy: 0.3908 - 9s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.3231 - accuracy: 0.4495 - 7s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.1420 - accuracy: 0.5517 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9760 - accuracy: 0.6333 - 7s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8773 - accuracy: 0.6779 - 7s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.8231 - accuracy: 0.6982 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7819 - accuracy: 0.7170 - 7s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7602 - accuracy: 0.7283 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7439 - accuracy: 0.7314 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.7270 - accuracy: 0.7420 - 7s/epoch - 16ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.7211 - accuracy: 0.7400 - 7s/epoch - 16ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.7086 - accuracy: 0.7484 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6948 - accuracy: 0.7531 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6866 - accuracy: 0.7566 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6792 - accuracy: 0.7568 - 7s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6755 - accuracy: 0.7576 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6649 - accuracy: 0.7644 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6558 - accuracy: 0.7660 - 7s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6511 - accuracy: 0.7691 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6444 - accuracy: 0.7714 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "472/472 - 9s - loss: 1.4602 - accuracy: 0.3989 - 9s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "472/472 - 7s - loss: 1.2866 - accuracy: 0.4843 - 7s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "472/472 - 7s - loss: 1.0502 - accuracy: 0.6120 - 7s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "472/472 - 7s - loss: 0.9142 - accuracy: 0.6631 - 7s/epoch - 15ms/step\n",
            "Epoch 5/20\n",
            "472/472 - 7s - loss: 0.8336 - accuracy: 0.6972 - 7s/epoch - 15ms/step\n",
            "Epoch 6/20\n",
            "472/472 - 7s - loss: 0.7885 - accuracy: 0.7124 - 7s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "472/472 - 7s - loss: 0.7631 - accuracy: 0.7242 - 7s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "472/472 - 7s - loss: 0.7407 - accuracy: 0.7326 - 7s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "472/472 - 7s - loss: 0.7227 - accuracy: 0.7389 - 7s/epoch - 15ms/step\n",
            "Epoch 10/20\n",
            "472/472 - 7s - loss: 0.7115 - accuracy: 0.7437 - 7s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "472/472 - 7s - loss: 0.6996 - accuracy: 0.7451 - 7s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "472/472 - 7s - loss: 0.6856 - accuracy: 0.7521 - 7s/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "472/472 - 7s - loss: 0.6776 - accuracy: 0.7531 - 7s/epoch - 15ms/step\n",
            "Epoch 14/20\n",
            "472/472 - 7s - loss: 0.6680 - accuracy: 0.7582 - 7s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "472/472 - 7s - loss: 0.6585 - accuracy: 0.7625 - 7s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "472/472 - 7s - loss: 0.6496 - accuracy: 0.7649 - 7s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "472/472 - 7s - loss: 0.6449 - accuracy: 0.7661 - 7s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "472/472 - 7s - loss: 0.6389 - accuracy: 0.7694 - 7s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "472/472 - 7s - loss: 0.6335 - accuracy: 0.7717 - 7s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "472/472 - 7s - loss: 0.6274 - accuracy: 0.7745 - 7s/epoch - 15ms/step\n",
            "Epoch 1/20\n",
            "590/590 - 11s - loss: 1.0322 - accuracy: 0.5969 - 11s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "590/590 - 9s - loss: 0.7020 - accuracy: 0.7409 - 9s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "590/590 - 9s - loss: 0.6247 - accuracy: 0.7699 - 9s/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "590/590 - 9s - loss: 0.5872 - accuracy: 0.7845 - 9s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "590/590 - 9s - loss: 0.5558 - accuracy: 0.7957 - 9s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "590/590 - 9s - loss: 0.5333 - accuracy: 0.8017 - 9s/epoch - 16ms/step\n",
            "Epoch 7/20\n",
            "590/590 - 9s - loss: 0.5234 - accuracy: 0.8065 - 9s/epoch - 15ms/step\n",
            "Epoch 8/20\n",
            "590/590 - 9s - loss: 0.5018 - accuracy: 0.8139 - 9s/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "590/590 - 9s - loss: 0.4929 - accuracy: 0.8158 - 9s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "590/590 - 9s - loss: 0.4827 - accuracy: 0.8240 - 9s/epoch - 15ms/step\n",
            "Epoch 11/20\n",
            "590/590 - 9s - loss: 0.4725 - accuracy: 0.8233 - 9s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "590/590 - 9s - loss: 0.4651 - accuracy: 0.8283 - 9s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "590/590 - 10s - loss: 0.4594 - accuracy: 0.8281 - 10s/epoch - 17ms/step\n",
            "Epoch 14/20\n",
            "590/590 - 9s - loss: 0.4521 - accuracy: 0.8314 - 9s/epoch - 16ms/step\n",
            "Epoch 15/20\n",
            "590/590 - 9s - loss: 0.4472 - accuracy: 0.8341 - 9s/epoch - 15ms/step\n",
            "Epoch 16/20\n",
            "590/590 - 9s - loss: 0.4441 - accuracy: 0.8344 - 9s/epoch - 15ms/step\n",
            "Epoch 17/20\n",
            "590/590 - 9s - loss: 0.4360 - accuracy: 0.8386 - 9s/epoch - 15ms/step\n",
            "Epoch 18/20\n",
            "590/590 - 9s - loss: 0.4317 - accuracy: 0.8408 - 9s/epoch - 16ms/step\n",
            "Epoch 19/20\n",
            "590/590 - 9s - loss: 0.4314 - accuracy: 0.8396 - 9s/epoch - 15ms/step\n",
            "Epoch 20/20\n",
            "590/590 - 9s - loss: 0.4215 - accuracy: 0.8427 - 9s/epoch - 15ms/step\n",
            "Best score is 0.80 using {'num_cells': 128, 'learnRate': 0.01, 'epochs': 20, 'dropout': 0.3, 'batch_size': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best CNN-LSTM Model based on hyperparameter search\n",
        "best_CNN_LSTM = keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=25, strides=3, activation='relu', padding='same', input_shape=(3000,1)),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=16, strides =16, padding=\"same\"),\n",
        "        tf.keras.layers.Dropout(rate=0.3),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=8, strides=8, padding=\"same\"),\n",
        "        tf.keras.layers.Dropout(rate=0.3),\n",
        "        tf.keras.layers.RNN(keras.layers.LSTMCell(128)),\n",
        "        tf.keras.layers.Dropout(rate=0.3),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "PnDd7lNbt3Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_CNN_LSTM.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnIKtYjylAHt",
        "outputId": "bf55434a-cdd6-4441-c792-bde421e890d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_301\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1199 (Conv1D)        (None, 1000, 128)         3328      \n",
            "                                                                 \n",
            " max_pooling1d_567 (MaxPooli  (None, 63, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dropout_669 (Dropout)       (None, 63, 128)           0         \n",
            "                                                                 \n",
            " conv1d_1200 (Conv1D)        (None, 48, 128)           262272    \n",
            "                                                                 \n",
            " conv1d_1201 (Conv1D)        (None, 33, 128)           262272    \n",
            "                                                                 \n",
            " conv1d_1202 (Conv1D)        (None, 18, 128)           262272    \n",
            "                                                                 \n",
            " max_pooling1d_568 (MaxPooli  (None, 3, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dropout_670 (Dropout)       (None, 3, 128)            0         \n",
            "                                                                 \n",
            " rnn_102 (RNN)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_671 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_379 (Dense)           (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 922,373\n",
            "Trainable params: 922,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best CNN-LSTM\n",
        "sgd=keras.optimizers.SGD(learning_rate=0.01)\n",
        "best_CNN_LSTM.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "best_CNN_LSTM.fit(train_X, train_y, batch_size=64, epochs=20, verbose = 2)\n",
        "best_CNN_LSTM.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfM2LmMlg1nW",
        "outputId": "b1345a11-1081-4490-bf4b-5e92900b4e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "590/590 - 11s - loss: 1.0311 - accuracy: 0.5954 - 11s/epoch - 18ms/step\n",
            "Epoch 2/20\n",
            "590/590 - 10s - loss: 0.7208 - accuracy: 0.7365 - 10s/epoch - 16ms/step\n",
            "Epoch 3/20\n",
            "590/590 - 10s - loss: 0.6245 - accuracy: 0.7697 - 10s/epoch - 17ms/step\n",
            "Epoch 4/20\n",
            "590/590 - 9s - loss: 0.5867 - accuracy: 0.7826 - 9s/epoch - 16ms/step\n",
            "Epoch 5/20\n",
            "590/590 - 9s - loss: 0.5531 - accuracy: 0.7966 - 9s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "590/590 - 9s - loss: 0.5360 - accuracy: 0.8009 - 9s/epoch - 15ms/step\n",
            "Epoch 7/20\n",
            "590/590 - 9s - loss: 0.5192 - accuracy: 0.8062 - 9s/epoch - 16ms/step\n",
            "Epoch 8/20\n",
            "590/590 - 10s - loss: 0.5078 - accuracy: 0.8107 - 10s/epoch - 16ms/step\n",
            "Epoch 9/20\n",
            "590/590 - 9s - loss: 0.4941 - accuracy: 0.8162 - 9s/epoch - 16ms/step\n",
            "Epoch 10/20\n",
            "590/590 - 11s - loss: 0.4850 - accuracy: 0.8200 - 11s/epoch - 19ms/step\n",
            "Epoch 11/20\n",
            "590/590 - 9s - loss: 0.4728 - accuracy: 0.8241 - 9s/epoch - 15ms/step\n",
            "Epoch 12/20\n",
            "590/590 - 9s - loss: 0.4687 - accuracy: 0.8265 - 9s/epoch - 16ms/step\n",
            "Epoch 13/20\n",
            "590/590 - 9s - loss: 0.4663 - accuracy: 0.8262 - 9s/epoch - 16ms/step\n",
            "Epoch 14/20\n",
            "590/590 - 9s - loss: 0.4527 - accuracy: 0.8308 - 9s/epoch - 15ms/step\n",
            "Epoch 15/20\n",
            "590/590 - 9s - loss: 0.4468 - accuracy: 0.8332 - 9s/epoch - 16ms/step\n",
            "Epoch 16/20\n",
            "590/590 - 9s - loss: 0.4438 - accuracy: 0.8345 - 9s/epoch - 16ms/step\n",
            "Epoch 17/20\n",
            "590/590 - 9s - loss: 0.4374 - accuracy: 0.8369 - 9s/epoch - 16ms/step\n",
            "Epoch 18/20\n",
            "590/590 - 9s - loss: 0.4325 - accuracy: 0.8371 - 9s/epoch - 15ms/step\n",
            "Epoch 19/20\n",
            "590/590 - 9s - loss: 0.4298 - accuracy: 0.8402 - 9s/epoch - 16ms/step\n",
            "Epoch 20/20\n",
            "590/590 - 9s - loss: 0.4263 - accuracy: 0.8399 - 9s/epoch - 15ms/step\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.8374\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4184545874595642, 0.8374072313308716]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build up and train the CNN-Transformer model. This implementation is slightly different from the ones previous as the architecture is more complex and was harder for our group to understand. The CNN-backbone of our model is based on the architecture of model (1) from above with slightly different parameters. This allows us to better match the dimensionality that is required by the attention based layers."
      ],
      "metadata": {
        "id": "fRT6ckhYvOjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN backbone of CNN-Transformer model\n",
        "CNN = keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=50, strides=6, activation='relu', padding='same', input_shape=(3000,1)),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=8, strides =8, padding=\"same\"),\n",
        "        tf.keras.layers.Dropout(rate=0.5),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=8, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=8, strides=1, activation='relu'),\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=8, strides=1, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=4, strides=4, padding=\"same\"),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(500),\n",
        "        tf.keras.layers.Reshape((500,1))\n",
        "    ])"
      ],
      "metadata": {
        "id": "MCiS3uJ1muZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQKPIXQTtO8p",
        "outputId": "4494baf8-aa4a-4629-e356-ca6443b0a233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_76 (Conv1D)          (None, 500, 128)          6528      \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 63, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 63, 128)           0         \n",
            "                                                                 \n",
            " conv1d_77 (Conv1D)          (None, 56, 128)           131200    \n",
            "                                                                 \n",
            " conv1d_78 (Conv1D)          (None, 49, 128)           131200    \n",
            "                                                                 \n",
            " conv1d_79 (Conv1D)          (None, 42, 128)           131200    \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 11, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1408)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 500)               704500    \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 500, 1)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,104,628\n",
            "Trainable params: 1,104,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are used to define and build the indidvual heads and full on transformer layers respectively."
      ],
      "metadata": {
        "id": "FtY3JlWLvx1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = tf.keras.layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "zhnIejQdlnkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "  #CNN_outputs = CNN(inputs)\n",
        "  #x = tf.keras.layers.Flatten(CNN_outputs)\n",
        "  x = inputs\n",
        "  for _ in range(num_transformer_blocks):\n",
        "    x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "  \n",
        "  x = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "  for dim in mlp_units:\n",
        "      x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
        "      x = tf.keras.layers.Dropout(mlp_dropout)(x)\n",
        "  outputs = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n",
        "  return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "jaY59TQ2mG2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = build_transformer((500,1), 256,4,4,4,[128],0.4,0.25)\n",
        "transformer.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=[\"sparse_categorical_accuracy\"])\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyDG9xfUlzWC",
        "outputId": "9845e63b-c561-4d5f-da9e-d75f7685ab85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 500, 1)      2           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 500, 1)      7169        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 500, 1)       0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 500, 1)      0           ['dropout_3[0][0]',              \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 500, 4)       0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 500, 1)       5           ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 500, 1)      0           ['conv1d_9[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 500, 1)      7169        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 500, 1)      0           ['dropout_5[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 500, 4)       0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 500, 1)       5           ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 500, 1)      0           ['conv1d_11[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 500, 1)      7169        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 500, 1)      0           ['dropout_7[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 500, 4)       0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 500, 1)       5           ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 500, 1)      0           ['conv1d_13[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 500, 1)      7169        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 500, 1)      0           ['dropout_9[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 500, 4)       0           ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 500, 1)       5           ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 500, 1)      0           ['conv1d_15[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 500)         0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          64128       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 5)            645         ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93,517\n",
            "Trainable params: 93,517\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the final combined sequential model corresponding to the CNN-Transformer architecture we envisioned."
      ],
      "metadata": {
        "id": "IyQ5jDTGv-L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model = keras.Sequential([\n",
        "      CNN,\n",
        "      transformer\n",
        "])"
      ],
      "metadata": {
        "id": "lBvwa39ip3Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTcHcka9wkKp",
        "outputId": "0a8ea185-0aa4-4420-94f6-c17e7d457489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 500, 1)            1104628   \n",
            "                                                                 \n",
            " model (Functional)          (None, 5)                 93517     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,198,145\n",
            "Trainable params: 1,198,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now train and evaluate the model like the other two to compare results."
      ],
      "metadata": {
        "id": "FFp2rAU-wEbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd=keras.optimizers.SGD(learning_rate=0.01)\n",
        "combined_model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "combined_model.fit(train_X, train_y, epochs=20, batch_size=64, verbose=1)\n",
        "combined_model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBieg5kFwnQC",
        "outputId": "6e4e7689-e1a8-4808-b568-07b7d8c8775b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "587/587 [==============================] - 300s 480ms/step - loss: 1.0666 - accuracy: 0.6041\n",
            "Epoch 2/20\n",
            "587/587 [==============================] - 285s 485ms/step - loss: 0.6768 - accuracy: 0.7499\n",
            "Epoch 3/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.5893 - accuracy: 0.7846\n",
            "Epoch 4/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.5708 - accuracy: 0.7914\n",
            "Epoch 5/20\n",
            "587/587 [==============================] - 286s 487ms/step - loss: 0.5291 - accuracy: 0.8050\n",
            "Epoch 6/20\n",
            "587/587 [==============================] - 285s 485ms/step - loss: 0.5243 - accuracy: 0.8077\n",
            "Epoch 7/20\n",
            "587/587 [==============================] - 285s 485ms/step - loss: 0.4962 - accuracy: 0.8165\n",
            "Epoch 8/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4849 - accuracy: 0.8224\n",
            "Epoch 9/20\n",
            "587/587 [==============================] - 285s 485ms/step - loss: 0.4735 - accuracy: 0.8251\n",
            "Epoch 10/20\n",
            "587/587 [==============================] - 284s 484ms/step - loss: 0.4683 - accuracy: 0.8258\n",
            "Epoch 11/20\n",
            "587/587 [==============================] - 285s 485ms/step - loss: 0.4622 - accuracy: 0.8305\n",
            "Epoch 12/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4497 - accuracy: 0.8325\n",
            "Epoch 13/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4488 - accuracy: 0.8333\n",
            "Epoch 14/20\n",
            "587/587 [==============================] - 286s 487ms/step - loss: 0.4479 - accuracy: 0.8335\n",
            "Epoch 15/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4414 - accuracy: 0.8371\n",
            "Epoch 16/20\n",
            "587/587 [==============================] - 286s 486ms/step - loss: 0.4329 - accuracy: 0.8397\n",
            "Epoch 17/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4305 - accuracy: 0.8400\n",
            "Epoch 18/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4253 - accuracy: 0.8421\n",
            "Epoch 19/20\n",
            "587/587 [==============================] - 285s 485ms/step - loss: 0.4230 - accuracy: 0.8426\n",
            "Epoch 20/20\n",
            "587/587 [==============================] - 285s 486ms/step - loss: 0.4176 - accuracy: 0.8456\n",
            "149/149 [==============================] - 13s 83ms/step - loss: 0.5762 - accuracy: 0.7789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5762342810630798, 0.778854250907898]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Data\n",
        "From our models we can now generate hypnograms which can be then compared with the hand labeled ones from experts. Below is a quick demonstration using the best CNN model we found above."
      ],
      "metadata": {
        "id": "EQu-2N2nwlXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFh_q6DmjfFr"
      },
      "outputs": [],
      "source": [
        "test_yhat = best_CNN.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQue8uJLjfFr"
      },
      "outputs": [],
      "source": [
        "output_labels = [np.argmax(a) for a in test_yhat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLwo-juRjfFu",
        "outputId": "90d420c8-f035-403a-cb8f-10459f6c1336"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAADKLklEQVR4nO29d9wtSVXv/Vv7eU6YnJl8OAhDljAMA0hwCEpSMKCCCoiBKyaMXNArRt7r9RpRr4qSRAQUFEcliGQkzTDEYYAZwjAzTM7hnDnnefZ6/+iu7lXVVd3V3dW9e++9vufznL13h6rq7qrqWrVWrUXMDEVRFEVRFEVRFGX5mS26AIqiKIqiKIqiKEoaVMBTFEVRFEVRFEVZEVTAUxRFURRFURRFWRFUwFMURVEURVEURVkRVMBTFEVRFEVRFEVZEVTAUxRFURRFURRFWRFUwFMURVEmARG9gIiuJqLbiOi4RZdnSIjo0UT0xQTpfI2InpB//00i+vv+pZsGq3Y9iqIoY6ECnqIoSk/kIFts+xEi+tCiyrRsENEOAH8E4NuZ+XBmvj5w3OG5APj2lumfQ0SXpyhrF4iIiege5jczf5CZ77Wo8rgQ0Y8R0ReI6NZcyH4bER2x6HKFyJ/nPK8LtxHR5UT0j0T00BZpqACpKMpKogKeoiiKAgAgoo0FZn8igN0ALmw47nsB3Ang24jopMFLtQYQ0bcC+P8APIuZjwBwHwBvSpzHZsr0cr7BzIcDOALAwwF8AcAHiejxA+SlKIqyNKiApyiKMjBE9CtE9BZn28uJ6E/z7+8jov9NRB8noluI6F+J6Nh8395c+/NcIvo6EV1HRL8m0tlFRH9CRN/I//6EiHaJ/S8ioivzfT8uNUlE9Boi+stcW3M7gMcS0VOJ6JN5OS4jot8UaZmyPC/fdyMR/SQRPZSIPkNENxHRn9fcB29ZieieAIy54k1E9J6a2/lcAH8F4DMAfthJ39KS5df3u0R0GIC3AzhFaHxOqbt3RuOX379r8nv4XUT0FCL6EhHdQES/KvI6m4g+kt+DK4noz4loZ77vA/lhn87z/gFXo0hEpxPRPxPRtUR0vbmPRHR3InpPvu06Ino9ER1dc39Mev9BRD/rbPsMEX235/CHAvgIM38SAJj5BmZ+LTPfmp93CBH9IRFdSkQ3E9GHiOiQfN/TiOjC/LrfR0T3Efl9jYj+JxF9BsDtRLRJRA8nog/nx3+aiM4Rx9+NiN5PmRbxXQCOb7rOvLzMzJcz80sB/C2A/yPS/NO8rt5CRJ8gokfn258E4FcB/ED+TD6db38eEV2Ul+ErRPQ/YsqgKIoyJVTAUxRFGZ6/B/AkMzCnTJvxTAB/J455DoAfBXAygC0AL3fSeBSAewF4PICXioH0ryHTXjwIwAMBnA3gf+X5PAnALwJ4AoB7ADjHU7YfBPAyZFqQDwG4PS/L0QCeCuAFRPRdzjkPA3AGgB8A8Cd5GZ4A4H4Avp8yjZAPb1mZ+Uv5uQBwNDM/zncyEd01v4bX53/PCeRjwcy3A3gyco1P/veNUHnEqSch0yqeCuClAP4GmVD5EACPBvDrRHS3/NhtAL+ATCh5BLLn9FN5/o/Jj3lgnrelHaNMc/rvAC4FsDfP741mN4D/DeAUZJq10wH8ZsRlvxZCACaiB+bp/ofn2I8BeCIR/RYRPZLEBEHOH+TX/C0AjgXwIgDzXDB/A4CfB3ACgLcB+Dcj2OY8C1k9OhqZlvY/APxuns4vA3gLEZ2QH/sPAD6B7B7+DjJhvi3/DODMXKgHgPOQPd9j8/T/iYh2M/M7kGkt35Q/kwfmx18D4DsAHAngeQD+mIjO7FAORVGUhaECnqIoShremmslbiKimwD8P7ODma8E8AEA35dvehKA65j5E+L81zHz53Jh5NeRCUrSZPK3mHkfM38awKeRCSQA8EMAfpuZr2HmawH8FoBn5/u+H8CrmflCZr4DfsHgX5n5v5l5zsz7mfl9zPzZ/PdnkA3gXYHtd/Jj/xOZQPiGPP8rAHwQwIMD96iurDE8G8BnmPnzyASg+xFRKK8YmspzEMDLmPlgnt/xAP6UmW9l5gsBfB75c2DmTzDzR5l5i5m/BuCvUb1vIc5GJsD9CjPfnt/bD+XpXsLM72LmO/My/lFkuucCuCcRnZH/fjYyYeaAeyAzfxDA9wA4E5kAdj0R/RERbRDRDNnEwwuZ+Qpm3mbmDzPzncgE/P/Iy3cQmSB4CDJB0PByZr6MmfchEzjfxsxvy+vXuwCcD+ApRLQHmSbx1/Nr/QCAf4u8f5JvIBOKj86v7e+Z+fr8ufwhgF3IJkq8MPN/MPOXc63g+wH8JzJhXlEUZWlQAU9RFCUN38XMR5s/5NobgdSo/DCA1zn7LxPfLwWwA7aJ2lXi+x0ADs+/n5IfL889ReyT6crv3m1E9DAiem9uKngzgJ9E1VTuavF9n+f34fBTV9YYnoNMc4dcmHw/uml5YstzPTNv59/35Z/eayWiexLRvxPRVUR0CzLtUJSJITKt3KXMvOXuIKITieiNRHRFnu7fx6TLzPuRraP74VxIexaqdU4e/3Zm/k5kmq6nA/gRAD+e57UbwJc9p1n3j5nnyOrTqeIYWb/uCuD7nImQRyHTWp8C4MZ8gsMgn00spwJgADcBABH9cm5yeXOe31GouX9E9GQi+mhugnsTgKfUHa8oijJFVMBTFEUZh7cCeAAR3R+ZCdjrnf2ni+97kGmProtI9xvIBs7y3G/k368EcFogDwM7v/8BmfbndGY+Ctl6N4ooRwx1Za2FiL4FmVnoS3Ih6ipkpqI/SKUDjzsAHCpOk05Y3OvsVR4Pf4nMyccZzHwksvVdsfftMgB7yO+I5P9DVvZvztP94RbpvhaZlvLxAO5g5o80nZBr1t4N4D0A7o+sDu4HcHfP4db9IyJCVseukEmK75ch01QfLf4OY+bfQ1ZXjxGmlUD2PNry3QAuYObb8/V2L0KmyT4mn3i5GeX9s+pEbpr6FmSayBPz49+GdPVfURRlFFTAUxRFGYFco/JmZALUx5n5684hP0xE9yWiQwH8NoA3C+1RHW8A8L+I6AQiOh7ZWjHj+v0fATyPiO6Tp/vrEekdAeAGZt5PRGcjW6OXirqyNvFcAO8CcF9ka6oehEwAOQTZ+joA+BQygW8jX38oTRmvBnAcER2VqDwuRwC4BcBtRHRvAC9w9l8N4JsC534cmYDze0R0GBHtJqJHinRvA3AzEZ0K4FdiC5QLdHMAf4ga7R0RPZ2InklEx1DG2cju3UdzrdyrAPwRZY5pNojoEbkw9I8AnkpEj6cszMUvIfNw+uFAVn8P4DuJ6Il5OrspczZzGjNfisxc87eIaCcRPQrAd8ZcZ17mU4noN5BpHY3zmyOQrWe9FsAmEb0U2do6w9UA9uYaTgDYicyE81oAW0T0ZADfHlMGRVGUKaECnqIoyni8FsA3wz/Yfh2A1yAzxdwN4Oci0/xdZAPjzwD4LIAL8m1g5rcjc9byXgCXAPhofs6dNen9FIDfJqJbkQk8/xhZjl5lrYOIdiPTwvwZM18l/r6K7L4ZM80XIhMKbkKmuXqrSYOZv4BMoPtKbh54StfyBPhlZMLwrcicsbhhBn4TwGvzvL9f7sgF+e9E5gjn6wAuR7a+DcjWBZ6JTPP0H8iciLTh75DVuTrB9UYAPwHgYmRC6t8D+L/MbLTMv4zs/pwH4AZkXipnzPxFZBrFP0Om6ftOAN/pW+eXX+dlyMw/fxWZEHUZMoHVjEV+EJlW9gYAvwHbCZGPU4joNmQC8Hn5dZ6Trw0FgHcCeAeALyEz99wP22T0n/LP64noAs68hv4csjp/Y16ecxvKoCiKMjmI2We1oiiKoqQmdyTxBQAnMfMtYvv7APw9M//twPnfB8DnAOzyrfdSVg8ieg6A5zPzoxZdFkVRFGUcVIOnKIoyArkZ2C8CeKMU7kbI97spi/d2DDLNy7+pcLce5Ga5PwXgFYsui6IoijIeKuApiqIMTO444hYA34bM9GxM/gey2F5fRharzV0bpqwgRPREZGaQVyNb96koiqKsCWqiqSiKoiiKoiiKsiKoBk9RFEVRFEVRFGVFUAFPURRFURRFURRlRfAFVZ00xx9/PO/du3fRxVAURVEURVEURVkIn/jEJ65j5hN8+5ZOwNu7dy/OP//8RRdDURRFURRFURRlIRDRpaF9aqKpKIqiKIqiKIqyIqiApyiKoiiKoiiKsiKogKcoiqIoiqIoirIiqICnKIqiKIqiKIqyIqiApyiKoiiKoiiKsiKogKcoiqIoiqIoirIiqICnKIqiKIqiKIqyIgwu4BHRBhF9koj+3bNvFxG9iYguIaKPEdHeocujKIqiKIqiKIqyqoyhwXshgIsC+34MwI3MfA8Afwzg/4xQHkVRFEVRFEVRlJVkc8jEieg0AE8F8DIAv+g55OkAfjP//mYAf05ExMw8ZLmWhX0HtvHZK27G2Xc71tq+tT3Hx756Ax55j+MBADfdcQCXXn8HHnj60bh1/0F86erb8JC7HoMPXXwdTj/2EHz4y9cDAI47bCdOPuoQfO4bN1fy2nvcYThk5wbudtxhuOGOA/joV66vLdvRh+zAk+5/Ej5w8XW4df9B3PfkI7E5m2HPcYcCAD57+c049ZhDcOxhO2vTObA1x9s/dyVOPHI3tueMr99wBwDgzD3H4F4nHRF3oxSLS6+/HczA3uMPAwB87oqbcfShO/CNm/bj7Lsdi498+XqcedejsWtzA+/9wjW46pb9vfI7+pAdOOPEI7B7xwynHXNo53Te/6Vrcev+g3jK/U/GbEa9ylTH/oPb+NRlN+Hh33QcPvaV6/HA04/G7h0bAIDrb7sT/3XR1Thr77G4+wmH4yvX3oaPffUGHLJjA0/55pOxczP9nNi1t96Ja27djzsObON+pxyJQ3fGd8vv+vzV2J4znnT/k5KXKyW33bmFL151Kx5y12MWkv/NdxzEOz9/Fbbnw75ajjl0B554v5PADPz3l6/Do/I++kOXZN+JCLfuP4h3fO4qbEWU5W7HH4aHf9Nxg5bZ5ZJrbsWhOzdxytGHjJrvqnPx1bfi/EtvLH7Ld9wFX78RX7vudpx112Nxx8EtXHHjPlxz652t8zjh8F24y5G78KWrb8PZe4/FrXcexP1OOco65pb9B3HJNbfhzD1ZW7zipn3Yd2AL97hLu/ftfM542+euxOG7NnHOve6CD19yHR56t2OxY2OG//r81bj2tjtxzxOPKNr8F6+6FRd8/UYctmsT9znpCJx/6Y04dOcG7nfKUTjvazcU6d7vlCNx75OOxPmX3oBvufvxxXb3/Au+fiO+5e7H45pb92PX5gZOOmo3jj98F4BsXGHOP+9rNxT96gcvvhaX37iv8drOudcJIBDe98VrwACOOmQH7nXSEdi5McPpx8a/4z57+c3FeOsedzkcMyLc66QjcPiutENvZsbbP3cVbt53sPa4jRnh7L3H4mNfvR5du8Ijdm/ijLtk938MvvWeJyTri977xWtwx53beMo3n4RPXnYT7nGXw3Hk7h1J0p4igwp4AP4EwIsAhHqOUwFcBgDMvEVENwM4DsB18iAiej6A5wPAnj17hirr5Dj301fgJf/8WXzypd+Oow4pK+EHLr4WP/qa8/G+Xz4He48/DK/7yKX4q/d/GRf+9pPwj+dfjt97+0X49599NH74lR/DsYftxA23HyjOPeqQHd5O4JAdG5gz44VPOAOf/PpNeNfnr24s39tf+Gg891UfB5ANbB50+tF49fPOBgA851Ufww897K745SfeqzaNj331erzwjZ8CAOzYIBzcznqds+92LP7xfzyisQxKlZf+64WYM+N1P/YwAMCPvPo8AIwbbj+Ad/z8Y/Csv/ko/uxZD8ZjzjgBz3vNeUnyPObQHXjE3Y/D//uhh3Q6f9+B7aIu/fvPHob7n3pUwxndecfnrsLPv+lTeMsLHoEfeMVH8YyHnIY/+L4HAgBe++Gv4eXvuQSPvdcJePXzzsbL/uMivPsL1wAAjjlsJ771nickL8/j/vB9uHX/FgDgifc7EX/97LOizrvm1v34ib87HwDwof/52F7C9dC84O8/gQ9efB0+91tPTD64ieEfz78ML3tbyJAkLe/75XPwjZv24dmv/Dje/sJH486tOZ79yo/jLS94BB5y12Px1k9egV//1wuj0jpi1yY++1tPHLjENr/wpk/j7icchj955oNHzXfV+Y1zLywmWwHgoXuPwT/95LcAAJ75io/iwNYcxxyavedvvKN+oF4HEcCc9cm7Njfw0V99vLX/jR//Ov7gnV/CRb/zJGzMCL//ji/gq9fdjnN/5lGt8vnCVbfiZ/7hkwCA//yFx+AH//ZjeMWzH4IH7TkaP573SycftRsfeUmW/6+/9XP4eC7IHX3oDtyUX6P8DmSC0C992z3xgtdfgA+/+HHF4P5/vfWzOO9rN1rnHHvYTtyy7yAO27WJZ559Ol7y5PsAAP7roqvxU6+/AG/96Ufi+/7qI3jqN5+MP/6BB+FHXn1e1CTPDz1sDzZmhL/7yKXFtmMO3YGH3e04/NWz499xv/xPn8YXr74VAHD4rk3sP7iNX3vqffC8R94tOo0YLrnmNvzU6y+IOjY0BmxDijRieeZDT8fvfe8Deqdz251beN6rs/HO237u0XjmX38UL3rSvfDjj/6m3mlPlcHetET0HQCuYeZPENE5fdJi5lcAeAUAnHXWWWuj3dt3YBtzBg5uz53t2e99B7eLT/N9/8FtHNxm3HZnNmC8ed9B7D3uUDz7EXvxO//+edx25xa+7b4n4neefv8ivb96/5fxuo9eiu05Y/+Bbdy5Ncd9Tz4Sr/qRh3rL9Z4vXINf/ZfP4vY8DwC4ad/BogwAcMeBbet3iDsPltd2cJvxE4++Gz57xc3Yd3Bec5ZSx74D22Cw+L2FOw5ugxm4Je+U9x3cxp3b2fP5lSfeC9975mmd8nrfF6/Bi//5s9nzP9D8vEMcnJfP+86tYZ/9HXk5r7klmyH/4lW3Fvv253kfyNvcnVtz7Nyc4cDWHHdG1OcuGOEOAD5/5S3R58m2M/Q968unL7sJALC9vZjue3/+7D74osdix8YwKxPe/YWr8Wv/8jncuTUv6ti+g9tF3qbf3p8/t//6xW+tFXb/4r2X4E3nXTZIWeu448BWVN+ttGP/wW08dO8x+LNnnYlfeNOncMeBst0fyNvvTWLQ/OIn3xvf9aBTo9P/t09/Ay9720Uw9k837TuII3dXj7vjwDYObM+xPWdszCh7V3fou+/cKs8xfdi+g9vFtezYoOK7Od5M4t66f8v6fsZdDsfrfuxh+M1zL8SFV95stZ/y/Dl2bsxwYHte5HfzvoPYnmfjnf3iGsz1XH9b1sdfdOUtmDNje874qXPujuc8Ym/wur7zzz+EA1tzzIhw/OG78CtPvCf+51s+WxnjxLB/axvfft8TcdzhO/HG8y4DMwZpW6ZP+f1nPACPOcM/Cbnv4DYe+wfvwy37D2LnxgwfeNFjW+fzka9ch19406dxy/6DOPtux+LlA08Cfc//++9k77aDIp19B7M20GfMsgwMOZX6SABPI6KnANgN4Egi+ntm/mFxzBUATgdwORFtAjgKQL1t4BphhkKuwaoZvJvtbB3L1uecGZsbs0IDOGfGoTszcwbD4bs2MTfn5efu3JxZx0jMLKOcCWO2y8mectddo+GI3Tuwe8fGyje8IWFw8FkUz0xUmqMO2RF81k0cfWhmgstcfZZtsOvKsEJA0X6c31k53LbF2CAaoVQm/3HPG4uifMNZ3tbnn3+efNRubA4k4B1j2oKoUSzaWVnvss+TjtpdK+AdvnvTqptjEdt3K+1gALt3ZO/eXTtmEIY15THivh/dsl8+6lDb1Cx7J1cfJLv1sWPfLc+R+ZivMyL7mHwbwNm4ZDYrvu/YyMYbh+7csMpjvccYmM0AbKMYr8hPNy/f+UA2xqi7r5szyl+PjM0Zle26w31iBg7duYHDdm6W932AtmWu/thDdwavzYypmDMtb5d3vrwXpi4PyebGzFuHu+Crr6vezQ3mZIWZX8LMpzHzXgDPBPAeR7gDgHMBPDf//oz8mFW/56MgOzhCOa4yvyXGpMPdFoLyndvOSXZnykXnW4d7DCF7CQy8VGalmbN9X+X3bfFCNPd4VvewG5BL5fo8M7bK2z2dGOY1L1pf3uYax+ia2mThtrcpU8h3CxLwTBvoU9ebMPVkPi/zY9HO3M+mZaYzGr4t+GBeTL6rzpzLd+eMqLGtt62rvuN9eVQmsSLf1aF0AH+fujGjiuC3kVd697spOuX3Rbaf4nw52ebk11R8ubvptsqx0ozs+9q2n50zY0ZkrSkfoq8u+pSaEb287q79oDxvwGXyVh5D9EXr0r2NvhiCiH4bwPnMfC6AVwJ4HRFdAuAGZIKgkuPOtIW2S+2Zr8Mjshs3OY1b/jLn1bVdOZCxygW7M4/BJ1jOqHrNSjzszmaKH+aZmRlKoF9H3eflJ/HNtA5GMXtnD3Tkd/k5m1HluClgtbcFliOGcsC2mPyLfm3AQQkVml4WfbSsZ/Y9aBpkZULA+DeMpdpRSQdz0ddmeqz6e9y2rvr6cV8OrnaLQwc24JtgknV/o6LBKwW0rLzld/N1RnlasmwivzrnW00TXuZ+N91WI2SCsu9SaGrbHDkX6uWzHESDlyfqju0kKYSzWeD5DYWrBe6DT8s8tXd6akYR8Jj5fQDel39/qdi+H8D3jVGGZYQrX+yfPgHQfJMzcgS7g6k0SzlIzzvouo4ipMGTMy3zyFlBtyPO0qaK8KjEM+fqi9Hg0+D16adTvbhCGschqNfgVYU/8yKbmlaDnfY2ZaS2YDH5Nw+A+iJn/gsT+TlX6lvssyIsps5lFgDj57vqzLmsIz6rGZe2ddV3uK+u+cwbu/Qf9vs++8xkM9PWqpNnoXEI5b+IbAsUWS7ZF/vwjYN878GY28pggMkqm1ueGJg5m2C30miVRBTFu7zmmLpJ/lhqx5FDQOnebTIV9z2/qowRB0/pSMhOuDJIEoOntoOIap7Nlb7U4NnH2eYUcQN+3yGZBk/pSjYjK5+FEJ7mpeCSYtA7cyYHuhISSIfAbVd+M6b8E+Ws+xgvgzYC0Jj3rC8L1+BheJMi0xaEAiLvB/2DiaYZ8EIjOPJNyyb5Jl6hlpCsLylEvAgTzXbpx5tomvKUv7s8bVsjIt8reXk8JppSA+er/pnGhr19c1Mbtq7VM6HU6hrzcZBr/dRagwdj5im3DdG2sjTr+hSfxrQtKYTENswo3WDQNyG66t2cCnhLQKgS+jvqasV1Z5DcqRfLRDM/N2YmyI3jNBedKnOckOk7hgg6wOiBXPcD2DOGW4WAV04G9Oqm5Rq8HlrXuWewMBRzz8vfLYdsU2atyBhajTZZ2Gtgpt1e+k489WXOPPiAxCQvNSJzOek2N59sHd+U3ti3LFtDOG6e68B8LteaNbf1FNXVr8Gz96XQ4G2LftNsDjtZyfd7hL16DR43aPDk9+rkczGh2fDGK54Nm+Ut3TV4c+aKBdWgGryaS6PA9zbIezfGeurMiiHNDfMtIVr1bk4FvBXFbRO2ap2C++q2lftyE82ABq8czDWX0z0mW4NHkx+wThn3hW05WZmbF2caxxOzHi8/iT271jmZKOpm7/wTDuNpUtpkIe/T1JuLebkuSnCY83gaPGn+LCe6yk/7+Jj0xqSr0w2lHjnJQGjuTwZ3sjIvj+kyOedzsiLfPbOKiSZbbdDSKJnPfN2pz4w+M/Hs1ojlbYidWDHCmaV9a9ks5pw5Pkm1Vj2Yz7z5XW45WenYGdrPr1MSLfMbZiy4Lt2bCngTRpqJ1W2XJme+cypOVSoaPNn5GA1es6rfbXjsfMbMj1TW4OWzXevSAIdAmsmY3wbpnaw0pemel2160h3bFGech++GS7DKIWb4XM9tY5Qp9uji28Tby9zTL41Jn8FhLIXGDX6TtbJqlQPgOmYivTGZeFVaagonKwOswfMKeJ6n6dbDrm3S7jfLSl5YhlDVRFNek1X/8+2FUOiZhJPm8t7yNEx4xV4lISs3o5xwlmVog7lmcralxiTZNDFfOrPpKOBJresIq/CSjgV9Y4ypvzh7ogLehPGZW/q2l59l9yNnygl2x+o2S8vG3FjAR6j6XQ1eZaY6YlbQp2kk1eD1QmrnXAHap8Hr01HbkwPdn5mtceycTKu8/Bq87LN8AYg1pxOrkz7Bfaq42v1F5D/0cERqeqVJqtsWS3OquDV4Yz/briZ7Sj1GIwTkQkSDsNC2vvqdrHi2ze16KMN6tMF1gAKYflNo8MTxVQHNo8EDWRrwNk5WfFPLvsm75nZXTpYT7OfQ9t1k+p0+Zp4xxL7Lyflsizyvz8RwdH6ULmSWTEaGA15lVMCbMCE74eqMsPh0hKz2mTYPwoIaPFfgjNHgeY5J6Rp3HfG5AzZYAe3zbX0UG33MVyTe2eCB8E2MuCWRdbgcuA9arNZ5VEs9Xeo8l44BY3i33mW8RFs7XPTP4ktMURa1Bs+1AFDSwFwOimM0E+1NNH15VjNhZ58MbdAGv2VIud2N9ecKaL7yzgrhqmw/stxtNXierj2KrA0brVf3SUzT79hawAEo7nn9YaYc3b1okvf7UGTXk+aOherrKjN6HDwlHW5nE+rMMicr9m+Jr5nWNV1zflWDZz7tGcI6XC2fmTFb9YY3JHKA6Qrh5plZi877dNTi1D4zk9Ij69DPvm72zqd1Lp2sDF8p2+SwTBo8w8KcrMzjhKo+mNnzOQuHKqKdyUDnMUUx6Y19y6R2X0mHpcGj5rbevr5WT/Bq8Dz1sa8GT/apZqvxiGlwJ1l8Xh2JyAot4jpZ6bwGT46HGo41+0vtW7mvrTZpzlVPnMNo8LLPGO2k/GyL7ctheIzTnRRYyoQ16d5Ugzdh3Jm2YrtTOdlTb+01ePFOVkwHXW/LnX2GnKyEyunDPSSzeR9ei7PKuIGWJaWAJ2dau+c1xMzk0Ou03LWr3n3mN4+7FqqdBm88oTgViyrmuBo88WREO5NrnmLKMmZ4DptuGh2lHvleNeu86mgfJiGQb8jSRpihd3nc1nyyR4PnailNTDhfeQvTQaPBc8pq8qszC7SPDfftzU5WqCxDZQ1eO4zW0no2A7St2HW9RgBcqkDnA3RGfdefLgsq4E0Yr5kBpBBnPsvKWqz9EJoIyv8Vv10NnmuCwPW23GZfVcDL83bWnNThzmZlTlbS2V2vIyE304BcgycCnfdag2fn2xVrNnjgIPcVE2dLE2a2lYJeGd9sFBEv/khn8LQMuLEzR8uXh1+DZzJw25/UlJjPNiaaY9+yOVffOUp/mMW7NkKD11ZHEtLeVCeE2doutcxt8HnRLNbwozlMgs/cj/L4gOwbQ3CLQOdyhsXZFqPBK8dBzgR4y/tUrI0bfA0e8nzqj5NrHbtQZwk2BISEGjz5np9Xt60iKuBNmNDsgttBy8+QaV50nhzO12Bmf7adPKqmH81l8HWYmVp+xVvegMjYW+5t3BbPSLqz7or0qtXPyYr8Puyzn0t7oko52NolZ52nNungE0ynzqKaNUcKVX2QEwHsaWfltjhTs0WFSVAnK8Mw59LJiFxaFOo3U2nw3Gfpj4PXLi/AnojzBjonwJXwLK1dYA2eHUfSOr1ewHOODW2LgYFi/bUsc9t2YTR4fcw8Y/AJkj7M/VsWDV5Kh3syFfc9v6qogDdhmjR4vupZzsqV2yommjXtktE8GDKDenc2Xg6K/aXz5OcclK0XpJWfWRkU9r/ggPKZSW1vnzV4yZyscF2tTktxb3xmGu6kCco1eGPUye4mmsvRYBYXJoE7x36KpRDwIPturrZFjhtgjencR8I8fBtcR8xgHyjNAM12Hyni4AHVZ1nxwo1u/Yc9YJZpleWJXoNnts3IEhJth2H162itK/CMQaLXnOeCKXPVA3nb22Ri/7mhqJIj7nkdZZiOjhq8kdfgpeyyvRrnFe/oVMBbWcqaS3AbY3gNXt029+xwmARYn3X4jtE1eP2wZ0Dt+yjX4JWzfn1yS2N6YgftHliD52jAffskY2pSWs0yL6EGb5GBzocekJSaXtssk522KJ1t1KaXf47dF6oGbxikmXBhBohwv9K6X+6swevWLm0nK+WIWa51Y6dfD67BE5pNn1kz0KzBq8P1SVBH2e6qDuraO1kp/QqU29K3rTJMQj2FKWzHztBWFCyXBs9mPfo3FfCWgMqst6tlkOYRsPcBABwTgaoXTXt2iZ1tLqZhb1enBp3yNTci99oodym8Hs1vGCwNgrNv2/Ns+phapNLgWXrpgR++SX9btBu3FLIdSc3M0HQdzC/LYvFFTdzEOjbpgy9MAlA1l+ZIDZ5Mb1R4AXmuAZnAUA6w3b7GJZkGzx0+uNoL7roGT3wXn7YGzz4mrMGzNZs+64qmdtNkjmm2xQhBZi0hwQlx0NZEM+93hu575D2vw+zuHOjcen6dkmiZX7q+yJ5syD+X5L3ZFQ2TMGFCwYErnv7Edq+Jpvjf/pb/loN0cKMpROlF0/aG4WqNYhqmOyNG0DV4fZFr8KoavHm+PX7Wr45Ui8ftNXg9ChRBMXM+t9uRlbcw8TGe28YQTrpq8JaluSxUgzf4gKTU9Ppc0EuNSczs9yIDnasFRXrkezXT4GXfg8+3ZX0NHV4V8Oz3c1enOq75pJuX6wFRTpZVClyYDiJfw1ote9Mkjc/JirePbBKC8mMLDV6PScx5Nls+QpiE/F0eqZ1Mo8Hrlkar/DCMBq98zydPelKogDdhQloY34yw+UzjZKUe08luO94OfYu3m/OrHqNeNPthLX53ntG2iM9l7nGd6+km0q3BK78P7mTFMwni5l3s4nJQsSgPkCHkgGZ5JkQWpMHj7jG0YpHhNOSA1/XpkzlviE9vEV40J1bVV4JMg5V9N1oiINxvptLgVU003QmHbia5PsdYUjiTWkqgWu995c2crJR9rR0Hr2FixBLmPOe36HvkOMgOk9DyPrFxspJmIjRErBdNsw45jQZvDBPNdH2Rb4yx6t2cmmhOmFKZwLXbLY2eZ1awycmK20yb+p9y4OGWy240Mf2Ye4wp69KMVyeKWzcMUruaItB5r5efp1xZOsNiyimDvruZy8mVcU00ux27LO1lUYJDrFlkH2wvmtk2qQ2TQl/M4KhwsjLyMES6ulfSMReTRVKDFxbw2qUfjIPn/nYnHCImdf3pigkm43ZebN+YUaWP2hCF3PA5Wcm1fr4xRKOJpuf73NO3N5toltZQ1NMDpvGcKvMcpq/OEm12stJvDV6TF9TUECHZi9c3Ibrqlgoq4K0BBNcawm6ZficrNWvwAnHw5kI7JD/rqMbBUycrfQktUgdsoWYe+cKLz7fPuXKmdiwNXjUf3zYzKBlDOGlz7fLIZdHgLaqcsY5N+lA4WZnbfSA7bXHOcRo8c8zYtyzToIyb5zogzYSJyJoE8NG6vgYOjwuTkEqDV9ZXV9hwJzZ8k84Ev1mzYaPjLI1MptmM0RxQ9YDZ9j6Zfsd2stIqich8ss9oE83OOcnnN7yENxvMycp6oALehGk00XR/B2a+yDERqHeykqVR13TLNXiBhhcot/fQigYvC8quTbo70lTXFRgKAU/838/Jil13ujKmNsodWLFnnzSfKp1dDF8r2+QwZmiJVCzqXT2qBg9OfXZM8WI1eKVGMGkxm+mo0VHqkSaG9rp3P+01eP4T3PrjMw3tUsd8/Q+L78Yc0HLoJS4q5GQFqJo1m3Tq4+DJSUL7U6bVJDgbCyLOBXJrCUPL+8TInqMtDKVvXSGh2sWUo7uJpkirUwpt80s3FvTV91WXHVXAmzAhG31fHBvz6bM9r2rwbCovm4YZ5mKmujIzaPLO0+qiwaMy2KnSjToNni+4bZ+JuD4L0CXy3KGfPTv1VOI6CDLBbt0yTgF38LMMLE6DN86Mc5YXe9uZHSahGXOMOllZDZjbhUlI52SFnd/2dqllboM9YC4nFM131wusiQlXlNenwXMm01whso+Jpvka0w0YQZXyf4Yugc5BjgZvAO14fJgE+7Mtsg8dbw1emr5IpqJr8JSFU9brQAftmRl2zYG65Nl0aulkJa5cbZHmK0p7pAbBXUsj4+DFzvrVYa/B647PA9pQmOS3PdPExWSJpW0x+0aolC2yGFPrmYqFafAQZxbZB5/GTbYzOREXI2yOufZTIvsPJR2ZgFJq8Ny+xqW1k5WA9FOZIHYGt9Liow32mia5PS+PU3/l9QP+63PHFm5bqtfgye/VSbzWTlbyiW7LkVh0CmUZXA3eEO8Rk2JTv2KuJYUGb4wwCSnHghroXJkkwUrobg9oQapOVmo6SbO4uKY8IRPNaqDz5tbjW4OXctZmHZGzqO5tNM8sXZiE8nu6MAnDPvvCQ5tnFsQ3+Bl1DV7Ho5fF6+EiTTSHFvCk9sEOIm1rI5rC0JQJZh9je2/VQOfDINdeEsqBa0hb2ra6ho6PW4PXMjPYmij/xCHybeW+kIAg1+DJ9FwBra1g4lsb2KzlIhgxzIxH3PTi8jb59XPUEkPpMK3+uL7rkOX5owQ6RzrrFJnKuvRvgwl4RLSbiD5ORJ8moguJ6Lc8x/wIEV1LRJ/K/358qPIsI7FyndzCnoPcDsbF11DrGm9Ig1e8ODydc4jKMZQHOl+P9jcIdYvUbScr5qXQR4Mn8+3+0HzrJ4bC1LltT0a+OluESRihUrZ5mY0pFKdiUd4ZpQfDoZAaC2mm7k62uAPdxvRGvmXMy1OflgmpgZKTmEENXksVSagfD5rpG8+XHZ+3zzGWNO9119NlAq5fQDCCg7nmUsCzJ7HqmrD3CjwbYx2RZDHsbP8FbW6T1ODJvmfIOHjNXjQRdVwIn1ntkJiwGckxffGKG2kOGQfvTgCPY+bbiGgHgA8R0duZ+aPOcW9i5p8ZsBzLS8hO2KNlyH6z9b2A3JkXOzn505hr1LVd00lUB8hc88uPmwQh7azNOhJytgOUz4yL//qZWnR9+bl0NaXpQhEr0hPovOLSHuMOtNtksYwmmosNkzC0gJd9yjVN0uRdTrrEOVnJ0xhxEOJqsJV0WBo8qtYLl3RhEvzvZRnWqEv/wZ7vLL679Zfh19rJ7+SMLdqZaFYnCS3Tf5NXtJMVzr16d3vHlXFmnRwH0eDleTUJr8bJSkfVjpx0GNorMWCcrCTS4HnGGMvy3uzKYAIeZ63ttvznjvxvxW9nWkKD9IpgZw0mzCCiPN5thnUNM66zz2fmQho8Z5Bch+/lNptpoPM+zNmeUbX2CfPE0slK947anRzois8+fii4qKfVfe426RhgapMO9oBmWmULsdgwCcNSOp9yzN8ci4Y5x5nfyfTGYl3WpiwCZvnupdp+yBzThlA/Xhk/OMKTfF+3eRdYfXbN2m5bc12/Bo+csYXdr3GtYGIfWR0HxfaRUvgmsp9COxPN8tjhNXjZZ4zwGnNc8HzxfZw1eCmd0ow3xpgKg67BI6INIvoUgGsAvIuZP+Y57HuJ6DNE9GYiOn3I8iwbXm2cZ7tvJq7SidSaaNppM9er30MaPJ8pUltMh7rqqvMhidXgmaP6dNTJwiTI74MLeFkG22Jg45ZDlmFUDV6LPHwz6FNnUYIDY4w1eKae2PWprFNl/9jKycqIN83nvVBJg5wsyh6t/f52SabBqwh49Z+xyONLf1XSi6ZbIHYEvGqa7tjCfS/Uar7ZPjYrF1e2xcg2zKUvgq4aPMPMkRKHaFmxa/DMtXR954fiGA4F0TBhEjTQeQKYeZuZHwTgNABnE9H9nUP+DcBeZn4AgHcBeK0vHSJ6PhGdT0TnX3vttUMWeakIzcy5+9xZqDoTzaat2fnGTt7e7lu83YSrBczWC6oGrw9yFrUi4Ilg9KnDJPQKdC5OHtzJSmgSBP4O35iljONkJT4T3wtr6izqhdpWO9EFkzqzXIfMFa1YtJOVnEVo8LT/TY8V6BzNglXb+hrSyoTDGfk/YwkGOjflKSwfys+Qszc3PqB8TxkY7e+JbHNFXg3nmPtoQuR0d7JSCl22Bi86iWhMsRrXF5L7pR3ytFHCJCDdO2PMSeSpMIoXTWa+CcB7ATzJ2X49M9+Z//xbAA8JnP8KZj6Lmc864YQTBi3rlAjGwatoznznlhihqfxt4wbhbJrtLtaaVMIk2LNuMY3IPaRwS7wmDXAIGPJZOC93y5TGvIC6d9R2mIREGrzOqcTmlQ9ovGvw7GOyWWN726Bla6XB80/oTJlFFVM+x6EonazYGnS3LTLiBkflMSNq8Bq0Skp3pBdIaQYYartt62uoSrnJl32c/3csoTpSMdEM1Htf0OzCoZU3TALX3hPfejtfCZved+bZGA2eZeFUe6ZTnuI+OKEWBuisS2uc+mvrq8ELCehDMZTDvbr6sUoM6UXzBCI6Ov9+CIBvA/AF55iTxc+nAbhoqPIsI6EZPrdyyk+fiU2jBq9iolm/XsXMcG2F4uC10eA5x5gOdVk0ElOkLtD5lljbUMz6Jcu3z7lSWBn22RdeNIUXObccUtArvWgOWqw8v24HL0t7Gdvlf5Ev8+BOAYo1c3PbBIidtiidbUSlN+ItK8o6QDDmdSfzyph9z8Ik1L8n29bXUJ2KXSufRoPHcE3/5bjAFurC5n5b82qZmiZGbGGwzNPd1qzBK61giFxHYvH3qAxDRJUxVmpirXHI+WxL3TMbgpRjQXeywN22igzpRfNkAK8log1kguQ/MvO/E9FvAzifmc8F8HNE9DQAWwBuAPAjA5Zn6SgFt3pBSgqC5kjZqVcFurhOMkQ58HBfHKZTjk8r5JZ+WQasU0R68at7RrGuleuQXrV6CWZysDDwiLZuQFMMVIpjs8/Ms9q06qQszcSKFmRRxWxysZ4Cb5gEeCYNuJ0Gb8y+cF3WpiwE8dwtDV7g8Lb1NVSnQhZAbjDwto88GDi60FyV7cF8Who8oV6oaPA8A/AmLbx1rGOlIbc1kq/7yryJk6N9i0siy69IbjJhEszuZQl0nnIsKJ9/ab2z2v3ckF40PwPgwZ7tLxXfXwLgJUOVYdmJ1+CVldWdLTbUtWfXQNO1lXdxY9VUyiW0H424GjwyTlaUrkhB36072/NqXekl4CWambTDJAyLK/z6TB2lubF5QY8y5m0zgPAMaKbOoiZuYoWqPlgTX2bwPC+fjFzrFFMUVwMyBl3N9ZRm5kKDZbREQHhCq219DQp47gSx+XTe0+0FvPK7nBgrBZtcwBPCmpxc9pW3cLLiGYA3raP19eO2F01TrmASVl7MAHoIZ5xrwd3rHKI9x15baaLZVcCTS31GWINH6foiu75Wt60iQ2rwlKFxK2dgkEz5v/K3g6ex1zVes8f1olldtB1MQpxTzZfGGkyvKJmA55+J3xbPRi4C74qsJ30G725A2yGpcyrguwTTekYJdN7idWbPSA5RmvQsql23dWzSBTmglSbSrlaMOdZEanEaPLWgSI80E87ecfWCVdv6GjTRZPe3/X6uczpVh89DpZjbEGuXzT7HRNPrZCWfPC4mSMrjGe21Ru5keJZH/Tlmdy7fOWES4vMOO1lJ37aK9fSRYRK6yma2k5VuabTLL91Y0J4QXQ9GcbKidCO8iDmg0oN/YJ/ZkYvjXZNNK+3cNKFOg+cshJbn2p/NzahyjaKsaibUDTvgvY3lZCXf1mfga2nwuifjmBsO+9xN8r41eNIhQFEWo8EbtFTVsrQ5dllaysIEPIwX6NyaYIGnX0TLQOdjavDM57JUqCXCFVBK4SOVBi+Qr/MwK1YKgXdFE7b5ZKlxcx1+yPSbnaxknz4HWNLEtak8brlkWtFCEPdbg2eOnJGzBi86hXjKvOqP6+9kxZLQuyXSgtlASyNch4Crigp4U6ZBjVwZjAKVwYTBlu/shul2Pk0mmmZfyMlKPw2etMNvPl+p4gZalthOVuJm/WoRp/ZZO+eNVzQQxYy1x1PbXDYmlLO4oLE0eN2OXRaNy0IDnQ+twUPZb5UmQGU7K+td3NiInAHyGHDhnn68PNeFzOTPaKpQNODQvW5fX/0nNGnwujtZYfHdpCU0eGZ0KfpUue7OG1Mt/9LJyYr87tGOxsaKM+azZg1eVwcpIQ3eEAKLeZfFerbsHOh8bA0e0vVF/qUYadKeKirgTZjQDF9IUya1Ml0HUjKNEKW3OPvIqjOB5jL4ylnM4q166xsIy4umG6vQE59r1qMX6BsEtjy5/Dr0c2/jZMV8yWYSBy1Wa2wPcRMrXIBFlTJzsjKSBg9s9YUyCLT5bKPBUycry08Z/Dv7TSgtAkL3Ol2g89D4we4HuaWZN3v6bIatucq2lftiA53P59V62GRmbQtzdrlM/rFIXwR2KKAWaeQHE9mOWoaYPCne5bEavI7vfPv5jaHBS+hkxTvGWO1+TgW8CROy0XcXRUtBsOzYyuPJeC4pftvpydmcLI16l+KmYbtr8FyBNKrpOAdlgUXHn7leJeQL3J0c2BZ1qphp7eVkpdvLz6Xri7gLJn23/gKeSROYFzSNMujtYgKUnZe+LEOwOCcr9TG0UmD6rbkY5doebcvPGGHT9UI4Busx7BmfudPXSq+8YQ1eWxNN//Fu8j7LH7k9FmsNcCmtCmHWMdFke2LDvj6yztn2jH1cAdFXIvebz8lKE2bdV9b3wxHOWvTPllA/rAbPpNhUZ4xgl8KL5ggKPGCgidV1cbKiAt6KIjtfghO/xDnW29brTDTzT9eLZnXxdnsNHonyqAavPW7cH/cWbs/LZ1TG6emOPLfP8/LPrg2DzwV3WY7qRkJaU5E6WmVh3bPUJRmIBZWTefgBSbl2hy2Nxpzt0UR0WRaowdO+Ny3s9LXCQhOhRtG2voadrDjv6bm9fS7eCW2whSefBg/FNvMZcrNvyu6OLVwBrb2TlWpf3xjovMiPKw7q2jSLQujC8Bq8ePPTfr2gPH82go3mUBOry+J1ui8q4E0YV0MX2m6PH3wdmt3wqxo8mTjKdUcBQvGZfCajTbjHZMrGUeaGVhJ3xtO9vzI0QOysXx2pTDTHXINn0t/2mQG5n7lZ0FhhEtoNINj7fcosTIMXaRbZB7l2WJqIudoEZo4ykXI1IGPgyKJKIkpzeCo+fdY2kmRhEpz0gxZALR+6zySShYRX1t8yv5CbffOtEgfP6ePqhIpgeUQKMq8QlGuNjAaPRFtt03+VsekcRy3RKcQTa41jbl/XvnAEq0yLGaW7X831Y/VQAW/ChDped7sclLpCFuDR2NV0cUJGDGIauavBM/m67pfr8Ac6N/tWvPUNgL3wnSv3sBRq4mf9aulovuLimw0eijotRWUdqdlB06uPttZzceVowhcQeWxiHZv0wSQv17fKdmbFwYuYxJKahLHo6nBDqcdnqVIE4w7c61T1taLBY3t7k6AZk649cZgLNjPbxNgV0KxA51K1ibAGbyPWyUohxLafOMzWR5o1eHZLbdMsTNldM89BnKzEWuNIJz8dsJ2sDC/tEYYJdC69vq4yKuBNmHgNXtmZhTrruqZITueTzVyFzyjWmngWZdtaxObG4zYwqW3UMUZ7rJccV+vOvAgNMECg886p2GcPrsHLPysOVSDbVjn4IYzzMmsL+wo+QcYU3kNkoV/G0eBl7a7aJ8uJuBjrpkWuwVvxcc/CKPoRsbYo1CRaa/AClaqSfmj80OOhe71oOu9x18TS1x5n7tjCsa6oD5NQfYdYfU+Rb92VlOczqn1/qzilxQRqd0+c0Xnln0Nr8LyeTwdkNkt3v3wTohN+bSZBBbwlIFQJK6YXVgUuf0jHJdlv+zzbyQpy2/MwZZiEqoTnzl434R6T2av7TUCVZpo0eOaZJVuDl8j989zT+Q6FKadPA+3WXSMY0BQ1eOL7lDV48j4vTIPHIzgFEJYHcoDpaozn2Qxac3ImvRFvmq7BGwbpMh+wvWimutehGuUm73pK7TrYnVvtupwscycOw140q+aaZot8T5UXEu/9sTqJV7bJRu25MQtkrixvadMUy/zs9+QQbcutXyEcRWlr5HljhEkAKNk7w35frkf/pgLehAkGOne2s2efrL9ZB2P/tvA01LqOovR0Vd03Z1iu+JuomK4Ie/UpD1qnimtn7gpd5plZYRISafD6PK/Q5MQQmHmJba8Gupq3mcWd2kvBZyI1ReyyLUiDx2OswSu/+8IkFJoTjvPoWTqbSlfGJtqY1yvxuFot6UUzqMFrOYIO1e+qiWb+fnadrbTsQ6xJOWn6n29zvWFn65mlgFeebzYbAU6+p2S567TwvtL7tKSxQpCZFOoaw04KurOBBbxCmGy4ttKLa38N3jhhEoax+ghZx60aKuBNmLJec/12ru6TZ2SOS5wN8qeTNqN+hseNVWOVTYifMY3H13aLvFe99Q2AJeCJWUtD8SKGNCHpnl+qAK7jhkmwBzSuUFz5pKnGwfN/nxpT0OBxi9n/rkjLg1KDx976FhcHz9aAjMG6rE0Zm9LhRqmpajbRbJdHMA5e4Hfls+Ujtx2gmDRYXKudbsVEU6RVCHiFiaanb0b9PbHnkcr3nFvepttKlJ0orTcMbfqv4j7MqmOs1LihKUIUcfA6vvPHd7JCyXoirzO1Fe/mVMBbAppMNKXWTna0JWGBrpJmTX7l+bkGz+tkpd2MoAY6T4s941l9IUnPkbGzfvF5dz/XfjcP+9zrwniEPMOmNBVJhz27PVVkvMFFFTPWsUkf5Nphn8maZfYbkx7s88ZAmpYq6XBvJ5F4VweGsK3ra+DwZicr8e9rXzpWWuhnomnY9lgBNWnh2fO9t5MVT9li30/mKLnspE052lA4dGk6UGiQu0Aja/BSLo3wjTFWfSJLBbwJ43rJDG2XAwd2Om9DXVt011E1OSSgGgGMWRYsnCcCh1iBzptPVxzcTsx9GUktQuHtrJeJZreXn0uXF3FXTPqFsBuYiTaUcYymVSMnLNNZ+NbqjA1j+NlnK0yCyVe0wWJgPY/U4BkvhAsQ8CZW1Zcezs0hSw0eVeqFS3sNnv+ESv1xLBeaNIlBPH02iwFAVYNnmybXOlnxjS1Q3278Tlaq26KdrHDVA6ZMpwm5Ls5ysjJA43KF6hB9nazINEZxskLpwhPJdMrYpGnSnioq4C0xbsUPmWxlDZGc32K/J+26tmvO9zup4FoNiYsrEGQ27/HnKzaxGjz5nPp01O65XR/ZmOvJ3LUv3o5fYF7QPq+xi0SWdMptZWsCAt6cu687aZ+XFOqq/eHcqAYaKNcCjXfP1MnKMFScrAgNXvBep1HgeSb57O0+U/UYvBo8loKUPVHLAEJr8FzNkl+D1/5d5R/H1ydSaOLzY91+I7ZthLxoDqEdj3eyQlHH1aZRmHmO15+mYbxJ5KmgAt6EcTV0iPgtzSEMBNfJimOyac0uoVh3FKJ0shIS8OpnJq3jnUEzicLqIKM9LO6nT4O3LZ6Nuy6kC+65XZ+ZLWR1Lk4UpowhE2PA1sBkkw7Tc7Iy5j3rw5heIEPEOjbpg+VIoQhH4jH7RZx2hhbQDzYKHUonzN1stwavXYUNO1lxf9vv5zYTsr50ALvfdK81FOjcNtG0t20HxhCx98Q3DirW4DUJQWTGQezX4EWVQGrV7DHXME5WSmGyDrMOuc9k19gavCG0bOx8rioq4E0Y2+xBbC8+2fksd9phEvwLmr2/8xm4Ovt/s8c7QPaUr45KHLzCHA6r3/oGwA7mWb2FdqDzbFuffto9t+sjs+MVDazByz/NIMIaBLjaPZTtZ2rV0X3WU0VOBC3MRDNOadaLwnR9Lh2rVM3FskmD5tLYmoRx8MWGVPpT0bBEOKdqW19DA+7K+KHo2+wJwLbPXB7v0+C5Jppym1teEoIvYL+n5DXEOlmpNdEMJ5HvL81nCVVhKLYPK9fFkVXuIbpA855qwg1H0YVSCzi8hJd0DZ41IVr2xauMCngTxjcLBVRn/mQnyM4xgEdjF5FnHcUsm0/Am1fdMNfhm9yXa1mUdrhmM27naDtZiZv1q8M9tbsGbzxhxTVR8u4TjouA7B5NTavRZFo6FWQ/sahiznmMMAmlSZqsRz6T4BiPnq4GZAyaXPcr3XDNFos5TA6/cdvW11A/XqfB69OHuMsBgLy+mzV4s6oQK7dZsXmdba6JZik0hu+Jfy115MUISg2ebVJbpB2ZZrnG3X8vUhLbv7neSrtQptE5iWhmlG4caE/kVretIirgTZiQCYcr+MnPwq7eaRW1TlNkoHMuTROCx4uZ6kqZ4VEb1eBem9Q2rrqHoyFwZ2Td+2uFSci39emo3fUFXd9d9uzrsM/dDXTuNXEWAxYCZQPyiVXHiRUniJzoWWSYhKFnnOXaYdl3m0uW69viwiSUaYzFmO1wnXA1UJbH1UCjaG+iGcg70FO4wmXrx+2pK5ZliLhGd1uovKEQTOZXbRw8rn6feyaXYvqBrN2WmvYuXjBNv0dkT7EP0aoy89fm4/qGSZBpDO2V2OSVahxoTWZ43v2riAp4S0zI9AKwO5FWJppmW02+xSxbQAPSZqG+38mKavC60qjBE8/GdHJ9B77Wy6urgCdq7NDPvTTfqe7zaZ0pX0MxNS2ZbDtTWOcWwg6TsJhyzhsmrVIgAzuXA96yDboTco3pYfx+0O4/xst31SkEFNiDYznRVqFlfQ3145VJPiGMuWEI2hByjFVOHJpr5Mo293upKbPHFnNhcZKd06qIAYumyHOlBs9KM+4+yTV/8tkM8R7JgrLHa/BSWO2MocFDSg2ep46uOirgTZhyQBAW5Nzf3g6N/Pbu3jzzGeem9j8jYNszGJbx1WL6MfeQzMlKmZbSDquueJSp28L5QwoNXna+mN3s2HVaa/CGFvCK9VHhIbdsR2ah/ZRr45TLNgUTTWCcAQmRrRmRZnDSLX4bc6pRTTStdZ1TrlXLhRv8Wz7b0IA/WaDzwHhBhlXKfrfDpzGTpv9SA+0T0HxBz8224j3llK0+TIL47lhiyG3NTlaoELx9Jo2xAoc0K01h5VKbF+ImsArtWwoN3igmmsO8eNVEU1k4ofFnzXDUu7iY8n8hyBmgc8RsUGhNUlsNXvWYMiioji/aY5khcHWQJp+NXATeB9nRd51tGzNMgtHS+dyDu9vyIUFe3wctVmt85Z4iUsBbXJiE4QOdA9lA1e0DZfw7AI0m8EVahcln+nKGmII57SrihqQplyGE33NttSyh+l0NdG60Y/36XZ+2V6awIdaksrMNcNbgOUKDO4YohaVwedzJTXm+TKNRwMsPtpwhWe+4uPtUONZBNwGxDVLbWAcVnz00eOZzDCcrSOhkRXxXJys9IaLdRPRxIvo0EV1IRL/lOWYXEb2JiC4hoo8R0d6hyrOcsPhfbnYGoeKz1DxIFZ59el27NLbnTWQaPI+oKQc0EW3HdwwV+1a78Q2B+8J2TQ5tL5r5C6hnL5DC/MSeDR5YwMvT92mgXa2eHBRMrT6OadbaB0uDt6AyzDnOsUlfzJqRueyTCxPNsk7FrcEzE12L0eBNrb4vM65DK9/6NJe2GrxQlaqE6RDCjzVJ1DLOp8+8U14PifrrbgP8YRKqTlby9MGV8138lkzt+57CyYooWBcvmIVQOnOXMaRvV/N5rJOV7Jh+6+7zz+5JRJMyPJFvjLHqPdyQr7w7ATyOmR8I4EEAnkRED3eO+TEANzLzPQD8MYD/M2B5lpZQ/a6Yborv7oCv1mmKk0bMbBARBcMkVA0rwlTW4FE5ENPxRXvcl5x7CwsBT2h7+3oXTOECekz7eJO+dDhTlsP+BEwspOnZaLKv4BNkTO1siExrNvyQZJZreuUavHJAbT7jYvJJr5xjMeFqtNS4fW0ZBLzORLNdfQ0d76Yu386258nuD79cZyq8aFoaPHtb9r2aTsVDd0WDF3dPpDm0uy1Ge8X5y7M0HRVWTm01eETO+VGnt4IRO2lkPrv3hcYj6BiBzlMujViWCdGUDCbgccZt+c8d+Z97W58O4LX59zcDeDyN8RZeEsKCnb1f/nZni4HqTEtdoPO6bXYafg2eZZIU0Yjca5TmDDqD3B5rMD0Ph0mQ5jl9G5zthbXbM7MnJ4Z97uXL31d/q8cT0pqKpMI1x50qU1iDxzzOjDPI1mIwPGa/UjVQl5RjrjYGUxDGV5FCg+XZnuouh97ZITN9aW0jyxiLN0yCqPv2Gjx7G2CHDnAtIV0NXnFOrYmmb5tnsjnGRDM/ww1rAbTQ4In07GUM6dtVZoLeTOlkpXtehdA7xgIvonTvDGvymyvbVpHNIRMnog0AnwBwDwB/wcwfcw45FcBlAMDMW0R0M4DjAFw3ZLmWBVOx3/qpK3DkIZt4wGlHW9vL46raD8tC01nkW/Gi6YZJyLfWMSMqPF1tzMgbQDtmsF8JdG6tB+zHpdffjr9835exNeXRb0eOO2wnXvSke2PDeeNV64b9uwzu7fds1oUUGjyjTduYJezQA5j0t8VAR+wFANy5Nccfv+tLuPPgvNDgtS3X1667HR+8+Fo8+xF7+xfag13qYW/aV6+7HX/9/m5t6YbbDxTfF7XmIXaGuy8zyrV2KCcRyj653BanwTPnDVDQALYZU7p0v3Ltbfjwl6/HMx5yGn7v7V/AbXdugQA85xF78c2nHVUc94lLb8QbP/71SY677nni4Xj+Y+7e6dzCyUo+KLbXZFXfo+4xMcjj3XeyRE409Ik/6jWJFNtLAU5ck4yDJ9JywxHI95TMaxYp4VUtMWyBqw7KzaxZtFPf82qidCzjOFmJOrsdMVZXpixAv/Vz44ZJyD5TW2CUE3BT7GnSMaiAx8zbAB5EREcD+Bciuj8zf65tOkT0fADPB4A9e/akLeSEMZXvzZ+4HDs2qBTwnE6P5fEe7VlVg9eQa0SdJwLm2/mLiQjbYkAjA6k24bP7T7X25F2fvxpvPO8ynHzU7lEGd2Nxx4Et3HjHQTzr7D3Ye/xh1j5bq8OVezgXM6OlCUm/8iRZg5d/bozgzMTnXKXcl33educW/vTdFxfbu6zB+9dPfQN//F9fwrPO3oPNjfTTnVaYhIHv2TsvvApvPO8ynHLU7k4v2uMO24nrbz+wwDV4w4dJALJBD0M6VJHma+K4qLKMb8kwlAbvrZ+8Ai9/zyW4z8lH4jUf/hqOO2wnbrjjAA7btWkJeP90/mV4ywWX4+SjDkmWdwpu2XcQ/3zBVmcBrxQuzAA7387lTvkelcfEIg+338n2cfL97IbVaYOvrkiNpHSW5jOxtJ2s2J9zR4NnxjzuhKbEF+i8i4aSxHWQ3Oik3UShtaVuAmIbYgWgJBq8BGlE5yVCxWz0zE/edccCeGUZVMAzMPNNRPReAE8CIAW8KwCcDuByItoEcBSA6z3nvwLAKwDgrLPOWvFHUmIN1ufV7ez+Zin82bep3oumm3bzYEhq8GYzANuyDOZ786OqaPDgvPx6YLQN7/6lb8WhO0ep6qPwr5+6Ai9846e8cQhtN+fVl9G2qDzyBdSHFLOTpsPNZriHbeIm9XI9otjnuaeUe9FsW6rtvNFuMw/S0drlHiADgblX7/uVx2LnZnth9cbbD+DBv/OuhcXrYx5PgzefSw0exKRbOQnWZr3MmHDge19MX3ww92z0p898MH7ujZ+smPlvzRknHbkb//3ixyXMvT9/9K4v4eXvvrizJsGdTCt1W+WEqHyPAu3rqzzcfifb99jSXng0XLH4+01PmASU7yWrjDVLQ0rrCrvMtQo8jzDns86IDnTO0ilJewGteKc5GrwhXm+MuP4ijZOV/lrAWKQGr6+RvV0/wpO8q8SQXjRPyDV3IKJDAHwbgC84h50L4Ln592cAeA+vut/SjvhUyXWBzq0wCWR3rFUTTZkPotarmFkuANgUxtjS7CPmSfqcwaQKdG4GD6ukvQPKWUzfYLkp0Ln5KbV7vcMkWPl3e2imLJuzWWtvbm0x98i/hrR6PJGp7+2urQzW27aEkXheWENh7lXdDHodqdp0V2LXqPTFhNMoZ4irFg1zjptUoeKejXfTLJO9hPXWtIUDW1mis5k9SWiYz7neDG9BbPSsv3VeNE2am86iprZ3QQ64ZVpumaUDkj4aW1lXrCUa+TafBk9ek9eLJspzZB7s7G8sm7AoqiuDD+NPi1H2GdVJ8GbCYRLSt+d5rAav+OzexsyZY8UVBdK8N9bRQ/CQao2TAbw2X4c3A/CPzPzvRPTbAM5n5nMBvBLA64joEgA3AHjmgOVZOmQVtEwNao7z2Z5LrVj2226ZnZysBGbibBPN5kbk86JpkuvbCPsOSqeKGWz41kO5C99DHaN0htM70LlIoOsjkzO0i3WyUt1GyAakbV8y5vlszecANtoWs5ExHWJsFZMlHRMQs/mLQM7GD0k2OGRrkksKe+YzpizmXg894SHpY7JXx/a2LeBtEGFjVm43bM15kv21sbDems+xMWvfll0NVGl6VtV4GbpU16z/dNdFO0K0Z/LBd1wTvpiJnElGAGwnQVKDSWQ06uX55lj3Hrhjibp74iu9a+3UlEZ+RJbnvPjayQtmaSFDziRo3PltcJ95CHMdfZrYmGvwhprksrTYK8xgAh4zfwbAgz3bXyq+7wfwfUOVYdnxmRzI71z8NrNcHOjQ7EDn1Q5Odl6c257XN145qJcvZPaUrw633RpzON++thQC3opp8My998chtH4FX9ryOfV3stJfwJOOBobuck0ZvU4IPJkbN9ftB0D54GSgAbpvYmcosjhL3YUk29RmfKTDhCExzngsTXlRhvKzVRy8AcoZwnrPJEzXaOqMiebmBmXrxJz6sM1TFfAyCa9rW547fW2hwRP75HVTx7Zm4oa572SJXMPfpw9xlwMAtjBnafDy48xIhAFrIFI4WQk4DbMmrMlfVp/DGF/X3jS2ydJn61h3EjsGKbjbzuPSt+jYCaxigqGXkxX7c0hSWl/5+rZVV+SN4ehU6UgoRk3IxWvWkVa1E22aSDbwb671Mk35MrHDJDSn4zummLnu2fqMY4Upmvz0YdOYaHruj+t4I3QLkzpZsdLt9szMWRuzdIFNQ9Q5AQrlTYHj6zCB1H1rJQ19BB556tCmj9vMFROyNqSatOlKrFlkX8zgUDpWkTHCzLY2RVkFJytmsuNA3ihmRNjYoIqZ+XzOk5yQMxq8urZcR7EGzd3O2d4sj6rJYlvMrXPfyRL5fvaFOojFF2OOIU00831i4lkKrj4NnnvdRR7F+WHxzFd8W0MZONHBpM8sfRGEBeYQhUBJZAuIA0z4MceGSbAnGLow5ho8qQXui0zB5/hqFVEBb8qENAuFfFfVQPhmvID6Bu3al3PD8YAbsNTW4LRZg1c5pIeWwGV7ooOFvtRq8OR3IfBXD2TrBdSHFKEtrFnfgXtdOduc/ZaTJ366OFkx6fueU3lMy0QFqYIUx5Ctjep+fqpJm64w4hyb9KUIdJ7/ngv1hRnYRYdJkF4qRiJkNdKXUoNXCjNeDd5ETTQrAbhbYp59ZXDMVe2e+70NPqcg7nO0xggeIS0We4KpfOcXliEzMakjjjUl812j+y4qJ0VKATn0vmLPtfi2xdzaYhxUlLXcF+soqnynDS8MxVoFlKaw3ctTCOOjaPCyzxR9kVfDu+ISngp4S4KvHoY67uy73aPKtuh2Nr522tR2ZRKWOQhzq8ZTcbKCdIPBbZ7mgv2+lAv+q/fHnYEPzRbO2Z2h7A51ePm5mGKPq8GrzuJ51+CRbbYTSxmsN3xeKg3e0C+qvpMlhfOEVAVqyWgaPGSDUal5qGjwOG7AZ45YmJOVhPkabfZBocGbOXHfACP8Tq/PrnNsFYPrRZLEdtn3GbreAnNanQZPrkG211y2y8sXpoXB4lqrZokyJq89JrE/yzzsT7lGv00ZZVljxzbM/YQZWeYuJp5tiA0DU4Tp6JFXCiExOq+EoWLsye8Vl+xyVMCbMKEK6VZNX/wXeUy2rk3+tnE1MDEDELnf9hBVHUDXUXWyUpa1r9nZVM19+rJRaPCq++yF71Uvmu6+FJ10ikDnMijs0OaGpozRXjRBxdqWNhjtxHAaPJnOsDet72RJSlObLqQOlBvCeNG0B9HmO4ptMUVZhOdRu06lS7cw0TROVnINnlsfpqrBK/rcriaajpZOChHumrVsf7d7UDrRCGvwpLatl5MV35hEavDENRbCDoSQYV1itdxWWcVRoVvDnu++bU3STRbLMvvnBmCXZWqiXAJh+0AYRsCLXdebf/ZoY6WTleGRa1VTEh5NrxYq4E2YkFDnug4uZrnEbKAV6JwA2RzdfkD+zDRwzZVenrMpIlCyEDdjmk7FlBRyvU5PDd589TxoAmUHu+VRzzXFwbP2cZpOWr68upoKFq7CN0ZwsmLWqZbTznJnBTNr3LY6Gg+B9QJeHwmPfV8Hoe/AWzpcWASp6noTRtMr++FSCyE0eBGlKQc34900e9CeUIPHHgFvRthyvGhu8zTXTBfCdlcTTTPYz3+XGrxyn3yPdr0Dps6472QJi+0NXV8toTGJ2V46CZLLAVBcnKXN82j1snTt9F1hyXuw+OoLdB7nZMXR4In9sVXAEmoTTILW5hX59EL3uQ3m3D4m+9F5mTqUYt2iuEXrEuhcBbwJY3eg1e/+z3Lm2FDR2LXIN4ScLZJasvm8nQYv5JY+2xdRkBq25/OVFPBKc6HqPreehIRkY56TWoPXPU5U9umb1U/N3PPyL/f58x5Kg9cHmergGry+JprFbP5i3qhjmf7NyNaMZAP4bJ8crMYFJc4+x9Tg9THZq8O0AeNkZWPm14pvz+eFE6kpYcrkC00TQ6HVykdcvklM2b661lVznvtOlhTefdkWWNv2Ib6QGizUdbYGrxRwfVdWCA1NGrxQAnDGS55xUBshyAiqpQAqNaJx6Zj83EDnQ7Rn5jiBq9Qgp9DgjdOfAqlMNKt1fcXlOxXwlgVfRQzNzAE+08dw2pXZJa4/HvB7wDJlcgXPOioaPJKdfL/mN1WX232p8+hmCXjiWfhgpFqD1/7l52J59By41zVl3PZ08r6szQxs20szg6c6s64+Ly5pCjX0i2re00Rz0YHOGeO59Z5bGrxSpyFNNduESRhzmnm4NXhZWmYNXhYHr7oGb6qOseocW8UgzfWyz2w7i32yfXWtq8X6qNowCfmns6Pt47bW4M3LtEthjCrbZrNS2JlRVUSorMFzylYj3zllq5bRJBZTvUotfG6iKUbKsVXA3JMZkdPe07dnjpzA8nkwbUufdYltSRkqxp78XnXRLkMFvAkTqpBup1cu3vcLV+7C5IqTFU9DbTZj8M82ulqjpobkDnDNeqdsX+2pjWzPx1kIPDZlTKbqDWoT6FyaoPQhxexkMQAYQYPnffnn1DtZaZePEezqzLr6WWhmJ2/M2sfoa8v2nHtpVoopmwW9V+fzkdbgwdbgQbTBot+OnFhJZcnQBp+lSArcOHjGRNOx0MR8Po7pV1vqHFvFUAg9zqdQeFmCbde6as6yNHhOmeXkQ5+wGPJwnxdNUwY5LskEtFLIdQXeioBXTMKV0llwDZ6n+Oy0PVOGOsqxT9lO7fFQrAYvP5fscchQgc5jakwK4cznqXUoSiuGBBo8T9+26oLeBLtSxRDSLNTNvPlm52TwcMC3Bk/O9rFlmhCinIXzCHg1ZXVxd5vBdMy5TcznXGi7Vgnz4mwOk+CuspD74mf9mkgxO2nM1kyg6CExyZeBzuWERPX4ItB5y2vbHlqDl3/SCPes72RJyhd1F2L6tBQUTlby39lESi7oFwPruAF8uW5xvHvmC16dgnmhwSu1VRuzahy8qVpdbPTU4EknUgCKyig9rkqtW9e6atKwtO2V8YL/Gbe9spBzt+JaZ2KbR0CT2jifMxOrfB4BMao8nutrbHtkrkOajpa7ozV4wirFtpJK354ZLZ2s9DLRzD7H6k+B9BODPsF/FVnB4e/q4DMvyL6ytcnXuVpr8CoCXV2ecR2QtE23NTjcyq7fl1eqweA2T9Pcpy+zGhPNNhq82Fm/JpJo8LisS2MHOi8HA+F8s3J1y6duUNjnSuVM+Rj3rM/AW5prLYJssDbOjHNmGl1qNMo1eOW2KA1e0Q8OUVI/rhfeVBRr8LaEiSb5TTSnaHVhBKbOGrxSvsk+ix1SE18e3/UOFBo8y6TQLnMx0TC3NXitvWiKuiLDEZhULMdKloCWfxcXGdIs+dbgxWjwpJbSt78OyjOUk0L2MoS4dEqt5fBr8OZSGq0hSZiEgDA+BKWmu/9NkylIjfMqowLehLG0Mb6ZVWcaQmrPXC+aVlOskfhMGk1Nt3THbHd+bWPr+OLgpYp9kgVnnt5goS91s8mueWyoYzRmZKk1eF2fmQn+bDQgQxIOHeE/ntDNdNR4CAzFIgTQyztYOZAaXgjYSuC+PnNAspg3amxw8b4YDbQMieAOJuKdrKTpB9vgGwSlwKRlnKzMZtmfLw7eJDV4hdVEt/PdYOZyDZ7PRLPre8vrZMV5jHKCy3pXt7w2dzIRsK+nHBewI6AZIaMaE6/qZCVPQQpLgfLY1dWexJOlaLZOomKy3BfSIbZdSE3m0GESYq1xSu1bf2uMMVppyrXb/riNq40KeEuC1768ZksrJytWCnFrs6Q3JtcaJCSY+qgM+EiYQ/RsfVM19+lLrYmm9UILz1CZfanX4HV9dxmztZmZPh2QkIlzUPigbmaQhQZvKBPNYgAxvInmfN5fQBpjfWUI5nHc78/Ib5aZfefis81gbEy8sc0S4NXgzajSNqbqZKVwbNXbyUr22wz4zURblocQ8LquwTMCnuVkxS4zW9u7P2/vZICYZPbHwStFnWzi2b5Ot86XyZb3L0Y48fXpZRmaMZrIcilKewFNCvXWdQ3QBTLH9Rcp1s+l8MQZn1f2mSJkizUuXXXVXY4KeFNGDtZ9Ap7T+cmO1BHvrI7UbZa+htoY6Fx8uvblTWuaJFUNHomZ6/pzm0ihdZgideZC9oxsfaDzVMGfZQrdnRBwUZfGCnTuEtbgUe48o13BijV4NVPjKS51LCcrfdsS0eJMYubMI8XBszV4gEeDh1iHCAvQ4PUw2avDhBcwTlY2ZzPMAiaaU+yzjWOr7mvwsk9XIyRXScvr7noHTLoyLbfIcvLBNwERi18jUr7/pQdES3smL66iUbKvnJ22455uHVuzTV5axBK84hxfqaJNNM01o2rllJq50DbWETKFbUOKNNrmlUaDJ74X21Zb0FMBb8LYi4bDL96miuvardetyctMNJsHQ3Jmq+pF0182H+5uonSzNvOJzgb3xXgzbDTRRI0GL59pTTGWcp9/F7IZyNyZycCdbqX9FGta/fmaOtm2VMZDYJ1ZV5owCcMHh8+04f1eF2OY34ZgjDPjbNaQmsuUgc4LDV6kR0+pARmLNn13G8y1HxQmmpszXxy8qQp42WedNr6OUujJfkshogiTIOpE17rqdaIRGi8w93re1vGOICbLYmvw5Bq8qkhS0eA5nxUB0SpCdWLZ5328SXwmMu/Osp12eceZvs5n5ZSaWGscubSmKzPPPRkKX7zIFKy6YGdQAW/ChDpfV4iTnaDPNKiisavp4OqEAisNsZbA1uC4tvn1ifnWo6TS4E11sNAX07H6BDx3RrZOgzdPpcELjyWiyV6mWV0afg1eqAzZp6/KUAfzwiIO3lBhElAODAd3spLAIy0hjalNF0z9GprsGqXmQWjwTFkQNxgr1yInL2aQwQOdb2WfRZgEjxfNKa6brutzYygFFHtwLN+3lgav4y0wdaZOg2evwQtPHDch17XKtXKFMCcG51JAM8/XUuRVNHl2WYtA6eTGlPNTBjoX2yKvj8x1WOWqpt1YhqLMY2jw4iYFpHDdlXJyv3MS8Xnln2lumRyXpkx3uqiAN2F8Qp3cXhH0nMG9oaKxq/udd2xNKjw5U+gGurbKWp9MobkpyiLK03eWJZUTkamxUWOiad39mttnXsTJNXgdB/Am+LNZ4D4klTUpTmfv1hmCcRDSLh8zGKx7ofep41IgHfpFlcIj7RghMEKkqutNGA10qbWrahPcPi+ENOMbi5DVSF+MlXKhwcsH6hUnKxO1uqjrc2MotXT5BvGOk/EsDV3rqjnPWoNXsVgwnxwcY8TAkE4wzCRGaXRaxMETZaiswSs0mn7Nkts3y/FBpTyeCXHfmtJGE03KQ+KwNKkNC8wh5PskxSRoQ25RdaYQrns0MTd24ZBYnlh74hsfL2rCcSxUwFsSfANBd1Pd2re6xujGwZMdW9M50qQSaK/BmzsztnKGrm+jXlUNnrmmLc+bxu7Ewvc/0ywA3Vd7+OkXJmEcT4t1oSOAqjOOrDq2Ny/cjtHgtUvSe67P1C012wk80i7ai+ZoYRJYDiCqg9TMO19cWvK8MejjVbEOY9pYOFmp0eBNsc+uc2wVQ6nVyj/FdpOivQav2z3wOVlxtVhy8qFPoPM5l31lGVNUCDYmDp7YZhxW5V8r1+n+dsvkM+v0UU5+m8/yRkedz44Gz9oXd5/kGrwUyxjqmHOsVYD57KHBM58jmbwDabSeluJhteW6AhXwJkwo6Gx9HLzquZVA504+vnbaPMtVplXR4MmyNgwS5s7MujT57B8HbxzPeWNTzJp6TTTtF3ZYmIHXPLZPedz822CcYHQxhWxL6AVdmWXPIVAn4cQMaofyoikF0sE1eAk0K4tcg+f2M0NhzGVl7DvpPbMoS0Rh6tr5ULDTf6SiMNHcLr1ozjxeNOfzcdb2tKVwbNXbi6atEWIu07TCJHS8BSaJjUCf7Gox3AnBNsj3h7QqKjVlVBxnaeDEftcE0n30ribOHW9Yx3qmy9yxkixXCDn+MN9nVlzB2tPL4/Kxz8wRSodyshJnFeDXlLbBXUc6JK6GuA/eMfSKC3oq4E2YkPlEVXMnj6tWXHedXMVE00krxslKsdB25gmTYJlF1LcgN36LnO3q2/jmcy4ckqwS9XHwxHeE76Exz0kSB0/0Il2fGeea3DHMDSvtx/msmGhSN/PCwkSzZkTQZ+wuTYCGNjVJocEjGtcjpEGu3xkaI8SWa6FthytmW0xR5DqtsRjq8UgnK2Yd1gZRpW1sT7TPLhxbdbxBsq0CQoOHcjLAtWTpgnwve8vh/Khz3taEfH/4PHn7vWjaQl2pUYK33O54xh3LuOVxv/vGRo13lsrrKNeb2ZPYMcjQGPYyhvRkZY2ZNDKf3dvYuE5Wss/U98xXP1YRFfAmjC3UcWV7xcmK6FytNXhOummcrJRpu0E82yzUZ0ZFM5BKLb81n09yPUdfCnMhz+2pavBC2qr4gWYTlolv1wEQyro0uMOQQPpG2+yrM12EE3O8z5S2yDPBtW7MKKk5nY85J9DgYTEvVNc8bkjMNcoBhNfJSoxL8/xzTKG4j8leHVt5Z3Vgq+yTfXHwthJMJAyBKVNdW67DFS6k+a1JUbavrnW1SYNXZ+HR9nHLPsGnsQ550bT/t8vtXrbp11gcF1yDZ30vJ1iKbZHXV8QoROmEzJoEj0smWObhwiQ0E9KUtiFFGvF5lVrgvsjJDF2DpyycWA0eRGUtBTz7kNrGKDVwbAf4DCFncdwFxPZMWoMGD7aQITvDvk1vPre1S6vCxkb+UvVp8II/nOPygUUSDZ6jwe2CMTExa5iGpJK8GZwUs8z2bqNVblusGA1en2uVXtrG0OBtbvSrK7MR4vX5MDmOMeM8m5k+VGjwxODXfMYFJTbnDVFSPz4tSAqkBs8IS76JiTn399Y6BIUg09VEU5jrAfY7zu9kpZ8Gz3ayguD3NtY2LlLD5U5iyLLIWH+WsEP20hF5jlsm6aQlpINjz4DJJ8DG3FpjVloWVQjMkXVAxgN0x0hDEOVkxTER7kKKYOmxpAwVI9NQL5rKpPBVxKqg5/+eLUyWUpR9mm82udHJijSzcGan7FnC2mQ861Gkk5V+rW+qC/b7UmrwPAKeO0MbeADMYe1eazq8/KrlKevS0J2uW0bXpXZFg5DbBbW9X4WTlZrz+gl42ecGDb+2bZv7v9AJw5gnNSHX7wwNIZsIsN3Gc/HdfMbcyqFiQNUxlAbPtIWD26XWZ4MCgc4naHVRZxYfgxRwAKElEhMAtolmp2y8po6hYOaVQOctrQCkgzQ5iSEnnsw+K2SAKKsrQLnXXQZQR7G/1b1h5xPxYxs2hXTKFa3BEwJlRXBN3KZjQx6R89kFVws9JClDxcROfq8Sgwl4RHQ6Eb2XiD5PRBcS0Qs9x5xDRDcT0afyv5cOVZ7lhD3f6n+FgjZbWjInF7fziokZJReLVwOdi3I3dGTu4mDZgaeIgzfFBft9MVpJbxw88ZJ2X+DWcfnAIoWG0/Wi2gUTx2eMmG6h5H0BhwGhwWtZrBgvmr0CneefYwSH357Pe0+WjPFsfYS8ow7BjOxJLhZtUDpbie2XsvQGKaoXmVXSOHj5tR/YKuvRbEYVk8f5VE00C1PEjho8R+iRQoTZJxXkXd9bpYlmNW/A1WJwZUKwDSwmfeRykUJgLTR4QkCD41ilEHjt8pd52JMj8thKeTzf2TOGahzbmGO5FDC6OBKbi/vgZpm6TWfOiZqPS+NkJR/7jTBlVmjwEktkPuc7q8jmgGlvAfglZr6AiI4A8Akiehczf9457oPM/B0DlmNpCZk6FrNlzgJk2blagc7J7hTdmR75y5juNTXdcrFuNQ6ar6MN4mgGzGDalKUP81XX4DWYaEpTMd9xroObrqSIgwdwUZeG7nTd9KVmBQg5WWk/67otBvSxZWmDnPkfWm7aTuDdkDoIySloY5rVl+IaRR/t66djTaTGcKAjset4unyN1vzA9lzEaqu2jRTxFoeg1OB1Oz/Ut5j3bZZHOdvW9RaUJpr+mbtKDNDA9xgYLATffJu4Hin8yTZYhFiSIgLZ5xR5FIUyAjKF741nvNQp0DmZ6ygnuq1hROSNkib/fg1eunou1wvW0eSEJwZTtcZY/lJM9idYY25PZpiN/dOdMoM9Ima+kpkvyL/fCuAiAKcOld8qEqp77oDU8mCVH2M7WQkLdL48Y/rBUtVvd7jzeTszH9+aCxL7+jBVj2x9qTMXqjPBsY6bZwvsU9wdd4KgC/N5WZcW5mTFzKR7ekVC+1nXeaHBa1+WGIqAwp6Bcmrm8/5ro2hkbZShGFyOMONs6q8MiWAGJ0Zjwi3a3dj3rI2DrDaYyY6DW3Ns5hUpaKLZc63nEBR9bsd25potloPxsq7I9tX1DhQaPOnWf26/E8rvtgl/2wmsOZf5+OI+ltqX8n8poFnhkTyOV6x0izYcbsc+YdUX6LyJzMzaWYNnOZKLS2cu+p2Q6WkqYt/lpYlwd6SAPjRUTCCkvWHqZCUhRLQXwIMBfMyz+xFE9GkiejsR3W+M8iwjvvpd0UTA35EDqG3R1sxP5HR36WTFPt8VEJvaJcPR4ImF132b3qqaaJqXpK/Tszdx8AEYJUNyDV5XAY+5qEtDa3nc9N3JvKqJJnXSpBRx8GqmH32DquhAukIrMPRrKsV61kUFOjfPbaw4eO5EW1G/2H5mMYyt9WzTd7dh23jR3J5bWgRfmIRpa/C6qRLmznMvxDtRJwZzsiL2u5ZA9r52eUkLkHLSudRYz4SEZwto+Xdn7CDL75adrXNiypZ9dneyYjTt1XNihY3SyUr1OpMLFhxXZ4oYdj3amFerORApx2+2eXKyZCfNkCaaAAAiOhzAWwD8PDPf4uy+AMBdmfk2InoKgLcCOMOTxvMBPB8A9uzZM2yBJ0TIw1XF5Ed+ytFEjjSLML8lvjbU1KzkTKQ8thomoVmD55poFusTEmjwVtFEE/DPfgNVM4RQR8acP5vEKryuM23Zy5RyN/OL0eAF1+Dlo5LWTgjy4+s0eN6JG44chBTlG97JyjzBZAlhMSaaxUz6CF0BIeufpeahXJ9kexOMTm/EmzaYkxWjwdueF1qfDaqGSZiqY6zSLL7b+cEwCZCCQPgd3ZbQmrGKBi+wL4a5ECp86/zCXjRLDZArQIU0XVILH7o13nYiNIuGaCcrzKW2Ss6B155dydpyIOOO2VIxZ8ZmRKUJObNpQ4o0ovPKP5MEOrdteOXHyjKoBo+IdiAT7l7PzP/s7mfmW5j5tvz72wDsIKLjPce9gpnPYuazTjjhhCGLPClCs2sVDYTc51k8KoUmoNow5c/YAYhs5JabfHaE0SYNHlfLlmoN3jZPc8F+CnwxpIBqnQmuwcunKKcUJqFY69a7RPW46bsL+X3to8t9ivGi6RtURV+/mCEe3MkK9zd3Ng5IxsY3gB6KGWWu/y2NhtAmuDHCYtIb84710ejUsV2YqZbC0saGPUll7tUUrS7MeqPOYRLcwT7Kd5zZN0aYBGuMW/nd7tqkhksKLsUYQuQvBbQCkiaQ+ad3rZoQkD3aMFke9zt7jmge25QWLqW2yi8w1+G29RSWLiEYcXXGdz1tSaEFjM4rb3dD3C/5uaoM6UWTALwSwEXM/EeBY07KjwMRnZ2X5/qhyrRshIS6snKy81uaJpQnVAes4YYZ23mFzCzkgMYttw9mVGZszc++g8H5RM19UrDhMW8CqjPwYS+auVCVoCxuoPtOcFmXhvei6XvtC292ntE3of21FU5W6uLgeV4x0SZAMNr54WcitxN4N6SRhRXDqOY4hGL9DpA9o1KbJ51NxN1Lou5CRRfaeEBug6zTRRw8p60bYW+SGrzka/Dy7aKupBBsfQP4kKdMrljbtMuLhbbVWtPkXKucaJQmlvJqQxo8V+NVd4fscQdb5XL310OFUOpqXLOE4lJxhVrb23TaNm0mSJsIrXVsgzl3jImYMkxC//vFVl0v++RVptFEk4juCeAvAZzIzPcnogcAeBoz/27DqY8E8GwAnyWiT+XbfhXAHgBg5r8C8AwALyCiLQD7ADyTV/2Ot8Cekap2VHKW2HwWg1VhSuKaUdaZaJrzmswYZKBz102+vai7/nFmJprCe5gwwugdJmGi5j4p2KCqi3Gg3gTHPo4r5rFdkd60ujZfU5YZpfGYVZ+Xf3tooGW0yp3j4NWFSfBca/waj1K7OLRQnGJtFK2FBs/W1FVDJsRpEcr0hje/ldiDoHTpyjZg+uQNJ0yCEZ6m2GfXeS6Owe1bpHbLZxqeUoMXjIM3dwWgdtcm3x+uF025LEROPBOc5R2ORtO97oqTFQq3HV9IBNm/mm0xGrziaKqWq60Gzwxv8gUIrdKIxYQZasKnTWyLW4eHxBQzSRw82Q7yerHqwkbMGry/AfArAP4aAJj5M0T0DwBqBTxm/hAa6gAz/zmAP48r6noT0x/IQ9wOpL7xVzuvpvZfuMoVnXRWhnZhEjKTHFnOdGvw5vNpDhZS4HNQAHjuWUiYQdU8tnNZEpieMMq6NHSnW9HgORMm1TjnhNms/bWZwWB9mATfM4xL37jG7hKjry0p1rPOjO3TyISe6xBkJpps1SlzyewcFwNRe9O5PtheBxNq8DwCXuGQhrN6bAZdU+yzXU1VW1xHP7Z2K/stPV92dUFv0pfm1D7Bx2y3frfW4AlPmUIQMxNP8j1uCWhCi+Q+affRl5rwQjyLe2flh/s0eDHeH12NIfV4xxUCkcg2eYtmjurffGVpSxlLb4wJs2IqpHdadePjVSWmGzmUmT/ubNsaojCKje1kRWwvnKxUB/M+ocjXkVr7PTubmm6ok5az19nvGA1eVWMC9Dc7m6pHthQE1+BFavCMeU5qO/pegc5hzA2H7Xy9697EvfK/uNprUuYRGjzfpUYLePk9wwiasTmnMNFczIu1nLQawaSI7HY3Z9tsvihLbHoY3vxWMnSYBECswXPCvRQavAn22XWhaWKoWsYY7VYWOiMTiMrr7uyC3gy+YzR4Ld/VLj4nKybuY8WztkdAs8w1qdjr5OHR4IXCJNQUX75TGjV4kH1Guc0tUxNuW7cEvMRWKq3DJPRoYyFz2iFIq8HrPpm6rMQIeNcR0d2RyxhE9AwAVw5aKqVKjVpMVlL2bINj1tAU6Dw7pr44spG79v5WeRoakNHcyHSl960+bCVYNzRVZkRej26uKW/o/mfb42b9YspSpttxAMRcPPshO91Q+aSmJRTovO0sohmw+kxpDd5QF5H5mJn/MRzTpJgsGdvc0FA+1+HzMuayZT/M1nog111+Y3ozGnWdyFBr8LY8Gjx3XZsJpTDFPnvWV8BzBQYxiWkmOWWV6HoLiiDyIY2T+25u8a52scIkiDSqGjxXQCu/Q0wUA9Vxh1sk8hzjK7/raVxua5y8Fv2pf/1cQwLOcXI5i1uWVMig83WU2rfuebla6CFJ5XDPpdQMrzYxJpo/DeAVAO5NRFcA+CqAHx60VAqAqjam2O7sL52tSI9tYsbK6dLq2mW0k5VC1W+/mIzJTfm7Pj32aAZSzdr4gqivChszv/MFueagNtB5ocHrXxbq8PKrwGVdGlLLE0paald8A8ysXO3yKkw0W2rwYvPJBlKUhx8YduFiChNNwmJeqHM5uhwBhm2yZq1Pcgb6TWTahPRlDNFmcq4Nsg24A94inEihwUuXbyp6r8HLP30aIWaPZqpjXTVnyT7MDZ0jt/fR4DGX+Zjna2RG+3rkWESMHTzXWxHwKhq8ON2mbxwUe3mEcvmDX+MVOQHndDu2FjCuLLHM53FVJiRIt6EMHTF8QzU5pAmTUFKkt+IqvEYBj5m/AuAJRHQYgBkz3zp8sRTA0cbI7czWNllXzTbXi2Z9HDxpzsGVbT7KxbrVBchtzHwyMw9RFpA3tk4XVtlEc3M285poVr1o+u+hMc9JH+i8+wy3qUtDCnh190MGppWYOtnehCnXTNSc50sz3otmNlU+mwHz7VZFa82c+6+NWpSJpslyPA1e2e9Vnaxk22MHR2M40JHId84QcfCAsh5tuhq8NfCi6Qq3pk5ka2nL47tr8HLtqOed7vvuCwQei4y9VpzL5cSTdHFvCWhCA+QKP1UnKybZsm8OvbPcIO6mjMU2lPnWQVTtM7pp8GwhsYujllgyC5jmSpPEyUrhf6FzEtGQW7/6YI1L2d20ksR40fxF5zcA3AzgE8z8qWGKpbjE2A/Xzr7WNEZ3NjEG2SFXNHiWYFqfoHS1DNidft9GPV9lE82ZfzaZgz+qxNrtN9F+brMKc1mXhux0Q2lL7bc7wDRmRW3r41aMBs+3LTYfLgc8Q5vxbc3nS+9kpfO6phZQXlHkJFw5AVfOwMWWZOxb1mfAH8I12zd9cmH2mJtm1mnQF02pbewq4GWfFRPN/J8ruHS9AyaJTaEGtc0U7e/2Ov9218aoCr7meiAmlVmkTbCvzb1O97c3RmnEzXFNNO1rbU7AXE8pNPnvZwzeYOkDNOqYOpNC6xbyeDoE5Viw/w1rE595VYgxYDsLwE8CODX/+x8AngTgb4joRQOWbe2p65izT3Z+lyfJ4zOzCPm7OoB1025qu/a6uRoNXoPlmOvoQ2ob+zbqFMGZp8oGkV/Ai9TgmWOTdPgJZial5njIzjfsdCasXaF8W5trk4Paull//8RNXD5ZHEOj7Y4uWifm8/4v9EVp8ErnOcPn5dPglWvw2peFRhDeJX1M9kK4/ZTpk40M4mrwpthnF9rGjpbQ7nosuQzBaLzsNXjd7gE56cu8ATghjPo51ZFaI8sZCttjDjkmyCZwTRmpIvCGNHilw5LwNI13ssx8ip2NGjxU636XGHbmXvsCg6du07HWOCk0eD6T06Fww3D0wTeeXnVBL2YN3mkAzmTm2wCAiH4DwH8AeAyATwD4/eGKt96ENHJVzZ2chatuMxoI+VtCqHY8TbPd0lWu7PzkjHX2u74FMduOPjJzuDKtPqQIzjxVZhFeNN1n4bI9T+VkxZ9/GxhlXRpyQBtKWmqeq2ES2muf5KC2blDoK0/s5TOXZRv6PZXFlOyXxhjhHHyYLMeKg2c8I5rM5YRcUZbIhpe1h+TFDBKaVOyD208FvWgWA+Lp9dkzR1PVFhnoG7AnMc07UAoA3ePgif7KybtSJiONFb9bZsYyTEKxSazBK/fJtadSJ1Z6464KpiY9+QmSY4+wxtnSmjs03Vk5yegTPGNvk9vvuOOklDDHhdZIEeKgnKQYpz8F2muXmygtLFZbwot5Zd8FwJ3i90FkQc/3OduVxITj1+Sf7P6WTlbK49s5WYkrm2VHL8smZqxlGUMwV91iF7OCPadt5ry6a/A2yB8HLzbQOZANqNJo8Ow8u5BpE83sae8i1eTj3z5nLuNwee5JW+2THAjWnee71vg1eOVM+dBanlTrWReiwSvUB2PklsVzK/thO2RC+zAJI6/Bs/ruNPm6VhzFGh4ntpz5nOIaPCArV9d3UlkFbfUHo7Risa664y0wGi77nSzLYb+bQyEUYpDvVylQcW5ZQOIaTcpyu2VV5NFymfRk+vLaXCHFG+i8ZmK8Dnael21eGanBE0Jt9kmVfamQ1hx1+O59W1Kk0TavJBo88V06vlplYjR4rwfwMSL61/z3dwL4h9zpyucHK5li49PW1PyuOFlxzCAlvgF6s4mm+SR7dovrtY0uRnMjy5JKg7eVwPPfVNmYBUw0nRnZuntoHJv0JcWMu4mplGmjBtTghWazxb5KmIRcq9ymVHJQu7VdJ+A1t+sQnA8Mh9aMFaZGCdbgLSJMgsx/+Dxys8z8t4yDJ70WxjtZWaAGL1G+W46EV4RJIFuDZ9asTrXP3iCqDXlSh+vASWq3ZIgYQ2cnKzPfO9k/4SrXHXdBvrvtSQwzfpBayvwksrV2TeZ+ZfnKdmNr1QL9uZhgKVOIa3tyMs+nwYuPg2fS82jwErdpRpzA5dMmtsUX9mEoSicr/W9YaKJjlYnxovk7RPQOAN+Sb/pJZj4///5Dg5VMCa/BK0cM1k5pZubW39imKGfK6rBmtiwBsd06DvNyk+Us7fojC+3BvFSmaO6TgpB3PdcNdl3HuDVn7Iix62ggpQYP1Lxusw91YSNcsxyDmSAZQoPn29XGi6ZpfkO+sFIFoM5OX4AGr6XWrA9y3RGQPSNrtjhQx8LpjSsUDxHovKLBMwNEx0SzXLM0zT57NuvTv2Wfcv1Zvidfg+dotDrWViM0kfNOLr+Lfmnu/m6vwavWd3ivpxDQxHbX+ieUB+Bq8PxSoe/RlEMkMeHdkKfMtzi2i3Dmjm0G1OCZyb4myPOtLaUGtXMSrfNKcbt8TlZWXc6L0eCBmc8joksB7AYAItrDzF8ftGSKI9RVt7ufCMzIVTtbR0PhaaiNGryZOY4qs1ttzD7cxcHy5dRn1mbKLrdTsLnhn012Yx7VCUvzOYM2+pfFenH1cEJQaqOG63WDTlbEYMc3wMxmdePz2RZau7rYWTHeccPnoliTMqQQULSlngHKFqXBKxxcjBAT00y8FBqNefmMZd8YK8SMYX4rGSJMQmUNnhsmwazBm7qJJvmtJmJwnevIgauJBWuFSehYV81kVEiYqDPhb+1kRTheKhVt2UpTaXIqrXosSyLxO9QcyjAJKI4rtWr2sVzzy5SjLq+yXGTll+Ul72f9+fK4kGfU1E061honhQbPG8dwIMr6lVaDV2zrneq0aexGiOhpRHQxsgDn788/3z50wRRYtY/tH/ZhHhMM6+XsmpzVtMvYl7o0O6g4WQmsHfTBXH2hyxhBXZn6YKEvs8Bgwzax4tqOcZsHiIPXMQ1GWZeG7HRDdaouTALQwcmKyKjWi2aLMvogGDO+ATV4RsDrWVeGLmcINwbZkBhz2dCEXMiRT216SUtYz9xT7r4EvWguURw8IGwWH0NVg5dvR2nqmMbJCnnfyb5f7pV0GUSbZyWNiTJtkjCvk86FSN4DObHrv97qGrzwPfKZF3cKdE7V/GzzyriETPgLX3mTm2hyXJ3xCaxtKSYpRpgwKzTEia16Ss3waot4MY/odwA8HMCXmPluAJ4A4KODlkoB4Fcpy+2Ohaa15spagwe7Y3Sbttwn3RHXQeLT9cLpChl1MLtre8rU+swgFw4zJjpY6MvGLGSi6Wjwam7h9jzNQmmZRC8TTWBwpxKh+mi5sK/EwaPWZpByIFhn+tQr0DlzsSZlyPdUssmSBWvwRoFsc19bmyfcxUfOfsv1QGMwiJMVJx13DY9pH3VOjqZAqM+NoeJwo1ifZhxkJOqLCYWjFYNr1SG399LgcdVLtW1KWW6TAlMxdoi43tKUrrx/YU+QVeHVG+g8cmwjy9hF+5bFmZVCrNyXtk2bOtREk8Y0Bt89GQp3jWcfZArrsgYvRsA7yMzXA5gR0YyZ34ssNp4yIn71cmhurtpZ1zVon71+o4mm6GSlOYkxOZG/63BnuYg8Zh8dSLVuaKqE4+CJ76i///N5Kg2eLEC3NMwM5Gw2rLAS1OCxPcssybRk7TQp8gVSb6Lp2RaZB6NsL0M6pkm1Nmpo7WyYkTV4sCfhbO2GPdCPSm/Em+bTgvTFrf8bIQ3exK0u+mjwDG4cPDMh6i516K3BE/cw9ExdTXPbB5712c42sDXxVOYjBbRse4xQ68b6lYJj3bky9qS7rcutjQk7US2DnVcKS5f6vJovLEUcvHGdrGSfSe5Xj8mMZSVmDd5NRHQ4gA8AeD0RXQPg9mGLpQB+Mx+53ffpmjQA1Q6tEsjZMj+IK1vRSRMg53Kqa/Dq0/HZqRdq+R4jjCKm0kQHC32ZzfxmC7ZJSr2TlW3mXjN5hlSBzk1dGrLzDZVvLtpOxYsmtdekWHHwas7zavAibwBz2V5GWYPXsy0RFmMSEztplYLsGss8pQbP0mTErsHDuLPNYwQ6N32yaWeVOHgT7bNDjq1icJ12FNotlF4nfZqjtmT9ga2jCj3Ttu9qF19wbWNFZDSJQGmGWpYv/y6EwMY1eCKBkAbJO1nmnh+BLAt5Mou9T1zzfk3vZCXuXU5uBexA0zNLiYwX2Ze6MfSqEqPBezqAOwD8AoB3APgygO8YslBKhl0hw1ox/4xSuU26I85+2zgGHdm2htYrg1267n9D5fZRCXTuzPx1pVw31D2NKbMRCHQucZ+Fy3yAOHhdH9k8n/XN6sJwvW4oZbkGz6fBk8FvY7ADnbfT4MVSODOgYR3TmHqWJkzC+G/U8rmOocEzJppCg+AR9mJvJY2s9eyh0AlS0eCRrcEzE1Wp1noOxcaMakOe1FFxruNot2aEJBo88/6U/XpQgwdnXNGypjE8Gjy2J56AUkuZFbAcb2TaOPPdf71uQGo5lqmYh3q/V7813VrXEQzQNUyCLQC7lk4p8T0LHym0bymCpcdi7ln614Zdr1aVGAHvpcw8Z+YtZn4tM78cwP8cumBKWDhyzRZKE6BAoPOKBi+cZ3Sgc/Hp2pa3set3NXiAdLLSX4M3VXOfvszI70WzOkMbvodb8zi7/SZ8azjbMpY2KuhFkz2DMEEx4x55fdECnucFE78GrzRZGlJuSjXwJlrMjOm4YRLIqktASIPXJr0l1+A56ZQmmtlvEyev1OAlyTY5M2qeVAvhPvdSu2XCJNRPwsZiNIG+ZRfZd/vdzOw/Lgb2afBQTjy52wD7Om1NWSgPkQhszWBVe1idBLeuqeXYRpbLmgKP1uDZ54ViE6YgNtC5oU9fWIz9RtTgJQl07qnrqsEDvs2z7cmpC6JUCc2m1ppowswcSw2ePQivE/hiB0NyFqca6Fx2tHXaCzObbc+YmV99GnXIYcaqsDkjrymfa3JT72QlVaBzf/5tYC7r0rBOVvzbbe2KfVPk+pjY64uNg+c3s43Lg1GuwRs0Dl5eoM2+JpoL0uC1DS7eB9eUV7bBujoWYkbpPcjVEtD29MHtp8y1b+SSXBkkO81EwlBsBPrcGCpOVooZI6PpcTRHHe+BWX8XFei8Mhnb7tp8k7PFmkLY12gLaOK7R4Cy87Ans2W6dWESzHfbyUpkP+ARtLsIZ3VhElJPYs45bmIkhQavsN4aYcrMPOMkTlY8dX3F5bvwGjwiegGAnwLwTUT0GbMZwOEA/nuEsikC30x/rZMVpwepa89WxzO3X0QhisW6s+oCZNcMJIQ5TmrZzIBV7u9CqkHpVAkt+Lfvff0aPN8aii5YaXSd4QYXA5MhZYBQ2lK74mp9szppjmPEzH/K9levwfOVJe4GZIfR4M5LjIDR30RzMTOmIdPbIZiRLQTIUCVinBs9gB/agY6Lb0DcF1frVYRJKNbg5ceZPnuidvWbM0JHC82CcnCcYeqEu9Sha101k2ShMAmuZ27rcjpo8HwWMmbiyRcmgYBicOF6+/TmIcqanSq9cIbPLkyk5/b1FmWIpJjIluaVkedmmszydxdHLbEwx/UpKeLglY5auqcRS1mH+lM3Pl5V6pys/AOyeHf/G8CLxfZbmfmGQUulAPBr7QBRUZ06Km3d5S45awZUZ158a6iaNXj+tKS7+ex3vYDh5i9NOJI4WZnobHBfQlobN+5P3S3cnqdysiLz75aGdCk9pJYn7GSlFIYrGm6xrYsGb7su2Lz3GcblgXwAMbRmrPRu2C+doUNghJCDw6EhuNpbaQ4k6liLNMcci/RxuhEi6GRlZu8v1npOtM+e9dHgze3nXgxcuXQwZb2jO96CwkQzYDZfH+i8vQbPLWf5zgkHOi9OEUJg6HpLTYvomx0hWebtws5nXV5lsewJ56KwpkxtnGAF7G5Ta+VNmKEmiuL0aGK+OIZDYbJI4mTFM4Ze5zh4BwFcwczPYuZLAewG8D0AzhmjYIoz4xAws8h+y1nX6snGEUO5wc2pKuHFO1mpBvAMCaYuZpdlxmDN/HWnMPdZMw2epCnQuXFs0hd7QX9HDV4+yGkbULx1PsH8/fURACDaT+zMqxUHr9ZMuU0pq+ea8c6Q76lUkyWzWfqZ6xjaBhfvw4zIEuhZVCzZN8abaC5/mAR3MGsmCowGT8YJzPZPs88OhaaJwe1bioErsvqRhYgpr7ufkxV7PZ9rlim393ne/jV4jHLiyWyzBTRpllnKG/7rZbY/5Tl1a/BEgSpfG+PgeYZK4cDxYVwHcoNq8BBXZ1KESQiZyA5BCmsuLx5FyCpSJ+C9A8BeACCiewD4CIBvAvDTRPR7wxdNgU9wE798s1Ol97Zw1a1rl7GzeOVaAvtlUnW93KzB873Qs0Frfw3eVAcLfZkFvGjOLcGifqYwmZOVVBq8vC4NqsELFNDMpAPh+miOi8un/F7vRbO7Bo/ZzNgPKwSkmizJNHgpStSOUcMkELAtHr6sV7JvjC1L336wLaM4WckvvoiD54ZJmLAGr6uTlWqg84zkGjzYk6Qy7+y7XaZQEPQYmKt9ghEapRbR0uChqsUEwtfrWiRJAbF2DV7+o25iPISVrEfDGHufzDvNl27qJl2GGWrCr/1sQ+H5dCSLCCDRGjzxfe5WrBWlTsA7hpkvzr8/F8AbmPlnkTlYeWpTwkR0OhG9l4g+T0QXEtELPccQEb2ciC4hos8Q0ZmdrmJF4cCPclaLnd/lYa4XTfvlYTdMX+fVaMYgbLntMAn2S6NWg1eTV1/HEVMfLPQlNJtcZ4LjkjlZ6X9/bCcrHWe4mYu6NKQQECpe3eCbUNaj2OvbEoP8OgHPtyvaiyYyz2nGNf9QGNfwKbxorr6TFapob0sBTzh/iizKokJLAOkEy21nlqk00fQLeFOdlNuY1bflOsq+xR4cM0pnHGmcrJDnnSy/2+/m2MlYHz6hglFOPBXrluUaPBJazOK/+jxkuaXDq8o9srR1ZZtztzWPbcrvPo1XvJOVsAYvdZueR77LS98J3dvYjJrvYSpSavB8kxkrLt/VCnjy2h8H4F0AwMwHAMRYEG8B+CVmvi+AhyPT/N3XOebJAM7I/54P4C8jy712+CpixVQTsgLbO+sapNwV7UVTfLoxd6yZtJom5DNXkrNzfRp1uW5omoOFvgSdrNQtoneYp1qDl0APyCjr0pBmfKG0s4GJf1JATpBEa/DEgW3DJMTmUWjweraVJlJ5pG0bSzAVUnswNETuoDIwcxxZmoEtlivYTlbS4K5BLTR45Ah4E++z+5howhGG5Nqisu8T+zuW0Wj0LRNN+J9pkxOuJhgBL5r5xBOKa5SDaztMQtN1VjR4kBrA5vOkpqZLPyBj9rlpN+GOpEJmsymITa6YYOiRlxTSh8Zkk1IgXtRE4yKoc7LyGSL6AwBXALgHgP8EACI6OiZhZr4SwJX591uJ6CIApwL4vDjs6QD+jrPW/1EiOpqITs7PXXuCM2+VT6HJ88xMZB2+31QAcAS0cmNt2aS7XVcDaJmERDiYcAOdmzL30eRMfTa4LyGX3XOnztS9wLd5Oho849HTHSCnJpR2Zq6Ufa8GOqfWGjw5qK0z6+qjwTMz/8sSJiGbtBn/xRoS3IdgRtX1l3Y/Xh4XQ+ZAJ2EBG7D77lQaPDudjdxLZmGiycuiwevezkIu86WJZopA56UGT2iLRF9UMeHvqcHzmUkWE0+FiWbZBuR2OS4JaSx9GrxyEtgRLj3nu2OkPONafE5WQiavdbhr8LqkEQtzXJ2Zea6nLTMaI0BCRtulEXVIAb+oFysu6NUJeD8B4IXI1uF9OzPfkW+/L4A/aJMJEe0F8GAAH3N2nQrgMvH78nybCniomXlzKqU1gPCcUDE5q2udkfVddhQzImzOssDbr/7wV7H/4Hbx+1f/5bN42dsu8qbRtObpHz52Kd554VVxBXK48+B2lvaKmmhuzghX33onHvsH77O233D7gWJm9LUfuRQHtubFs3A/9x+cp9Hgief/l+/7Mt7w8cuaT3K44sZ9OOnIQzAjwoGteeW6UnFgKxvtmPIanvPKjxdmlXVr8J768g9FDUD3Hdgu0vr0ZTcFr+fW/VuVbT/x2vOxa8dGYx5fve52nHr0ISAiXHdbtS6kYn/elvqHSSBcdOWtScu5c2OGc+51Av7z81cHjynKP4qAR9iX57c5I+w/aNe35//d+a3KMiPg41+9PnjPdm3O8Jh7noB31Vx/LDs2CIfu3CzK+vL3XILXfuTS3unKtrA956JPNuEQ/tdbP4ffe/sXirYw1T57czbDeV+7oVP9veH2A97B/vNecx4O3bmBU48+pNi/OaPoCQCXTKNfCk6bM8IHLr62KLN5FpszwmevuBlfve724ve/XHAFPnjxddF57T84r/aFLK0xik2leWTxX1hjacz0N2dlv2bKmWnw7AmCImvf0hDf2KgBX7nkGOev3v9lvPG85nfcdbfeicN2lUPsGZX9wE+9/gLsjujjY7n9wFZUnUkRJkGayQ5NYaKZ0I5BOnJbbfGuRsBj5n0AKs5UmPnDAD4cmwERHQ7gLQB+nplv6VJIIno+MhNO7Nmzp0sSS4lv5heQsw/V3z4nKxWNnRsmQXyPNdF8+oNPxU37DuK7HnQqTjn6EJx81G7cePtBfPna2wAAjzrjeHzm8ptwy77qAFbykD3H4An3ObEQCky+P/+Ee+KiKztVl4JDdmzgIXc9plcaU+V7H3Ia9h3c9s5snXGXw0EEfOnq7Fk85p4n4GvX3Y77nnIk3nnhVXj8fU7EB750LQ5szfH9Z53euyzPeMhpuOeJR+AbN+3D12+4o/kED9986lH47gefihOO2IUrb9o3qNbiW+5+HK6+9U584EvXYnNG+O4Hn4o7c8HviN2buOeJR1jHEwGPv8+J+PyVtxTr0WI4bNcmHrr3GLzvi9fWHvf1G+7Apy67CQDw1AecHDXAveDrNxZl+94zT8UdB7YGNX88dOcGzjy9X1v6oYftweG76uYU23HHgS3810XX4EvX3Irdmxv4tvueGDz2sF0beMDpRyXLO8TTH3Qqbt53EBtEeOy974J3X3Q1iAiPu/dd8J4vXIPtOeOQHRs4M7Jfet4j74b/Cghvt9+5hXd/4Rp88epbceiODTz+PuHrb2LfwW286/NXgwg4/vBd+N4zT8M3btrXOT2Xw3Zt4qy7HoMPXnwtnvqAkwEA33T84XjOI+6Km+44WBx37GE7cfqxhybLNyXP/Za9nSccAeBeJ5X9imzh9z/1KDzjzNNwzr1PwM8/4Qzc9bhDcerR3e7BD569B4+8+/F49D2Ox88+7h44/dhD8SFHaDts1wYeuvfYol869ZhDcPzhu/DpvA+K5YGnHYXvfMAp1oReqcFrDpMQMrf8raffH5++7CY85p4n4N0XXY0rb95fCnjipJoleGINXnUQ1ehFU37Pf3zPmafi7nc5DFfdvB+XXh//jjtrb9nOf+ax98CcgQ9efC3uyAXtVDzwtKPwtAed0njc2Xc7Fj91zt1xv1O694Xf9eBTcMrRuzuf34bSRLN/WqU3ZRKa4f7pTpl0b1sPRLQDmXD3emb+Z88hVwCQI8zT8m0WzPwKAK8AgLPOOmvFH4mf1oHOpYAnOkRjPiGxTSy5ss3HmXuOwZl7ys5LvrwMscKD6bxlvi845+5R564rD917LB6699jW5z3lm7PB1dMe2PwyiOX+px6F+5+abvD8J898cLK0QvzPN38GAHCXI3bh/37fA619bzrv69ZvAnC34w/DH33/gzrl9T1nnla7/9OX3YSn/8V/AwB+/3sfYM36hvjlf/o03vyJy0EEnLX3WJzVoS6MzePvc2IvIcTlipv24b8ueg+YgeOP2ImXP2v4etPEQ+56jDWp9J2inX1nhzb3tAeeEmyrl15/O979hWvADJx45O5e13/NLfvxrs9fnXlGJMKLn3zvzmnV8b0PKdvCzs0Zfvvp9x8knyF46gNOLoTTvsj36wu+9e547L3vAiCb2OyD7At+6dvvBSD8Hm7ql2K4Zf9B67cdT9Rjoglx7STGJiKNZz/8rnj2w+8KIKv/7/3CNfj4V2/IjyNLqxaisgYPYh1f0/yZZUqbfU/xjnty/u5NVYe6cNiuTbzoSf3a9r1POhL3PunIRCWqJ62TleyTKJ35+dTpGbo2DGWt+5UALmLmPwocdi6A5+TeNB8O4GZdf1cS1OBx6LMU+XzVN9SvyRkt9mwbGmvGbMR8lfXFmBv61iJUNNwDV0mf84UmjJZvnduL1HRO1axvSKw1W33NZ8X5U10Dt0rIdtv32S0St+TGsddsJtYZohxXZOu3qPK9Dnl/KCAUmrxdXGsn33m1LO+jWQnM7U8ZJkFYaA7q0G0KRGvwiOhIAMzMt0ae8kgAzwbwWSL6VL7tVwHsQZbQXwF4G4CnALgEwB0AnhdbnnXAXnfn3y63MKpCHyAWNecqvIrJptggZzkWwRqO05QFsNFiamuKQlQpoC64IAtkNpPf1+9GSEGsr4C7YQmLvZJSIpCPa5UmJ4xnTunJUy4dcQU0nxMTF/f+SAHRzbv8XuYN53uTgxEKfFfGR4YT6UupRSbvOHkVaRTwiOihAF4F4IjsJ90E4EeZ+RN15zHzh9DQPnLvmT8dXdo1I+Thp97JSvWcSn82sV5rhd5vypKwmY9ivXVv5PpoeW2LzNwIqOvcdNZdgycFvJQavE2V8EZlmW+3KywZDZ7lRROOV2+PUFfXfOX9sQREdw2evQivQqzHRNuiYv36lSlRThKkdLJSfl97AQ+ZmeVPMfMHAYCIHgXg1QAeMGTBFBtfBS8CnRcb6itsafre3GmN2a3ZA1xFGZ4yWG51X2XTlE0013gAsrHmZoVSg9FGI+3DEhbX71aOzqpo8LwmmgzLW2YwTILs92rykPdHagbrwiT4fRY052XyiCmXMjxFeKIEa+akk5V1Iea1sG2EO6DQzNW7RlSS46ve7raQPTE5g9k6Jyt124bCymt92p6yQEoNmGcNXsUkaHoUJpoLLsciWfd1Y7aA20/C21zzezk2st8x4SKWEd84IdPgkbOv9GBpm2gGBiWCDXcNnjHRrKny3vV4kctPuky4KcNgHn1SE801eqYxGrz3E9FfA3gDsvv8AwDeR0RnAgAzXzBg+daaeCcrpcvXeg0ewddUYhxNjMUU1zspq0fdGrbqGtVh62SXAUUxIF/j5rLuQom9Bq9fWimCbCvxyFu8zPfbfV8zmzV4wskK+wfXmbDWTEXAK7o+10YznIZlItqi01ziR7MSmGeV0umlfJ+vc6Bzg/Eh/hvO9gcjazePS1oipcBeNFz9Xn7C+nQh50tlAFt70rhoh6qMQemFspkpVknV4KlQktJEdd3NXcfGMtFcoftdrLcj6SCjHL0QyQG2rc0LYQl40vtoRb6rOllxy9aYmbNbJ5wXC+Va2hSCmHT0U2zrneq0aRTwmPmxYxREqdKkwfPva3ayMrV1OxMrjrIGbBQaPJ+J5rhl6eRkRdfgrb1QspFQwJ2tqMAxVWxBZXnvt9fRSb4Gz6vBE1cea7kg748UEH0OXsrvYZ8FTaiJ5nSQdSgVM0uDly7dKdJouE9EJxLRK4no7fnv+xLRjw1fNCXkFKrWRNOTDrmfFYEvfM4YWN60RsxXWV/qBrEx7SMlnZysqAZv7b1oyjVIfYUyIiqEPBXwhmd1NXjZP7kGj1Fq14JhEmp6MluDV/Z5VQ2e/7tL8xq81Xkey07hZCWJBs+kKbatuA4vZmX2awC8E8Ap+e8vAfj5gcqjBKgL4ln+rq+soX4rxtHEkFgmEdq5KiOwUfPiWGig88hzlnnWPxXSycoyu5rviiXgJhASTBrrKCyPjbzDyyzg+TR4XGjwyNoG2AIaUVyg89AavLo+sNbJSmOOJToeWSzmGSdxspJ/rtMzjXktHs/M/whgDgDMvAVge9BSKQBskwLrO0qNXfYbxW9fx1aYNBj3xJX9nnM6lbgbXQa4itIHIxx4BTxXgzdwrbRMNCNfPmbQs9rzj82Y+7COsdtSm6iaNNYxaPzYrIoGr+JkBbmAJwSx0Bo8S4MXaaIpc6wKl+HeUO5rM8Bf3iezGphHlVKDR55tq0rMW/F2IjoOZu0s0cMB3DxoqRQAzSaavp11gc6DYRI8eS9qkmONJleUBWIGVfN587FTrJMbNQLqOrHOQollVpmgkpo0VIM3BqtpXpwtE2FL8MsmnssodFJAc5eP+NisaPByAdFdgxf4Xm4zoRrq0TV406GYJEjqRbP8vupvzxgvmr8I4FwAdyei/wZwAoBnDFoqJSOwaNj9Jr1oejV4EVsWiXqqUsbGDKqm4Ca5iwa70OAtvvgLpRRKFlyQBbExI8y3OYmAa9JYZo3SsrAyGrxK0bmiwXOP9627qxOkotfg1cyCh8ZGPro4vVKGoTTzTaDB8wQ6X/X3Z4wXzQuI6FsB3AtZ2/oiMx8cvGSKhXdGqqLJC9RWxyV8pTMNdMRjYQ9wtUNVhqc00azuG9tG3zJAisy6bg3hOrGx5kJJNljhNBq8NdaGjo28w8t8v92SS0dvcnBum8cZDRzE2CR8D2aWBq903lK7Bq+uXA23WzV406EIdJ7gNVc6WVmfhxrjRfNQAC8G8PPM/DkAe4noOwYvmRI2ywx50YRfEDSEBq5eJysjCloU/KEow2A0PtteJyvO74FfCPaAIi4vM+jZThkBdgmZRQz2VpmUAu66a0PHRNbXZTbR9JlJZho8sgbnpRdNsjRvMVduhwORJpody9xikLHEsvdKQMVEZv+0/Ems9vszZg3eqwEcAPCI/PcVAH53sBIpBY1OVlwTzZCTlcBnsX/BGrwp5KusFxsbWdcXY/oxxSq5IQZP68y6a/DM4Detieb6OawZG/meW6XbzXkgvEw5l2vw4HjRNCaa0oyzpvrK+yP9bvomdWTIKBdj7dCowav5pYyL6daSWKp4YyP2T3bKxHQtd2fm3wdwEACY+Q5orR+FWCcr9u8Ir4BTk6ImVhxl9SnX4FX3jd882mdYrsFb8TdUA+su4BmhbDPB9W8W97J3UkoDUou0zB5gKyaaEF40821z5kIDk22vmmXW1V6pwWsKk1B6Fu8+mFcTzekgJwnSpVl+X/W3Z0zPcoCIDkHpRfPuAO4ctFQKAL9ZpvzqdmbS1l1SdKT2h9i/WGI7ekVJhRnETikOXpt86tYQrhNmkLeuAl6xbi5BJV33ezkmlpOVJZYivHHwYAti0osmgWwNXpFO+B649dH0z75q6o6NJPPIzlLHI9OCKJWTlarzn1WfII3xovkbAN4B4HQiej2ARwL4kSELpVTxu/1tPgaQXqvs3+V+zxq8EV86XdYgKUofzGDW72TF+T14HDz7M4bNQsBb7RdUE4XWaU37jY2EWreUwqISzxIr8Kpr8JjBzJgR2SaaxfG2Bk7GxAuRKtC51CLWoeORaTEjSuZkhbBejvxivGi+i4guAPBwZPfnhcx83eAlUywzA996vNLJSvnZzclK3LahoMB3RRmKujhyMWtUUxKK61RHnYC6ThhN5jJ7IuxD4RglYaBz1eANz6qESXBhzvokcjf6TDQp7n1vC3i2BrCaPyOU6lxoEWNZnSezvBASBToHW/Un27baBAU8IjrT2XRl/rmHiPYw8wXDFUsB7Fkon7VmxckK/CpnV3MXY4KmTlaUVaZNHLkpVkldg5exoRo8AKlMNPM01/RejomczFkljWmhrROeLrNtpRdNuVQkxjxd3h+pgfFNiLHz6dvX5nav0KNZWmZESQQx36ty1V+fdRq8P6zZxwAel7gsioMl4AW+Zxu8XwuqJpl9S5YWNYNQxsYMjH1hBsaujl1MNIvyr/obqoGUXiSXEWPepxq85ULe4WW/39kaqey7MdGUfZr07k3wLxWp63NdE02TgHcNnhM6yt4XuQbPceqiLBhKtxRB1j9g9SdIgwIeMz92zIIo9Vjmms6XWCcrob5qSnHw1sk+Wlkc9YHCmzXcKenkZMWUf81tNFN6kVxG0ppozpKlpdSzKk5WgFyIy7+7WjIiAovRS7aGrhT/fB41XSwvmk1hEmp0PaWJZj06HpkWM0qjaSudrJC1bZUJLu8loocS0Uni93OI6F+J6OVEdOw4xVMMXvVy7Mmis80+/futTSP2a+qWWBmbWY2JZrUODlspYwY5Lm1MTFeZlALOMjJLaKJqHLWsqzZ0TGRbX/b7bQ2YuXRmAfg0eOWVS21crYlmxclKs1lyvZOV+vtt7V7uR7MSZE5WEqzBY7v+rQN1/pv+GlmAcxDRYwD8HoC/A3AzgFcMXzTFDm5u7bD2W05WahpCUIPnE/BalLMv69XklClQp8GrzH+MpMFr0wxmNeVfJ2YJ16AtI0k1eCatNb2XY7JKt9gyecv/yclkew2e9AXQfpxhnVNjoukjVoPn5qcsFkIaZ2IMrla6FX991gl4G8x8Q/79BwC8gpnfwsy/DuAeTQkT0auI6Boi+lxg/zlEdDMRfSr/e2n74q82HPjhmkNIpyt1BmdBJyu+cxbUs63Si0+ZLnVeNF2mWCXLMAkLLsiCWffg3IWTlQQC3kzX4I3Gqt7hqgaPatbgUfv3vRAQazV4vpFQbJgE+V0HJAsnVZiEmiqxstQKeERk1ug9HsB7xL6Y+HmvAfCkhmM+yMwPyv9+OyLNtcL2osne7dnvei8rbic1uT5rauVRVp66QOGLeqm3ybWNgLrKrH2YhJQmmhGmb0oiVugWu27nmW2rBGviWZhYdhGk7DV41f1u6ChJbF9pOVmJOkMZFFInK12pE9TeAOD9RHQdgH0APggARHQPZGaatTDzB4hob4pCritSqJt7hL2iMzPbA3Hw3O6q6lXTq8NrWdruWGvwtEtVRqBuQFw10Rx4DV7EOhSXmQp4AIANMp/r2W8Mo8HrnZTSwCq950i6WeE83ph07GakPlTX4DU5gKvk1bAGzw0dJemyBm9Nu5VJkWwNHtbPyUqdF82XEdG7AZwM4D+5vMMzAD+bKP9HENGnAXwDwC8z84WJ0l05vG5/G34b3AHk1Ew07Zm88fJV1pc6M7TKBMjAZSlntONzKtcQDlKkpWHdXfubQW5KDZ7xpqkMx0q95ywNXu7JW4w5ith4cByroD5oeSgrd8mJD994KVqDZ31fpQe1nMwojSCWhe9Yrydaa2rJzB/1bPtSorwvAHBXZr6NiJ4C4K0AzvAdSETPB/B8ANizZ0+i7KdPMNC5E+tl6Z2sqEmEMjKtBLyBK2XMgMXFjMHXXYNXCDhrKuCZ697c6H/9Jg3V4A3PKtVW2+Qt15QU+8gK30QQWjtq37fagdI9Grya7tAyHY3Or93xSnqIKMl7zjx/y6R4xV+fC+vKmfkWZr4t//42ADuI6PjAsa9g5rOY+awTTjhh1HIuEp9Q536vO8cw9UDnijI2yz6INdqWVX9BNZFyDdoyknLdXEptoFLPqjrv4Pw/qZmTE88hxyqxehUpIHrX4Dmf1r7YzlInnCdFqjh4PuriJq4CCxvmENFJlPdyRHR2XpbrF1WeKRKq1LITs0MpNAQ6L2a+/PutbSO+gGwTTe1SleGpGxBXTJiH1uAF2mUd66qxckm5Bm0ZMZrcFBMW634vx2SV7rCtEeHKGjzLRBO2xYI7NonJq86LZjEeCsTBi8mGgj+UxUCJwiTYEwTA6k+QxnjD7AQRvQHAOQCOJ6LLAfwGgB0AwMx/BeAZAF5ARFvInLg8k1fdpU1PmNkWgCreNP3nuWvvYjR645poLiZfZX2pFZAqa/CGrZVlu2yxBk8H4QB0Dd5mLuGpBm+5WKVbbA2YYZtCEjlhEsje13Zyy/KiWTOp4XeywlF9rDp9mxZZ157KRLNDaI4lZjABj5mf1bD/zwH8+VD5rwZ2pTYdZ7H2zqOxq1M5t6nY4zpZESYRa9T4lMVRr8Fr2pAW1eB1Z92Dc6eMXWe0gKrBG55VslRx1zQxpBBnh0kgUNH3drkDNJN9t0eDV3NurAZPok1h8RAB83n/dDLNsrtttVnylSirTVV4q+631+n5TTQNIctyrwZvQR3bKr34lOnSxinFFGukxirLWPs4ePllpxHwsjQ21/RejskqN1/jrRDITTSl8zeyhb/Cg3CsiaY4tj4OnsfrOHNUPvaE8wo/qCVhltDJSnVj72QnjQp4E6Yq0NleM+W20DlAtZOaWp81tfIoq09tHLyRKyRVvjSjGrwM8xzXVShJaaJqwiNo3RqeVbrDPq2IbaLJlokmCuFPnhl3R6SJnbeehpfgtQh07v+uLIYZUTo5jOz3uzpZURZGSHiTgc4rnja9Tlbyz4BphNfJykq9ghTFpk7jU2kfI8VJUBPN9qy7Y5C0cfDsNJXhWCXNkHstc7Y1c9mwJBuYzISANiPb4UpUXuL/2kDnQScrEWvwAt+VxZEqHBDBfqar7vVDBbwlomm9XVOg8/J3hEZvzDV4ZH8qytDUa/Cc3wOXpYuTFR2EZxRr0Nb0fqQUcFOu51PqWaU77F7LfF6udSpNNMvf0mKhtZMVihsv+DQzc45bhKcavGkxmyGJKaVxUrhOz1QFvAlTMdF0Zqdkx1n87uBkZcHynWWvryhjUBvofFFhEtREszXlGrTFlmNRpBRwi5h6WrcGZ6UGmc61bM9Z9GlkO1mxhLr2dkLynE6Bzlvmp6OSxUNItAYPdv0z21aZNX0tLgcVjZ1jXy5NH4AecfA8b5tFmJCsktmKMm3aDGKnaK68rmvOXDYShglYRjaTrsFbb23omEyxT0nFnOs0eGSNR0pTztg1eA1OVsynZxzUzclKVLGUAZlRGkEsVCdWGRXwJkyo8lnBzRs8bQI+E82eBUvM1MqjrD51AtLY9ZGczxhUy5KxUQT6Xs/7kVLrZtLQyYPhWaV3nnspJt4YUF2DZ2vwwmnU5xeu8z5HdIboYNnk/aosCKI0gc4BYyJcPtXVFu9UwJs0vrAIcrtPw+cTCl2ThooJmifvcU00x89TWW/axMEb3kSz/Ro81bJkrHug85RC2eaaO6xRulF1siLjjVFlKQmJ88rvsXnVm7TXx8HjytjHm4eVn7aFRUOUxskKo7oGb8UVeCrgLRPV9XXtnKyEOsZFx8FrGwtHUfpSKxC47WPYonTU4A1RkuWj8CK5pkJJocFL0HmW97J3UkoDq/Suc69lzuyMNdg6Vnrzbrv+WK7Bq6vz/jh4cflIoW6FHtPSMjNq4J6YNZjr9Ey1K58ygTV4RawXZ2YMXB/VI1SxvWvwRmwGroZRUYam1ovmyBJeJycrqzRC7MG6rxtL6fmy8Mi5pvdyTFbpXecz0TRbyzV4uYlmZX1bu/vgCogudRoZW7MYn5+yWAipNHj581yjh6oC3oQJ6evCTlZCHVx7E7CFtIH1aXfKgmmjAZviYGxdNVYuRhhZV7PCcg1iirTWWxs6Jqs8xnQ1eJaTFWsNHlnfY5BH1cbB85wr1wbG5jHFvn/dmBElMaUMpbHKjlZUwJswbsUzsxh1TlZ8qJMVRbGpDZMwcn2Ujr9jWVeBxmXdNXiDmGiu6b0ck1W6w95A52YfnDAJEP2dLUlF51XnRVNaN7nEaoE0Dt60SLUGL08toHFeTVTAWyKqTlW4dr/BHT76wyL4zxmDOpMLRRmCKTlZKcY7LfJRT4cZKcMELCMmTEQaE83sUycPhmeVnHe4V1KvwSNrX9upLSkg1t1Df6DzuHxW6NGsBOm8aHIlDt6qowLehKnUaW8cPLnb3wqKjtAzcVYc07hheNap4SmLpT5Mgr1vcPmupl2G0HVSGSnXoC0jKcNEGGFRJw+GZ5XusNsVZc4sxBo8iDAJsIW6UtiLNNEUA3S/iWZZhsq+yEjnGgdvWmTdUYI1eAEnKyuswFMBb8pUY9zZMV7csAhNsxx1fVV1UDtuz5bN5mlvqoxDGxPNoWfbS816/DnrKtC4GHPCdb0fs4Qmqilj6in1rJbg4JposiW4BdfgEbV+5zeFVkjuZEXHJAsnM9Hsn47xouq+z3UNnrIQXI1cGQevXEgsjwjZKY9ucqYoE2fZTaR0nVTGbM09P6YUcAtt4JreyzFZ9v6nDingAbDX4BF5l2S0uRt1a/Bqnay0TN/9riyGzMlKmjh4/u2riwp4E6aqwatuD32XuGYQvlmpRQuB0lxDURbJ2G2hrl2GUC1Lxrpr8IrQBgmuf93NXZVuVOPgyXVyqLj3lhq4LiFiyri5HhPNWicr7QVrHZMsHkIaDV6WljpZUSZK1alK/W+Du8bH12kt0slKlr8aQyjTYOy20MVEU8lIGSZgGUnp+TKlR05lfagOmMu1bkSlpVFRrYrxSPswCTK/+nrqC3TOUX2sHehc28KiIaIkWrbSRDNBYkvCmr4Wl4NgHDz2HxT2oilm0xBysuKswRu5FdAC8lQUP25bGDi3mnap1LP2JpoDBDpXDZ7SBr8GL9+HzLyOnW3mPHdsEpehP1+g3twudg2eZTqqTWHhZJ5YEwU6R3WsGzLdXAVUwJsylbAI1d+ycjY7WanprVytxQI6Nu1LlWmiNXOqGI+Pm20i168QKuApU2POXEy4zAoNnr0NyMcYHaqam47ECAJeE815+0lkbQqLZ0aUJA5eONB576Qny3q+FZeEipOVwoumP9B5sBFUFhWlKF1adKZMmQrjrz8NrylR6ikGe2v6JlMBT1k07sTxfG570ZyzWf9mtlXP66DA84dJcEJJWeXqEOh8koOlNWNG6YQwksEX14A1fS0uB5VKXYmDF6dcdtf4RDlZiStiMgjr1fCU6VJpCyOZaCrtWXehJOW6uZTr+ZT1wR8HL98HCBPNfCLLMtEUB7bMr67O+0z6IsPgaRy8iUFIpMETsRit7arBaw8RvYqIriGizwX2ExG9nIguIaLPENGZQ5VlVajIe86GYJgEN8adp9Oqxv5qWbi+qHynTISxA52X+Y6U0QqxkTAO3DKS0vNl6ZGzd1LKGuHWvCxMQrmwuAh0XtHgCY+YrZyshE00DSENXpyTFZmXsmgolQZPnawk5TUAnlSz/8kAzsj/ng/gLwcsy1ISEuhCgc6bGkGdCVi1gx23FcjOXlEWSVWDN2y97OIqXMkoTTTX8+ZtkPlMIOCtecgJpRtl2ILs97ZwZkJA4UbT2paf16WmuWGfJE2BztuOa3RMsnhSCXjGk6s6WUkAM38AwA01hzwdwN9xxkcBHE1EJw9VnmWkEgahCOJZfrYJdO5+WscsWoO3oDwVpQmtltNl3TV4KbVuszW/l0o/zGTL9lxq6wgMxq13bpWDdBHovFMcvCK/6r7ST4FvX1w+FPiuLIZZXof6EvLEucommpsLzPtUAJeJ35fn265cTHGmR5MGz/0e8qJZFd6m121NsEjKmrIwJys6nGjNoTs3AACH5J/rxiE7s1f47h39r9/cyxRpKXGcctTuRRchGTs3Ztg338bBbcbOPDAlAfj0ZTfjipv2FQLZ7h0z7NyYtTKFPPmo3bjy5v0AgF07NrL0Axq8Z73io7h538HKvnlktGyrXNolLxyixIHO3TWjaZKeJIsU8KIhoucjM+PEnj17FlyaxdG0Bi9UVePi4NX/HhrS4a0yMv/+s4/CsYftrGyvxoQcthxdTTT//WcfheMOr5Z/nXji/U7C3/3o2TjxyNUZKLfhqd98Mk48cheOP3xX77SecJ8T8ZrnPRSnH3togpIpTfzzT30L9qzAvTb91lMfcDLO3HMMDm7P8bh73wVApmG+4qZ9AIBffcp9AAA/ePYePHTvsZaJZtOk87/97KNw2Q13FOeffbdj8cWrbvUe++Vrb/Nul6ajDVdUfFvX+JpTIlmYBKzfGrxFCnhXADhd/D4t31aBmV8B4BUAcNZZZ62ywG1RjXtnTDNRfErVdTBKgru42etkxR3UjrwGj6apWVRWl/ufepR3e0XjPfDUQ53pdB2h8q8Tu3ds4DH3PGHRxVgYh+zcwKPPSHP9OzdnOOded0mSltLMmXuOWXQRkmD6yyN378APPsyegJcCkqmnRx+6Ew/de2x+rj35HOL4w8tJjGMO24mHHnYsvnR1VcBjhJeqbG23d7Ki61EXDxGlWYOXWw5X1uCtsI3mIv1lnQvgObk3zYcDuJmZ1TyzhoqJZr542dA0y1E3UF28Bk/t3ZVpMrwGj6xPRVGUZcGMKzY8o0kpIPn29+nxfOMZZs7WAHrYnnPryToV8BYPIY0Qlmnw1EQzCUT0BgDnADieiC4H8BsAdgAAM/8VgLcBeAqASwDcAeB5Q5VlGQnFccm/5f+7Tlb8aVWFN+20FEVRFEVJg8+TrdxWZ+6YakTCQFjAiw10Lr6riebimVEaIUydrCSEmZ/VsJ8B/PRQ+S87fi9QVQ9RHKPBc00zIxbhje5owjOzoiiLYHwnK/anoijKsmD6S5/31Q2xyasN67j+OHQOc3iie3sea6IptY7aKy8aSrQGDwi8Y1dYwNOQpktEdU2ee4D/vNJLX/473M9WzhkLu4SKsjgW5WRFq7+iKMuG6bZ8wtBGgwaPekxvhc4IafC2tuOcrMhjNGTI4pkRMJ/3T4cBYM18PaiAN1F8XRR7Pi0nK4G0yJHsvAq8ipOVuHImY828GynTZXQnKzXtUlEUZRloEvA2NzwCXmINHhBeg7c1n0cN7i0nK54yK+OSxVJMQOFkxd28uio8FfAmin8NHlc+o0w0c+q6qkULV+pkRZkK1biRY+WrLUBRlOXCrG3zmmhKJyteDV53/E5WwmvtQoJfHarBWzzpnKyw38nK6sp3KuBNlXgNXkm0kxXttBRFURRF6Ykxn/M6WRFjDd9+wyhOVjoEOp/pCHnhzBKGSfBu75/0ZNHqO1G8TlbcMAmwZzZCGjw31kyEjxV1sqKsLWOvwTN5aPVXFGXZMGOQJhNNrwavMNHsYqNZ3VRnxbQV62QF9WVWxoWo2TotOi14TDRXWIWnAt5SYVfEaCcrjmAXFeh8bCcrpOEblGkw9hq8LI/Fm0kriqK0xSjG/F406zV4rgO4NvjO2doOD9ZjvWjKhNWL5uKZJVqDx5yPM9foRasC3kTxLfwsNXgmDp6jzQs0g1KwM51psy38IlzFr1G7UybMItoCEekEh6IoS4dZ89YUB88nLPVzslI9yWeGabLdigx0Lo9YJ2FgsiTS4DGy5191srK6qIA3Ufxx8OxP96AmV7JtnKwsol/TrlSZIlovFUVR/MxzoWrTI8DJbb79qccZWx4BbzNfSBetwVMmxeBr8FZYwlMBb4lgR8JzNXjhNXj1v6eAzpQpU2FRkxvaBBRFWTbmkRo8Xxw8QxfrBd8ZPg2eCc8Q72RFO+IpMaNUXjSNiaa7fXUlPBXwJopfg1eaZrrbgLAXzSKMeG2/teA1eNCOVZkKi3GyoiiKsmzErsHzr2eLGZv48Z2z5TFjkvm2XIKnTABC3di2a4qC1ZXvVMBbJlyhryoE1mvwqKYzXbSWTwe4ylSo1sUxnKyQTnAoirJ0zAsvmtV9G5YGr7q/T5fnO9erwZMCXstA58riyZysJNDg8fp5a1cBb6LEOVlhJ2SCPy1yvkQ5WYkvaiLWq+Ep02UhDodIZ44VRVk+zBo8nwmm2TYLeC+s8+zdhG8c4xPw2mvwtCeeFNTsXyIO9odJSJH0RFEBb6LEmGgyu4HOV7mqKoqiKIoyJQoTTW8cvPC+IWgS8JTlI3OykkaD12b7KqAC3kTx1bnmQOf+tMrwCOa375j630PjW/yqKIugGhNyhDyh9V9RlOVjuzDR9Al4RoPn79zc5SNt8CV50BMHz3jRzDPqlK6yOAjptGzqZEVZGipr8gLHuYKdf6nzYo00yVsGRRmfqonmCGvwdIJDUZQlhCMEPF+IBKDeL0AX0phoKlNiRpQoDl7+nl2jJ6wC3kTxqaTnYu1d9ul41GwIk1B2ps3xaFSDp6wrlbYwRp7eEKyKoijTJsaLpi+EAjBAoHPPGMiESQidU024fVmU4ZjN0phRMueBzl0N3uoq8FTAmyoxJprMcU5WDHV926KdrOjwVpkKbk0cK0yCTnAoirJsGK1ZXRy80Dq4Pl2e79xtX5gE0bFqF7uMUJIwCeE4eKuLCngTxe9kxf50fwUDnVdi3CmKoiiKoqShToPn2ydJNb275VmD19bJik41T4vs8Q3pZGV1RTwV8KaKT8ArVHdyW/k9KOCR/9M+xtVajLwGL+BGWVHGpmqiOcIaPOjEi6Ioy0utk5WgiWb3NXjRcfAsE81u6SqLgyhdoHOfr4cVlu9UwFsm3HrYHPjcpm4NXvXYcdEBrjJVxjHRVBtNRVGWl1oTzUYNXnt8E29bXicr5TA3ZrJOe+FpkdLJSu5lZW1QAW+i1AY6L5ys2EcFvWhGLGRevJOV9Wp4ynRZhJylExyKoiwzPk+Zm01r8Ho5Walu83rRFMfFafC0J54SWRy8/ulkTlbW6z2rAt5E8VdotvYxh2PitWURZmmVMoyeo6JUqZorj5GpKvAURVlefLHuzLawk5XunZ7vTJ8Gj4g02PmSk0KDB/iXAqmJZkeI6ElE9EUiuoSIXuzZ/yNEdC0RfSr/+/Ehy7NM1HrRFMew5WTFn5bsRHUQqSiKoihKSurW4DULWGkGJj4vmkCziahVEh0jTYoZURJXl0EnKyvsR3NzqISJaAPAXwD4NgCXAziPiM5l5s87h76JmX9mqHIsKz5tHHv2tXOyEp4vW4RreDc/NY1QpkAlZMgYgc49+SqKoiwLGx51QeFkJdC5pTbR9GrwkMVSw/Y0/Q8o9WROVhJp8FB9vqrB68bZAC5h5q8w8wEAbwTw9AHzW3mqTlW4dr+hDHQe7uAWLVvpEjxlKiwk0DmRTnAoirK0dDPRtD/bUT1r2xMmgajU4MXko93wtJilUeCBwfl7NkFiS8KQAt6pAC4Tvy/Pt7l8LxF9hojeTESnD1iepcJvosnWPoazBi+QVuk9M9zBVbUWceVMBWG9Gp4yXRYW6Hz4bBRFUQbBb6KZffqEP8C2LmpLvAaPCm+ecdloTzwlKJUXTQ5o8HqnPF0W7WTl3wDsZeYHAHgXgNf6DiKi5xPR+UR0/rXXXjtqARdFbaBzIeFJ++EmJyt13dai4+ABGmBUmSZaLxVFUerxC3jZEFPGopOkHmf4vGgCpTdPnURePlLFwdNA52m5AoDUyJ2Wbytg5uuZ+c78598CeIgvIWZ+BTOfxcxnnXDCCYMUdmrUhUkoj2m3Bs/9PiWmWi5l/VhYmARtA4qiLCleAY/MZ33n1qXri/WiCYpx8iIO1354UiRzsgL2e9Hsn/RkGVLAOw/AGUR0NyLaCeCZAM6VBxDRyeLn0wBcNGB5lp4mbz/BNXjmkyiojaiYaLYrWm90gKtMhUWYK9e1TUVRlKnjE+IKJytNa/A6OVnxrMHzeNEklCaiGuh8+SCkdLKyXm/ZwbxoMvMWEf0MgHcC2ADwKma+kIh+G8D5zHwugJ8joqcB2AJwA4AfGao8S4d3EZ7rQbO9k5XYRXgLCXSuKFNgEU5WxspIURRlAHxCnNkW1OAVY5MOa/A827Y9URJIaPA00PnyMSNK42SF4V2Et8IWmsMJeADAzG8D8DZn20vF95cAeMmQZVhWAvJdxalKjImmqdGtnKyMPNqs8/CpKGNSqfvqZEVRFKUWrwaPmjR43dfG+c7xa/BIaPAi0s0/NTb6NEgVJqGU79bHzcqinawoAbxOVtiuilxxsjJ8uRRFURRFUSS+dW6NGrzEHAx442izBq/POUp6iCjN2DboZCVB2hNFBbyJ4nWyArZNNMEtnayEQxFUvWi2KW0CVIOhTIRqHLxxjDRVga0oyrLi09IZwS4YB69Hn+fV4IXi4Jn8YwKd9wjdoKTHPIW+3i5LJyvu9tVFBbwloslVbL2BpjEDUycrilLHYpysaDgGRVGWl02PEGfCIzQGOu9iounpL71x8OQavBbpqgJvGhjz2hShEtbNyYoKeBPFb6LJHhNNe78PEvbnYQ2euyG2pGkgUg2GMg0q2uwx8oROcCiKsrz4gpnPIjV4nbRlnlN8VkwEKjSJcU5Wss+xzEqVekzV6a3BY/g1eCuswlMBb6JEOVmpeNX0p2Vr8ELHuIPaBThZWau5FWWqVDV4w9dL34tHURRlWfAHOjfasAYnKx3y850T0uDNWmjwDKEyK+NiHkNfDR7DbynTFH5smVEBb6J4Zyu4Whnlr1SxQhRFURRFUWLxabxKDd44ZfB50eyaf8jzpzIuZoK1ryAW0gCu8rBZBbyJ4pfvuLLddrLiT6uMg0dBbUTFscToJpqqwVCmQdXJygh5rt3qAEVRVomZZzRpNHjNJprt8/ONZQ56nKwAECaa8U5WVL6bBuZ5pBDEyOPMTAU8ZRJUhTtXmxdYgxcRB696zrjo8FaZChVz5bGcrGgDUBRlSfGbaGafYRNN89m+8/Odse010aRWJpqlkxXtkKdA6WSlrxfN9XvPqoC3RFQEPPG/b7/BmiULOllxB7Ujr8FTLxPKVKho8EZYgzd4DoqiKMPhF/CyIabPwyaA4p2fLtC5z8lKmX8bJysaJmEalE5W+qVTnq9r8JQFE1iC53GyUn+OpG6gumAnmgvLU1FcFuFRNvMiqy1AUZTlxLcGz2wLrWfr0+P5xjN+DV6pBWozWTfWukGlHvPM0mjw1ERTmQDeQOfM1nZ2joppADqEVBRFURQlJT4NnlmX1xRyINW4ZCvoZCU+Bw2TMC2KNXh9E1plSS6ACngTJUaD5x4XEvCKforCZgeLd7KicfCUaVANk7CYfBVFUZYF39jCCElNTla6dH5tTDSL/GNMNAufBdojT4HCi6Zfdm+XFqpVYJXlvs1FF0CJp0648/02dAl0vpg4eIqyeBYS6HzNFn8rirL6FHHwgiaa7U0ny3Or+OPgEVrId6UXTVV/TIJiDV7fMAlYv/esVuGJEojYYW3PNHps/fZRTJJRuBut7Bldg6czZso0qGrwRnCy0sLDraIoyjJgBLuQuWOfMAm+DrNJgxflZCX/VC+a08A8hd6BztkoEtTJirJgfEEZM6cqttdMbjhHURRFURRlbDYb4uClZisUB69D/roGbxqYSYL+TlY00LkyEXx1jivbuWWg8ymvwVMNhjINFhboXAcUiqKsEEYLFlyD53y2oY0XzSLQeYucQmalyrgUa/BSaPB8XjT7JTtpVMBbIpoqeEiDFxPofNFhErIB7siZKoqHhQU6Hz4bRVGU0dho0OD1iTnnO8XvRZNamWgaGVHlu2lgHkMKC7V18/WgAt5E8XvR5GocPESswbM0eA0HFT9HdrJC4zt2URQfi3A4VNs2FUVRlpDCyUrQcqh0ANcW3zk+KyaiUhsXJ+BliegavGlgnkNf8S7T4FXHtqu8tEkFvMniX4MnN7Nz2DxgoymdrIS60sVr8BaQqaJEMI4Gb93mFhVFWXVKE83647r0sb5JaJ8GjwBsFJPczRkZM081mZ8G5jGkCHTue8eurninAt5kCcbBkxo7drxqrnJNVRRFURRladho8KKZmpCTlTbr6cw4qkkoVcZhVgh4/dIJaepWedysVXiieJ2ssGOiibhA56DyIzoO3ugqPDXQVKbBIiZu1URTUZRVwwh2wTh4LTRroXMl/jh4wsmKmmguHaZuJFmDR746sLoSngp4S0Sjk5XAdhISXryTlZHX4EEHuMo0WISTlbq2qSiKsoxs5LaRmw2Bzrt0fr5T/HHwCJsb8Rlss5poTgnzGFJo2rKFEOvzXAcV8IjoSUT0RSK6hIhe7Nm/i4jelO//GBHtHbI8y0TQyUr+nch2smJ+m+/ezxpPla772MWESVifhqdMF3WyoiiK0p9oDV6nNXjlp/keCpMwKzR4zRkZTVELmVAZkMLJSpIwCdU6pyaaHSCiDQB/AeDJAO4L4FlEdF/nsB8DcCMz3wPAHwP4P0OVZ9nwBWWUgc4JtskmoTQtKJyquJ81QtSiXTzoAFeZKqEAqSkhIp3gUBRlpZjlI8zQGjx3jNKO0gOnOT8YB29G4ox6tnM/LWqiOQ3SOVlhyLcsFdtXl80B0z4bwCXM/BUAIKI3Ang6gM+LY54O4Dfz728G8OdERLxkfksvueY2fPW625OmefmNd1S2ffaKm4vvRISD24wLvn5j8dvy/sRcfMbS9nhFURRFURQfRrALxcFLAQlVzIEtXxy8dsJasQZPA+FNAvPsPnTJdbj4mts6p3Pb/i3rtxnvfvyrN+CmOw42nr9zc4ZvvecJnfNfBEMKeKcCuEz8vhzAw0LHMPMWEd0M4DgA18mDiOj5AJ4PAHv27BmqvJ0599PfwMvfffGgecwIePV/f634vefYQ/HV627Hn/zXxdZv+f3uJxyGK27ch0N2bgAATjhiF44/Yqc3/ROO2IW7n3AYvnR11oBCNvNDccIRu7Brc2PUPBXFhzsYGMMD3AmHh9umoijKVDnpyN246pb93n2H7tzE4bs2ccIRu7z7TzhiF47YvYmdm+2NyY47bCeIgHufdAQObM1x8TW34cD2HMcethM33H6gWLZy1CE7cMyhWd961CE7GtM99ehDAABPuM9dWpdJSc9Rh2bP7H+99XO903r0GTtwdJ6eGSf/33d+Merc4w/fhfP/1xN6l2FMaChlGRE9A8CTmPnH89/PBvAwZv4Zcczn8mMuz39/OT/mOl+aAHDWWWfx+eefP0iZu3L1Lftx7a13Jk93944ZTjvmUGzPGTfecaCYZdixMcPdjj8MX7r6VgDA4bs2cfwRu/C1627HoTs3cPJRh+Ar192GM+5yBO44sIWj887tzq1tHNxmHL6rKtfvO7ANALjqlv04dOcGTjxyd/LrqeOOA1sgUCGMKsoiuXnfQezeMcP+g/OoQUFfbr9zCxszwu4dWv8VRVke9h/cxvaccZhnXAEAN91xAEfs3uHV4m3PGbft3yoG8W254fYDOHTnBrbnjBtuP4Cb9x3EacccAmbg0F0buPjq23CPuxyOjRnhS1ffim86/vCoMcYNtx/AMYfuUEcrE4CZcck1t+HOgHa2Dfe4y+HYnBG+ePWtuNvxh+Gqm/fjjnzs28TGjHCfk4/sXYbUENEnmPks774BBbxHAPhNZn5i/vslAMDM/1sc8878mI8Q0SaAqwCcUGeiOUUBT1EURVEURVEUZSzqBLwhvWieB+AMIrobEe0E8EwA5zrHnAvgufn3ZwB4z7Ktv1MURVEURVEURZkKg63By9fU/QyAdwLYAPAqZr6QiH4bwPnMfC6AVwJ4HRFdAuAGZEKgoiiKoiiKoiiK0oEhnayAmd8G4G3OtpeK7/sBfN+QZVAURVEURVEURVkXBg10riiKoiiKoiiKooyHCniKoiiKoiiKoigrggp4iqIoiqIoiqIoK4IKeIqiKIqiKIqiKCuCCniKoiiKoiiKoigrggp4iqIoiqIoiqIoK4IKeIqiKIqiKIqiKCsCMfOiy9AKIroWwKWLLofD8QCuW3QhlJVG65gyJFq/lCHR+qUMjdYxZUimWr/uyswn+HYsnYA3RYjofGY+a9HlUFYXrWPKkGj9UoZE65cyNFrHlCFZxvqlJpqKoiiKoiiKoigrggp4iqIoiqIoiqIoK4IKeGl4xaILoKw8WseUIdH6pQyJ1i9laLSOKUOydPVL1+ApiqIoiqIoiqKsCKrBUxRFURRFURRFWRFUwOsJET2JiL5IRJcQ0YsXXR5l+SCi04novUT0eSK6kIhemG8/lojeRUQX55/H5NuJiF6e17nPENGZi70CZRkgog0i+iQR/Xv++25E9LG8Hr2JiHbm23flvy/J9+9daMGVpYCIjiaiNxPRF4joIiJ6hPZhSiqI6Bfy9+PniOgNRLRb+zClD0T0KiK6hog+J7a17rOI6Ln58RcT0XMXcS0+VMDrARFtAPgLAE8GcF8AzyKi+y62VMoSsgXgl5j5vgAeDuCn83r0YgDvZuYzALw7/w1k9e2M/O/5AP5y/CIrS8gLAVwkfv8fAH/MzPcAcCOAH8u3/xiAG/Ptf5wfpyhN/CmAdzDzvQE8EFld0z5M6Q0RnQrg5wCcxcz3B7AB4JnQPkzpx2sAPMnZ1qrPIqJjAfwGgIcBOBvAbxihcNGogNePswFcwsxfYeYDAN4I4OkLLpOyZDDzlcx8Qf79VmQDo1OR1aXX5oe9FsB35d+fDuDvOOOjAI4mopPHLbWyTBDRaQCeCuBv898E4HEA3pwf4tYvU+/eDODx+fGK4oWIjgLwGACvBABmPsDMN0H7MCUdmwAOIaJNAIcCuBLahyk9YOYPALjB2dy2z3oigHcx8w3MfCOAd6EqNC4EFfD6cSqAy8Tvy/NtitKJ3JTkwQA+BuBEZr4y33UVgBPz71rvlLb8CYAXAZjnv48DcBMzb+W/ZR0q6le+/+b8eEUJcTcA1wJ4dW4G/LdEdBi0D1MSwMxXAPgDAF9HJtjdDOAT0D5MSU/bPmuyfZkKeIoyEYjocABvAfDzzHyL3MeZu1t1eau0hoi+A8A1zPyJRZdFWVk2AZwJ4C+Z+cEAbkdp2gRA+zClO7nJ29ORTSScAuAwTERLoqwuy95nqYDXjysAnC5+n5ZvU5RWENEOZMLd65n5n/PNVxuzpfzzmny71julDY8E8DQi+hoyM/LHIVsvdXRu7gTYdaioX/n+owBcP2aBlaXjcgCXM/PH8t9vRibwaR+mpOAJAL7KzNcy80EA/4ysX9M+TElN2z5rsn2ZCnj9OA/AGbknp53IFv2eu+AyKUtGvjbglQAuYuY/ErvOBWA8Mj0XwL+K7c/JvTo9HMDNwqRAUSyY+SXMfBoz70XWR72HmX8IwHsBPCM/zK1fpt49Iz9+aWcxleFh5qsAXEZE98o3PR7A56F9mJKGrwN4OBEdmr8vTf3SPkxJTds+650Avp2Ijsk1zd+eb1s4Gui8J0T0FGTrWzYAvIqZX7bYEinLBhE9CsAHAXwW5RqpX0W2Du8fAewBcCmA72fmG/IX3J8jM1G5A8DzmPn80QuuLB1EdA6AX2bm7yCib0Km0TsWwCcB/DAz30lEuwG8Dtla0BsAPJOZv7KgIitLAhE9CJkTn50AvgLgecgmkbUPU3pDRL8F4AeQeZ3+JIAfR7bWSfswpRNE9AYA5wA4HsDVyLxhvhUt+ywi+lFkYzYAeBkzv3rEywiiAp6iKIqiKIqiKMqKoCaaiqIoiqIoiqIoK4IKeIqiKIqiKIqiKCuCCniKoiiKoiiKoigrggp4iqIoiqIoiqIoK4IKeIqiKIqiKIqiKCuCCniKoijKZCCibSL6lPh7ccK09xLR5yKP/Xkiek7+/XeI6DN5ef6TiE7JtxMRvZyILsn3n5mqrJFlDF4PEf0BET1uzPIoiqIo02Bz0QVQFEVRFME+Zn7QIgtARJsAfhSAEdj+LzP/er7v5wC8FMBPAngygDPyv4cB+Mv8cwr8GYC/AfCeRRdEURRFGRfV4CmKoiiTh4i+RkS/T0SfJaKPE9E98u17ieg9uQbt3US0J99+IhH9CxF9Ov/7ljypDSL6GyK6MNfGHeLJ7nEALmDmLQBg5lvEvsMAmACyTwfwd5zxUQBHE9HJ+d8Hco3f54jo0Z7reQgRvZ+IPkFE7ySik/PtP0FE5+VlfgsRHdrlepj5UgDHEdFJ3e+6oiiKsoyogKcoiqJMiUMcE80fEPtuZuZvBvDnAP4k3/ZnAF7LzA8A8HoAL8+3vxzA+5n5gcg0cRfm288A8BfMfD8ANwH4Xk8ZHgngE3IDEb2MiC4D8EPINHgAcCqAy8Rhl+fbfhDAO3NN5AMBfMpJa0de7mcw80MAvArAy/Ld/8zMD83LfRGAH+txPRfk16IoiqKsEWqiqSiKokyJOhPNN4jPP86/PwLA9+TfXwfg9/PvjwPwHABg5m0ANxPRMQC+ysyfyo/5BIC9nnxORiZcFTDzrwH4NSJ6CYCfAfAbNddwHoBX5YLcW0V+hnsBuD+AdxERAGwAuDLfd38i+l0ARwM4HMA7e1zPNQBOqSmnoiiKsoKoBk9RFEVZFjjwvQ13iu/b8E907gOwO3D+61Fqya4AcLrYdxqAK5j5AwAek+9/jXHWIiAAFzLzg/K/b2bmb8/3vQbAz+Sayt+qKUfM9ezOr0VRFEVZI1TAUxRFUZaFHxCfH8m/fxjAM/PvPwTgg/n3dwN4AQAQ0QYRHdUin4sA3MP8IKIzxL6nA/hC/v1cAM/JvWk+HJkJ6ZVEdFcAVzPz3wD4W5TOWgxfBHACET0iT38HEd0v33cEgCtz7d8PiXO6XM89AUR5DVUURVFWBzXRVBRFUabEIUT0KfH7HcxsQiUcQ0SfQaa1ela+7WcBvJqIfgXAtQCel29/IYBXENGPIdNsvQClGWQTb0dm7mn4PSK6F4A5gEuRedAEgLcBeAqASwDcIfI+B8CvENFBALchN600MPMBInoGgJfngtomsjWFFwL4dQAfy6/lY8gEvtbXkwuI9wBwfuQ1K4qiKCsCMXe1clEURVGUcSCirwE4i5mvGym/fwHwIma+eIz8UkNE3w3gTBPeQVEURVkf1ERTURRFUaq8GJmzlWVlE8AfLroQiqIoyvioBk9RFEVRFEVRFGVFUA2eoiiKoiiKoijKiqACnqIoiqIoiqIoyoqgAp6iKIqiKIqiKMqKoAKeoiiKoiiKoijKiqACnqIoiqIoiqIoyoqgAp6iKIqiKIqiKMqK8P8DXKBsnt9gAHAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(range(1, 1001), output_labels[:1000])\n",
        "plt.title('Hypnogram of Automatically Scored Data')\n",
        "plt.ylabel('Sleep Stage')\n",
        "plt.xlabel('Epoch (30s each)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning Exploration\n",
        "Another natural extension which we explored was developing an unsupervised learning clustering methodology which would be effective at grouping epochs into their specific sleep stages. We hoped that being able to acheive high classification accuracy using supervised techniques suggested that the various data classes were separable and thus even basic clustering techniques would be able to produce relatively accurate results.\n",
        "\n",
        "We initially decided upon trying to perform k-means clustering on the vectorized epochs. We thought that this was a natural choice because the number of clusters that we expect our data to have is known at 5. However, upon initial investigation and further external research, we saw that many clustering techniques including k-means falls victim to what is known as *The Curse of Dimensionality*. This is the phenomenon that data in higher dimensions (in our case 3000) tend to be closer together in vector space and have lower variance making it harder for our algorithm to converge to the correct answer. We attempted to utilize PCA to reduce dimensionality in a technique known as spectral clustering but were not very successful."
      ],
      "metadata": {
        "id": "JT61g8aGw2OQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZqb6wR-jfFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dab9895-1ff9-49fd-c040-7a34c3150ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwt59_xpi\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwt59_xpi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From <ipython-input-27-d988f054519c>:9: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py:107: BaseResourceVariable.count_up_to (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        }
      ],
      "source": [
        "#########################\n",
        "# UNSUPERVISED LEARNING #\n",
        "#########################\n",
        "num_clusters = 5\n",
        "kmeans = tf.compat.v1.estimator.experimental.KMeans(num_clusters=num_clusters)\n",
        "\n",
        "def input_fn():\n",
        "  return tf.compat.v1.train.limit_epochs(\n",
        "      tf.convert_to_tensor(train_X, dtype=tf.float32), num_epochs=1)\n",
        "\n",
        "prev_centers = None\n",
        "for _ in range(20):\n",
        "  kmeans.train(input_fn)\n",
        "  cluster_centers = kmeans.cluster_centers()\n",
        "  if prev_centers is not None:\n",
        "    print('delta:', cluster_centers - prev_centers)\n",
        "  prev_centers = cluster_centers\n",
        "  print('score:', kmeans.score(input_fn))\n",
        "print('cluster centers:', cluster_centers)\n",
        "\n",
        "cluster_indices = list(kmeans.predict_cluster_index(input_fn))\n",
        "label_dict = {}\n",
        "for i, point in enumerate(train_X):\n",
        "  ci = cluster_indices[i]\n",
        "  center = cluster_centers[ci]\n",
        "  label_dict[point] = ci\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UO8H7D_F8djj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "InitialDataProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}